# 计算机网络

---

## 第一章 计算机网络和因特网

**计算机网络（Computer Networking）**是指将[地理](https://baike.baidu.com/item/地理)位置不同的具有独立功能的多台[计算机](https://baike.baidu.com/item/计算机/140338)及其外部设备，通过通信线路连接起来，在[网络操作系统](https://baike.baidu.com/item/网络操作系统/3997)，[网络管理软件](https://baike.baidu.com/item/网络管理软件/6579078)及[网络通信协议](https://baike.baidu.com/item/网络通信协议/4438611)的管理和协调下，实现[资源共享](https://baike.baidu.com/item/资源共享/233480)和信息传递的**计算机系统**。

### 1.1 因特网

**因特网（Internet）**是一个**世界范围内的计算机网络**，互联了全世界的电子设备，包括计算机、个人终端、非传统因特网物品。

#### 1.1.1 具体构成

这些设备被称为**主机（host）**或**端系统（end system）**。端系统通过**通信链路（communication link）**和**分组交换机（packet switch）** **连接** 在一起。

通信链路的**传输速率（transmission rate）**以比特秒（bit/s，或bps）度量。当一台端系统向另一台端系统发送信息时，会将数据分段成多个信息包，称为**分组（packet）**。

常见的分组交换机是**路由器（router）**和**链路层交换机（link-layer switch）**，两者的作用是向目的地转发分组。路由器通常用于网络核心中，链路层交换机通常用于接入网络。一个分组经过的通信链路和分组交换机被称为**路径（route）**。以交通运输系统类比分组交换网络：

+ 分组：货物
+ 端系统：目的地
+ 通信链路：高速公路
+ 分组交换机：交叉路口和引导牌

端系统通过**因特网服务提供商（Internet Service Provider，ISP）** **接入互联网**，每个 ISP 自身就是一个由多台分组交换机和多段通信链路组成的网络。ISP 之间也分等级，并需要互联，以此接入全球互联网。

端系统、分组交换机和其他因特网部件需要运行一系列**协议（protocol）**，控制因特网信息的接收和发送。**TCP（Transmission Control Protocol，传输控制协议）**和 **IP（Internet Protocol，因特网协议）**是最重要的因特网协议。IP 定义了路由器和端系统之间发送和接收的分组的**格式**。主要协议统称 **TCP/IP** 协议。

**因特网标准（Internet Standard）**由因特网工程任务组（Internet Engineering Task Force，IETF）研发，他们的标准文档称为**请求评论（Request For Comment，RFC）**。

#### 1.1.2 服务

从 *为应用程序提供服务的基础设施*  的角度描述因特网，各种端系统被称为**分布式应用程序（distributed application）**。这些程序运行在各个端系统而不是网络核心的分组交换机中。这些应用程序使用特定语言编写，并互相发送数据，而因特网则是提供数据传输服务的平台。

连接因特网的端系统提供了一个**套接字接口（socket interface）**，规定了各端之间**交换数据的方式**。

#### 1.1.3 协议

**协议（protocol）**各方协商后制定的一套标准，人类语言日常交流的用语规范就是一套“提问与回答”的协议标准。**网络协议**类似于人类协议，区别在于通信双方是端系统。

计算机网络协议简称协议，定义了两个或多个通信实体之间交换的**报文**的格式和顺序，以及报文发送或接受一条报文或其他事件时采取的**动作**。如：向 Web 服务器请求网页，发送一条 GET （动作）请求，包含 HTTP 请求报文（报文），Web 服务器返回一个 HTML 文件（响应）。

### 1.2 网络边缘

一些因特网部件位于因特网的边缘，，因此它们被称为端系统。端系统也被称为 host（主机），因为它们容纳和运行一些应用程序，如 Web 浏览器与服务器。主机又可以分为**客户端（client）**与**服务器（server）**两类，如今一些提供数字媒体服务的服务器属于大型**数据中心（data center）**。

#### 1.2.1 接入网络

**接入网络**是将端系统物理连接到其**边缘路由器（edge router）**的网络，而边缘路由器是端系统连接到其他端系统时经过的**第一台**路由器。以下是常见的接入网场景：

+ 传统的家庭接入：DSL（用户数据线，利用现有的电话线路设施）、电缆接入（利用现有的有线电视设施）、FTTH（光纤到户，分为有源和无源）、拨号（和DSL模式相同）、卫星接入
+ 企业和现代家庭接入：以太网（Ethernet，由 Xerox 公司发明，现有 IEEE 802.3标准）、Wi-Fi（无线通信技术）
+ 广域无线接入：3G、4G、5G 以及其他蜂窝网络技术

现在家庭接入网络通常包括：

+ 外部接入物理媒体
  + 双绞铜线：是一种通过双绞构造增强干扰性、在百米内有效的媒体，一般用于局域网（LAN），可能需要与放大器一起工作
  + 同轴电缆：类似双绞铜线的媒体，拥有更强的抗干扰能力和更远的可靠传输距离，是过去主要的因特网接入手段
  + 光纤：是目前速度最快、传输距离最长、安全性最高的媒体，需要使用特殊的调制解调器（光猫）
+ **调制解调器（modem）**：也称“猫”，用于将媒体中传输的模拟信号转为计算机硬件可识别的数字信号。对于光纤，需要使用数字调制解调器将光信号转换为数字信号
+ **防火墙（firewall）**：用于在外网和内网之间构建一道安全屏障，保护用户资料和信息安全
+ **路由器（router）**：家庭用交换机一般为路由器，起到网关的作用。路由器处理分组，将非 TCP/IP 地址转为 TCP/IP 地址并发送分组。由于家用宽带入线通常只有一根，路由器起到建立家庭局域网的作用，多台家用设备通过路由器向外转发分组，由路由器根据转发表确认这些分组去向。在接到响应分组时，根据分组首部信息，确定分组内网中去向，转发给指定设备。目前光纤到户技术已经普及，一些路由器已经内置调制解调器功能，可以直接和光线连接并进行转发
+ **局域网（LAN）**：局域网一般是覆盖范围比较小的计算机网络。**以太网（Ethernet）**是家庭局域网技术的一种，是最普遍的局域网络。现代路由器将局域网建立功能内置，通过有线或无线媒体的方式连接家用局域网中的设备
+ **无线局域网（WLAN）**：利用无线通信技术（Wi-Fi）可以建立通过无线媒体连接设备的局域网
+ 家用设备：常见的家用联网设备有个人计算机、移动终端、智能家具、网络摄像头等

#### 1.2.2 物理媒体

数字比特需要通过**物理媒体（physical media）**传输。物理媒体分为两种类型：

+ 导引型媒体：guided media，沿固体媒体前行，如光纤
+ 非导引型媒体：unguided media，以电磁波形式在空气或外层空间传播，如无线电

### 1.3 网络核心

**网络的核心部分**是由分组交换机和通信链路构成的网状网络。数据传输的方式有**分组交换**和**电路交换**。现代的因特网是**网络的网络**。

#### 1.3.1 分组交换

在网络应用中，端系统彼此交换**报文（message）**。报文用于执行控制功能（如 Restful 状态转移），也可以包含数据（如 HTTP 传输超媒体）。发送源将长报文划分为较小的数据块，称为**分组（packet）**，这些分组通过通信链路和**分组交换机**（**packet switch**，本意是转换光电信号的“开关”，主要为**路由器（router）**和**链路层交换机（link-layer switch）**）传输。

分组交换使用**最大传输速率**发送分组，如果一个大小为 L 比特的分组通过速率为 R 比特/秒的链路传输，那么传输时间就是 L/R 秒。

分组交换不会预留任何链路需要的资源，分组需要承受**排队延迟**，因特网不会保证分组实时交付。

##### 存储转发传输

多数分组交换机采用**存储转发传输（store-and-forward transmission）**机制。该机制在向传输链路输出第一个比特前，**必须接受到一个完整的分组**，在转发前接收到的比特会先被**缓存（即 store，存储）**。

与接收到比特就转发（流）的方式相比，假设链路速率为 R ，比特数为 L，转发接收延迟为 2L/R（接收 L/R + 转发 L/R），而流无需等待，为 L/R 。

##### 排队延迟和分组丢失

分组交换机会为每条有最大传输速率限制的通信链路准备**输出缓存（output buffer，也称输出队列（output queue））**。如果一个完整分组已到达，而链路忙于传输其他分组，该到达分组会被缓存等待，直到链路空闲。因此，除了分组交换机的转发过程延迟，分组还需承受输出缓存过程的**排队延迟（queuing delay）**。

由于缓存空间有限，当通信链路传输过慢时，会出现缓存空间不足的情况。此时如果有新分组到达，处于输出缓存中的某个分组或新到达的分组会被丢弃，即**分组丢失（或丢包，packet loss ，PL）**

##### 转发表和路由协议选择

在因特网中，每个端系统有一个 **IP 地址（Internet Protocol Address）**。每个分组的首部包含了传输目的地的 IP，IP 有一种等级结构，这个结构决定各级路由器如何转发分组。路由器会检查分组首部包含的 IP 信息，根据路由器内部的**转发表（forwarding table，用于将目的地地址（或地址一部分）映射到通信链路）**找到适合的输出链路。

这些转发表无需手动设置（静态路由），因特网具有一些特殊的**路由选择协议（routing protocol）**，用于自动设置转发表（动态路由）。

#### 1.3.2 电路交换

交换机移动数据的另一种方法是**电路交换（circuit switching）**。与分组交换按需分配模式不同，电路交换会预留端系统沿路径通信时需要的**资源**（缓存，链路传输速率）。在端系统向另一端系统发送消息前，两者会建立连接，路径上的交换机需要维护这些**连接状态**（用电话术语来讲即是**电路（circuit）**）。

##### 电路交换网络中的复用

电路交换网络中的**复用**是指每条链路会为多个连接使用。有两种复用方式：

+ **频分复用（Frequency-Division Multiplexing，FDM）**将一条链路的频谱按一定的频段宽度分开，该频段宽度被称为**带宽（band-width）**，多个连接在同时共用同一条链路
+ **时分复用（Time-Division Multiplexing，TDM）**在固定时间内将一条链路分为固定期间的**帧**，每个帧又被划分为固定数量的**时隙**。每个时隙有一个连接独享，多个连接在固定周期中排队使用链路

##### 与分组交换对比

分组交换因为没有预留资源，其端到端时延是可变与不可预测的，不适合实时通讯服务。但与电路交换相比，分组交换**动态按需分配资源**，更简单、有效、低成本，在**低并发**场景下有近似于电路交换的效率。此外，分组交换在链路空闲时，可为单个连接提供最大传输效率，而不是浪费空闲资源。目前来看，分组交换是现在的趋势。

> [Traceroute](https://www.traceroute.org) 提供一些源，并能进行端到端路由线路跟踪

#### 1.3.3 网络的网络

网络边缘上的端系统通过**接入 ISP** 与因特网连接，这只是整个互联网需要解决的问题的一小部分，接入 ISP 自身必须能够互联，这个问题通过创建**“网络的网络”**来解决。网络的网络是有层级的结构，不同层级的节点不仅与高层节点连接，还可能与同级甚至跨级连接，整个网络是**图状结构**而非树状结构。

目前因特网的网络结构是一种多层结构，由**接入 ISP**、**区域 ISP（regional ISP）**、**第一层 ISP（tier-1 ISP）**、**PoP（Point of Presence，存在点）**、**多宿（multi-home）**、**对等（peer）**、**因特网交换点（Internet Exchange Point，IXP）**和**内容提供商网络（content provider network，CPN）**组成。

+ 接入 ISP：将端系统连接到因特网的 ISP
+ 区域 ISP：在一些区域中有一些 ISP 连接这各个接入 ISP，这些 ISP 会与更大的区域 ISP 或第一层 ISP 连接
+ 第一层 ISP：在第一层 ISP 看来，与之连接的 ISP 是**客户**，而自己是**提供商**，第一层 ISP 是全球范围的 ISP，并不向任何人收取结算费用。全球范围内有多个第一层 ISP 存在并互联
+ PoP ：PoP 是一个 ISP 网络中的一台或多台路由器群组，通常位于同一位置。客户 ISP 或其 PoP 可以通过第三方提供的链路连接到提供商 ISP 的某个最近的 PoP
+ 多宿：一个客户 ISP 与多个提供商 ISP 连接的行为称为多宿，当其中一个提供商 ISP 故障时客户 ISP 依旧可以交换数据
+ 对等：位于同一层级结构且物理邻近的 ISP 可以直接连接，而不需要通过上一级 ISP 交换数据，称为对等。通常对等时 ISP 之间不结算费用
+ 因特网交换点：IXP 是一个汇合点，通常位于第三方提供有着自己独立交换机的建筑中，各级 ISP 及其 PoP 可能位于 IXP 中并对等
+ 内容提供商网络：内容提供商网络（如 Google）与第一层 ISP 同级。Google 的数据中心网络通过专用的 TCP/IP 通道连接，独立于公共因特网，与同级或较低层的 ISP 直接互联（在 IXP 处互联或直接连接），并不收取结算费用。内容提供商通过这种方式减少了向顶层提供商支付的费用，并加强了其对服务如何交付给客户的过程的控制权

### 1.4 分组交换网中的时延、丢包、吞吐量

计算机网络必定要限制端系统之间的**吞吐量（每秒能够传输的数据量）**，在端系统中引入**时延**，并产生**丢包**。

#### 1.4.1 分组交换网络的时延（点到点时延）

分组交换网络的**时延（delay）**是分组从一个**节点（node，路由器或主机）**至另一个节点之间受到的时延，主要有一下几种类型：

+ **节点处理时延（nodal processing，d~proc~）**：节点处理延迟来自检查分组首部和决定分组去向需要的时间，也可能包括检查比特级差错所需要的时间。一般为**微秒**或更低数量级。这之后分组会被送入缓存队列等待
+ **排队时延（queue delay，d~queue~）**：分组在队列中等待时的时延，取决于等待向链路中传输的分组**数量**。一般为**毫秒至微秒**量级
+ **传输时延（transmission delay，d~trans~）**：大部分路由器采取分组按先到先服务的规则进行传输，传输时延是将分组**推出路由器（即传输/发射，从路由到链路口）**所需要的时间。一般为**毫秒至微秒**量级
+ **传播时延（propagation delay，d~prop~）**：是分组从链路起点到下一个路由器所需要的时间。该时延取决于**物理媒体**，是两节点之间**距离的函数**。在广域网中，该时延一般为**毫秒**量级

**节点总时延（total nodal delay，d~nodal~）**是上述延迟的和：
$$
d_{nodal} = d_{proc} + d_{queue} + d_{trans} + d_{prop}
$$

#### 1.4.2 排队时延和丢包

**排队时延**很大程度上取决于**流量到达队列的速率**（接收分组速率）、**链路的传输速率**（网速）、**到达流量的性质**（周期性或突发性到达）。设 **L** 为分组的比特大小，**a** 为分组到达速率，**R** 为链路传输速率，则**流量强度（traffic intensity）**为：
$$
La\ /\ R\ \  (bps)
$$
流量强度越大，排队时延增加越快，分组**丢失（lost）**比例也就越大。

#### 1.4.3 端到端时延

**端到端时延（end-to-end delay）**是分组从端系统到端系统需要的时间。假设端到端传输经过 **N** 台路由器，则端到端时延为：
$$
d_{end-end}=N(d_{proc}+d_{trans}+d_{prop})
$$

##### Traceroute

[Traceroute](https://www.traceroute.org) 程序可以由用户指定一个目标端系统，并统计经过的所有路由器。当一个接收到一个分组时，会向发送源返回一个**报文**。该报文包括路由器的名字以及地址，因此程序可以重建分组由源到目的地所经过的路由。该程序总共测试三次分组转发。

Windows 提供了一个名为 tracert 的命令行软件用于跟踪路由，请求网易首页可以得到如下结果：

```
> tracert www.163.com

通过最多 30 个跃点跟踪
到 z163picipv6.v.qdyd03.longclouds.com [2409:8c20:3c42:21::103] 的路由:

  1     2 ms     1 ms     2 ms  2409:8028:10:1::7105
  2     1 ms     1 ms     2 ms  2409:8028:10:1::7104
  3     2 ms     2 ms     2 ms  2409:8080:0:2:1105:1151:300:0
  4     8 ms     8 ms     7 ms  2409:8080:0:1:405:1105::
  5    11 ms    11 ms    12 ms  2409:8080:0:2:405:461:600:1
  6    11 ms    11 ms    11 ms  2409:8020:3042:102::1
  7    17 ms    14 ms    13 ms  2409:8020:3042:516::1
  8    13 ms    12 ms    12 ms  2409:8c20:3c42:21::101
  9    11 ms    11 ms    12 ms  2409:8c20:3c42:21::103
```

##### 端系统、应用程序和其他时延

有时传输分组的端系统可能会有意的产生时延，并将此作为端系统媒体共享协议的一部分。另外一些时延来自应用程序处理过程，如 VoIP 语音应用需要一定时间来处理声音源以提高声音质量。

#### 1.4.4 计算机网络中的吞吐量

除了时延和丢包，计算机网络中另一个重要的性能度量是**端到端吞吐量（end-to-end throughout）**。在任何时间瞬间接收到的吞吐量称为**瞬时吞吐量（instantaneous throughout）**，以 bps 计。一个文件的平均吞吐量则是以文件比特数除以传输时间得到的吞吐量 F/T bps。

### 1.5 协议层次及其服务模型

#### 1.5.1 协议分层

网络设计者以**分层（layer）**的形式组织**协议（protocol）**以及实现这些协议需要的**网络硬件和软件**。每个协议层（除顶层）会向上层提供**服务（service）**，即**服务模型（service model）**。分层协议具有概念化和结构化（模块化）的特点，这使得更新系统组件变得更加容易。分层有两个潜在缺点：高层可能冗余较低层的功能（如许多协议栈在基于每段链路和基于端到端的两种情况下都提供差错恢复）、某层功能可能需要其他层出现的信息。

因特网的各层协议组成了一个**协议栈（protocol stack）**，该栈自顶向下为**应用层**、**运输层**、**网络层**、**链路层**、**物理层**。

##### 应用层

**应用层**是应用程序以及其协议停留的地方。应用层解决**端到端（在发送端与接收端之间直接建立数据连接，忽略其他中间设备）**传输问题，应用层协议几乎总是通过**软件**实现。

应用层包括**应用程序（program）**、**服务（service）**和实现服务的**协议（protocol）**。应用程序提供**创建消息的方法**，服务创建与网络交互的**接口**，协议提供**处理数据的规则和格式**。

应用层将**用户的输入**通过应用程序转换为服务，匹配合适的服务协议，按照协议规定的方式处理报文。接下来，发送报文给运输层，由运输层进行下一步报文封装和传输。

常用的应用层协议有：

+ HTTP：超文本传输协议
+ SMTP：简单邮件传输协议
+ FTP：文件传输协议
+ HTTPS：超文本传输安全协议

一些网络功能，如将对人友好的端系统名（如**域名（Domain Name）**是因特网中的计算机或计算机组的名字）转换为网络地址（如 32位的 **IPv4**、128位的 **IPv6**）的 **DNS（Domain Name System，域名系统，将域名与 IP 地址互相映射）**也是借助特定的协议（**UDP**）完成。

应用层中端到端传输的信息分组被称为**报文（message）**。

##### 运输层

**运输层**负责传送端到端之间的应用层报文，运输层协议几乎总是通过**软件**实现。运输层要负责**为应用程序提供连接**，**管理和转发**报文，并**维护连接**。接下来的点到点连接由网络层处理。

因特网中有两种协议用于传输应用层报文：

+ **TCP（Transmission Control Protocol）**：传输控制协议，这是一种**面向连接**的服务，TCP 先在端与端之间建立连接，然后将长报文划分成短报文，确保报文的传递，并进行流量控制和拥塞控制
+ **UDP（User Datagram Protocol）**：用户数据报协议，这是一种**无连接**的协议，不提供不必要的服务，没有可靠性、流量控制与拥塞控制。

运输层的分组被称为**报文段（segment）**。

##### 网络层

网络层负责将被称为**数据报（datagram）**的网络层分组从一台路由器或主机传输到另一台路由器或主机中，即**点对点传输（基于 IP 或 MAC）**，网络层通常是**硬件与软件的混合体**，如路由器。

和运输层不同，网络层**为不同的路由器或主机提供连接的方式**，通过网络地址和路由表将各个路由器或主机**关联**起来。但关联并不代表已经连接，主机的连接由接下来的链路层负责。

源将报文段通过 TCP 或 UDP 协议向网络层递交该**报文段和其目的地地址**。因特网的网络层包括 **IP（Internet Protocol）**协议和决定路由去向的**路由选择协议**。通常也称网络层为 **IP 层**，证明 IP 是将因特网连接在一起的**粘合剂**。

##### 链路层

因特网的网络层通过源和目的地之间的一系列路由器来传输数据报，这需要依靠点对点传输的**链路层**服务。链路层解决具体的传输问题，将在网络层中关联的路由器或主机连接起来并传输数据报。这些数字信号需要交给物理层以物理方式在现实中运输。

链路层物理设备通过一个48位的硬件物理地址 **MAC（Media Access Control Address，媒体存取控制地址）**互相识别，MAC 也称**局域网地址（LAN Address）**、**以太网地址（Ethernet Address）**、**物理地址（Physical Address）**。计算机网络中的每个设备，如网卡，都有一个独一无二的 MAC 。

**局域网没有网络层**，其中设备都是通过链路层协议的 MAC 或不连接外网的**内网 IP** 寻址通信，这些设备不会经过网络层连接互联网。

链路层的服务取决于该链路层的特定**链路层协议**，这些协议由**硬件**实现，如：

+ **Ethernet**：以太网
+ **Wi-Fi**：无线通信
+ **DOCSIS**：电缆接入网

一个数据报在沿途链路上可能经过不同协议处理，如家用设备可能通过无线信号连接家用局域网，再通过电缆或光纤网络向目的地传输数据。链路层分组被称为**帧（frame）**。

##### 物理层

物理层的任务是将帧的一个个比特从点传输到点，以物理的方式**处理数字信号中的比特位**，并**物理连接**各链路层实体（如蜂窝网络节点）。这层中的协议仍是链路相关的，并进一步与**实际传输媒体**相关。如以太网具有许多物理层协议，由诸如双铜绞线、同轴电缆和光纤的**硬件**实现。物理层的分组被称为**比特流（bits stream）**。

##### 自顶向下

转换用户输入为特定数据结构（应用层）；为多端间的数据建立可靠连接以运输（运输层）；为物理上非直接连接的端系统所依赖的网络节点提供相互识别和寻找最佳路径的方式（网络层）；用硬件设备将已经关联的网络节点连接起来，传递离散的数字信号（链路层）；将离散的数字信号置于连续的物理世界传输（物理层）。

##### 自底向上

以特定物理方式传递更高效的数字信号（物理层）；使得数字信号能在各个网络节点中传输（链路层）；作为向导，引导数据走向（网络层）；维护数字世界中的连接，并将数据置于连接中传输给端系统（运输层）；将报文按照协议约定进行解读，并呈现给用户（应用层）。

#### 1.5.2 OSI 模型

因特网协议栈并不是唯一的协议栈。**国际标准化组织（ISO）**提出计算机网络围绕7层来组织，称为**开放互联系统（OSI）模型**。OSI 模型比因特网协议栈更加具体，分为以下7层：

+ 应用层
+ 表示层
+ 会话层
+ 运输层
+ 网络层
+ 数据链路层
+ 物理层

**会话层**和**表示层**是 OSI 中附加的两个层。表示层的作用是使进行通信的应用程序能够**理解交换数据的含义**。会话层提供**数据交换的定界**和**同步**，包括**建立检查点**和**恢复方案**的方法。因特网协议栈选择将这两层的内容交给应用程序开发者处理。

#### 1.5.3 封装

因特网协议栈的每层都将自己的分组交至下一层或上一层传输。在向下传递时，下层会在上传分组的首部添加自己的信息，对上层分组进行了**封装（encapsulation）**。封装后的分组具有两部分：**首部字段（header，头部）**和**有效载荷字段（payload file，或称 body，体）**，后者通常是来自于上一层的分组。一个大报文可能被拆分成多个小报文并被封装成多个具有首部信息的报文段，接收端必须能将这些报文段重构为大报文。

### 1.6 面对攻击的网络

因特网已经成为人类社会的重要组成部分，也面临这恶意攻击的风险。**网络安全**是一个非常重要的议题。

#### 1.6.1 攻击者可以植入有害程序

攻击者可以通过因特网向用户计算机植入**恶意软件（malware）**，受害主机也可能被恶意软件利用，向因特网中继续传播这种软件。这些计算机群体被称为**僵尸网络（botnet）**。

目前多数恶意软件是**自我复制（self-replication）**的，并以**病毒（virus）**或**蠕虫（worm）**的形式扩散。病毒是需要某种形式的用户交互来感染用户设备的恶意软件，通常来自恶意下载链接或电子邮件附件。蠕虫是一种无须任何用户交互就能感染设备的恶意软件，通常来自对脆弱网络应用的攻击导致应用使用者被感染。

#### 1.6.2 攻击者可以攻击服务器或网络基础设施

一种宽泛类型的安全性威胁被称为**拒绝服务攻击（Denial-of-Service （DoS） attack）**，这种攻击会导致网络、主机或其他网络设施拒绝（不能够正常地）向合法用户提供服务。大多数 DoS 攻击为一下类型：

+ 弱点攻击：通过一段精细制作的**报文**按照适当顺序发送给具有缺陷的服务器，使服务器处理出错，自我保护机制导致服务器**停止运行**或**崩溃**
+ 带宽洪泛：攻击者发送大量分组，导致接入链路阻塞，无法提供正常服务
+ 连接洪泛：攻击者与目标主机创建大量 TCP 连接，导致服务器超载，无法提供正常服务

单一且“有前科”的攻击源很容易被上游路由器检测并拦截，阻止其到达服务器。而在**分布式拒绝服务攻击（DDoS）**中，攻击者通过控制僵尸网络中的主机连续对目标服务器发起攻击，这是目前屡见不鲜而且难以主动防范的攻击之一，著名的 MyDoom 病毒曾经利用僵尸网络导致过大范围的服务器停机。

#### 1.6.3 攻击者可以嗅探分组

对于无线传输设备，攻击者可以在传输设备附近放置一台被动的接收机，并接受该设备发送的每一个分组的副本。这种接收机被称为**分组嗅探器（packet sniffer）**。嗅探器也可以被部署在有线网络中，如以太网和有线广播环境。攻击者会通过获取网络接入权并收集分组副本，进行离线分析，得到敏感信息。

分组嗅探器是被动的，因此不向信道中注入分组，因此难以检测。这些嗅探器也可以用于软件测试和故障排除，如 **Wireshark** 就是一种常用的分组嗅探器。

#### 1.6.4 攻击者可以伪装并进行哄骗

攻击者可以生成具有任意源地址、分组内容和目的地址的伪造分组，对于没有防范性的接收方，分组内的命令或恶意内容可能导致各种安全问题，如修改转发表从而导致更多的数据泄漏。将虚假源地址注入分组的能力称为 **IP 哄骗（IP spoofing）**，这是伪装能力的一种。

### 1.7 因特网历史

#### 1.7.1 分组交换的发展 1961~1972

1960年前世界上最大的通信网络是电话网。随着计算机重要性的增加，人们开始考虑如何将计算机连接到一起，计算机产生的流量往往具有突发性，即活动间断性，这使得分组交换开始被讨论和验证。

+ 1964：分组交换技术首次公开发表，MIT 的 Kleinrock 使用排队论体现了分组交换在处理突发流量上的有效性
+ 1967：第一个分组交换计算机网络、因特网的直接祖先：ARPAnet 总体计划公布
+ 1969：已有四个分组交换网络节点，这个网络最早执行的远程注册任务导致了系统的崩溃
+ 1972：ARPAnet 端系统间的第一台主机到主机协议——网络控制协议（NCP）完成；第一个电子邮件程序被编写
+ 1970s中期：其他分组交换网络开始出现：ALOHAnet 卫星微波网络、Telnet 等商用网络

#### 1.7.2 网络的激增 1980~1990

到了20世界80年代，连接公共因特网的主机数量达到了十万量级，联网主机数开始急剧增长。

+ 1983.1.1：TCP/IP 协议作为 ARPAnet 新的标准主机协议正式部署
+ 1980s后期：TCP 进行了重要扩展，实现基于主机的拥塞控制；DNS 被研制出

#### 1.7.3 因特网爆炸 1990s

20世纪90年代发生了许多事件，ARPAnet 已经不复存在，因特网开始走向商业化，主干流量开始由多个 ISP 提供。

+ 1989~1991：欧洲粒子物理研究所（CERN）的 TimBL（Tim Berners-Lee）发明了 Web（万维网），并研制了 HTML、HTTP、Web 服务器和浏览器的初始版本
+ 1996：微软开始研制浏览器，几年后在与网景公司的竞争中胜出
+ 20世纪末：Web 相关标准开始交由 W3C 与 ECMA 组织制定，Web 开始有了一个统一标准
+ 2000：电子邮件、Web、即时讯息、对等文件共享称为最受欢迎的因特网应用程序

#### 1.7.4 目前

+ 光纤到户技术开始普及，代替老旧的电缆传输技术
+ 高速无线蜂窝网越来越普及
+ 在线社交网络取得巨大成功和影响
+ 一些公司开始建立自己的专用网络，绕过公共因特网和较低层 ISP 直接对等
+ “云”开始为应用提供可扩展的计算与存储环境，并用于保证访问安全

---

## 第二章 应用层

### 2.1 应用层协议原理

#### 2.1.1 网络应用程序架构

**应用程序架构（application architecture）**规定了如何在端系统上组织应用程序。对于网络应用程序，有两种主流架构：

+ **客户端-服务器架构**：client-server architecture 。该架构拥有一个总是开机的主机，称为**服务器**，服务器服务于来自其他称为**客户端**的主机的**请求**。在该架构下，客户端之间不直接通信，而是通过服务器交换数据，每个服务器有一个固定且周知的地址，称为 **IP 地址**。一个服务器可能运行在单独的主机上，也可能是一个**虚拟服务器**，多个虚拟服务器运行在一台物理主机上，配备大量主机的**数据中心（data center）**通常用来创建这些虚拟服务器；
+ **P2P 架构**：point-to-point architecture 。该架构对位于数据中心中的服务器有最小或没有依赖。应用程序之间**直接通信**，这些应用程序所在的主机称为**对等方**。P2P 架构面临着安全性、性能和可靠性挑战；

#### 2.1.2 进程间的通信

对于操作系统而言，进行通信的实际上是**进程（process）**而不是程序，这些进程可能在单个操作系统上通信，也可能在多个端系统间通信。跨越计算机网络的进程通信交换的是**报文（message）**。

##### 客户端和服务器进程

网络应用程序由**成对**的进程组成，这些进程通过网络互相发送报文。通常将进程其中之一称为**客户（client）**，另一称为**服务器（server）**。在 Web 中，浏览器是客户，Web 服务器是服务器；在 P2P 中，下载方是客户，上传方是服务器。

+ **客户端**：**发起通信**的进程
+ **服务器**：在会话开始时**等待联系**的进程

##### 套接字

**套接字（socket）**是进程和计算机网络间的**接口（API）**，在因特网中即**应用层应用程序和运输层协议**间的接口。一个应用程序进程可能有一个或多个套接字。

一个端系统上的软件需要把报文推送到套接字，套接字假设两台端系统间存在运输的基础设施，即运输层的服务，通过该服务将报文传递到另一个端系统的套接字，再由套接字转交给应用程序解读。应用程序开发者可以控制套接字在应用层的部分，如：

+ 选择应用层协议
+ 设定部分运输层参数

##### 进程寻址

进程对间要想传输报文，就需要找到另一个进程的地址。该地址需要包含两种信息：

+ **主机的地址**：在因特网中，主机由其 **IP 地址**标识，这是一个32位（IPv4）或128位（IPv6）的值
+ **接收进程的标识符**：发送报文的进程需要指定接收主机上的**接收套接字**，目的地**端口号（port number）**用于指示应该接收报文的套接字。在 Web 中，发送和接收报文的套接字端口为80，而邮件服务器进程则使用25

#### 2.1.3 运输层向应用层提供的服务

套接字是应用层与运输层间的接口，运输层通过套接字向应用层提供**服务**。运输层主要提供下列服务：

+ 提供可靠数据传输服务：确保数据**正确**、**完整**的交付
+ 吞吐量保证：保证吞吐量（向接收进程交付比特的**速率**）
+ 传输时间保证：控制报文到达端系统的时间在一定范围内
+ 安全性保证：提供加密解密报文的服务

#### 2.1.4 因特网中运输层提供的服务

因特网的运输层为应用层提供一些服务，因此应用层开发者无需考虑这些问题。因特网运输层提供了两种协议：**TCP** 和 **UDP** 。

##### TCP

**TCP（Transmission Control Protocol，传输控制协议）** 协议的**服务模型**包含**面向连接**服务和**可靠数据传输**服务：

+ 面向连接的服务：在应用层数据报文开始流动前，TCP 会让客户端和服务器交换运输层控制信息，即**握手**，提醒两者为大量分组的到来做好准备。握手结束后，一个 **TCP 连接（TCP connection）**会在进程对的套接字之间建立。这条连接是**全双工**（连接双方可以**同时**进行报文转发）的。当报文转发结束后，该连接被关闭
+ 可靠数据传输服务：TCP 会无差错的、按适当顺序交付所有转发的分组，不会存在数据丢失和冗余。但是 TCP **不提供**加密服务

##### SSL

**SSL（Safe Sockets Layer，安全套接字层）**由网景公司研发，旨在解决不提供加密服务的 TCP/UDP 协议的安全问题。SSL 是 TCP 的加强版，提供**加密**、**数据完整性保证**、**端点鉴别**服务。使用 SSL 需要获取 SSL 证书。

SSL 协议加密报文过程：

1. 进程向 SSL 发送明文数据
2. SSL 加密数据，并传递给 TCP 套接字
3. TCP 套接字将密文传输到另一个端系统中进程的 TCP 套接字
4. TCP 套接字发送密文给 SSL，SSL 解密数据，向进程发送明文

##### UDP

**UDP（User Datagram Protocol，用户数据报协议）**是一种**不提供**不必要服务的轻量运输层协议，仅提供最小服务，**无连接**，提供不可靠数据传输服务。选择 UDP 协议的两个进程间**没有握手**。UDP 不保证数据能够到达，也不保证数据到达的顺序。UDP 不包含拥塞控制机制，可以以任何熟虑向其下层（网络层）注入数据。

##### 因特网中运输层不提供的服务

因特网运输层协议并没有提供吞吐量保证和传输时间保证，应用层应用程序开发者需要考虑这两个问题。

#### 2.1.5 应用层协议

**应用层协议（application-layer protocol）**定义了端系统之间如何传递报文，包括：

+ **报文类型**：如**请求**和**响应**两种类型
+ **报文语法**：如报文中各个字段应该如何描述
+ **字段语义**：字段中的**信息含义**
+ **报文规则**：何时发送报文，如何发送报文，以及如何响应报文

一些应用层协议由 RFC 文档定义，如 Web 所使用的 HTTP 协议。

### 2.2 Web 和 HTTP

**Web（World Wide Web）**，即**万维网**，是20世纪90年代兴起的新型应用，采用客户端-服务器架构。Web 按需操作、开放、使用简单。

#### 2.2.1 HTTP

**HTTP（Hype-Text Transform Protocol，超文本传输协议）**是 Web 的核心。HTTP 是一种**半双工协议**，即传输是双向的，但是不能是同时的，必须等到请求到达才能发送响应。HTTP 由两个程序实现：Web 客户端和 Web 服务器。

**Web 页面（Web page）**，也叫文档，由**超媒体对象**组成，包括 HTML 文件、图片、视频、程序等。HTML 通过 **URL（统一资源定位器）**标识其内部资源，URL 包括存放对象的**主机名**和对象在主机中的**路径名**，一个完整的 URL 如下：

```url
protocol://hostname[:port]/path[;parameters][?query]#fragment
```

HTTP 建立在 TCP 之上，在建立进程对之间的 TCP 连接后，HTTP 请求才会发起。客户端向服务器发送 HTTP 的过程大致为：

1. 客户端的套接字与服务器的套接字建立 TCP 连接
2. 客户端套接字通过该连接向服务器发送 HTTP 请求
3. 服务器套接字通过该连接向客户端发送 HTTP 响应

TCP 协议提供的服务向 HTTP 进行了数据完整性的保障，HTTP 不用担心数据丢失，也不用关注数据恢复的细节。

HTTP 是**无状态协议（stateless protocol）**，服务器只向客户端返回被请求的文件，而不存储用户状态。

#### 2.2.2 非持续连接和持续连接

如果每个请求/响应对是经过一个**单独**的 TCP 发起的，这种连接称为**非持续连接（non-persistent connection）**。如果所有请求/响应对经过**相同**的 TCP 发起，这种连接称为**持续连接（persistent connection）**。HTTP 既能使用前者也能使用后者。

##### 非持续连接的 HTTP

HTTP 1.0 协议采取非持续连接，假设有一个包含 10 张图片的 HTML 网页，在向该 HTML URL 进行请求时，将发生：

1. HTTP **客户端进程**通过80套接字端口发起一个到服务器进程套接字的 **TCP** 连接；
2. TCP 连接**建立后**，HTTP 客户端进程经过套接字发送一个 HTTP 请求报文，由服务器进程套接字接收；
3. HTTP **服务器进程**套接字将报文传递给服务器进程，服务器进程从其内存或外存中根据请求报文 URL 中引用的超媒体对象（HTML 文档）路径获取该对象，并将其**封装**在响应报文中；
4. HTTP 服务器进程通过套接字向客户端进程发送响应报文，并通知 TCP 连接在客户端完整接收报文后关闭该 TCP 连接；
5. HTTP 客户端进程**接收响应报文后**，**TCP 关闭连接**。响应报文指出报文实体体封装的是一个 HTML 文档对象。客户端进程将解析这个对象，并在其中得到 10 张图片的引用；
6. 客户端进程对每张图片建立一个**新的 TCP 连接**并发起 HTTP 请求，重复上述过程。

在非持续连接中，报文首部将包含一个 `Connection: close`首部行，代表 TCP 连接已经关闭。

###### RTT

为了评价非持续连接，需要引入**往返时间（RTT，Round-Trip Time）**，RTT 指的是一个短分组从客户端到服务再返回客户端所花费的时间。RTT 包括：

+ 处理时延
+ 排队时延
+ 传输时延
+ 传播时延

###### HTTP 的 TCP 三次握手

使用非持续连接的 HTTP 将经历**“三次握手”**过程：

+ 第一次握手：**客户端**向服务器发送一个小 **TCP 报文段**；
+ 第二次握手：**服务器**用一个小 **TCP 报文**段作为回应；
+ 第三次握手：**客户端**向服务器返回确认连接的报文。

前两次握手占用一个 RTT，最后的确认占用另一个 RTT 。HTTP 报文的发送包含在**第三次握手**中。总的响应时间两个 RTT 加上服务器内部时延（处理、排队、传输）和服务器到客户端的传播时延。

##### 持续连接的 HTTP

非持续连接的 HTTP 的缺点非常明显：

+ 每一个请求都需要建立一个 TCP 连接，这将导致服务器开销过大
+ 每一个请求都要经历两倍的 RTT 时延

HTTP 1.1 以及其升级版本 HTTP 2.0 协议采取持续连接。在使用持续连接的情况下，服务器在发送第一个 HTTP 响应报文后，TCP **保持**连接状态，后续的 HTTP 请求和响应报文都通过该连接发送。因此，一个或多个完整的 HTML 页面中的所有内容都可以通过一个 TCP 连接发送。

使用持续请求的 HTTP 将在报文首部行包括`Connection: keep-alive`，表示 TCP 持续开启。一般来说如果间隔一段时间仍未使用，服务器会关闭该 TCP 连接，此时响应报文的首部行将包含`Connection: close`。

#### 2.2.3 HTTP 报文格式

HTTP 规范由 RFC 1945、RFC 2616、RFC 7540规定，包含了对 HTTP 报文格式的规范。HTTP 包含两种类型的报文：**请求报文**和**响应报文**。

##### HTTP 请求报文

HTTP 请求包含一个**请求行（request line）**、一个或多个**首部行（header line）**、一个**空行**和**实体体（entity body）**。每个行使用一个空格和一个回车（**CRLF**，Carriage-Return Line-Feed）分隔。

+ 请求行：请求行包括三部分，**HTTP 请求方法**、**URL**、**HTTP 协议版本**，每个字段用空格分隔，最后加上 CRLF；
+ 首部行：首部行包括两部分，**首部名**字段和**首部值**，两者用冒号分隔，最后加上 CRLF；
+ 实体体：**实体体**包含要发送的数据，也称请求体，各种超媒体对象会被**编码并封装**在实体体中。

以下是一个 HTTP GET 请求报文：

```http
GET /hello.txt HTTP/1.1
User-Agent: curl/7.16.3 libcurl/7.16.3 OpenSSL/0.9.7l zlib/1.2.3
Host: www.example.com
Connection: keep-alive
Accept-Language: en, mi

```

**User-Agent** 首部行表示发送的客户端类型，**Connection** 表示 TCP 连接状态，**Host** 表示超媒体对象所在主机名，**Accept-Language** 表示请求的语言类型。

##### HTTP 响应报文

HTTP 响应包含一个**状态行（status line）**，以及一个或多个**首部行**、**空行**和**实体体**。状态行包括：

+ HTTP 协议
+ 响应状态码
+ 状态消息

以下是一个 HTTP GET 响应报文：

```http
HTTP/1.1 200 OK
Connection: keep-alive
Date: Mon, 27 Jul 2009 12:28:53 GMT
Server: Apache
Last-Modified: Wed, 22 Jul 2009 19:15:56 GMT
Content-Length: 51
Content-Type: text/html

<html><head><title>Hello</title></head><body></body></html>
```

**Date** 首部行表示服务器发送该报文的时间，**Server** 表示发送该报文的服务器进程类型，**Last-Modified** 指示超媒体对象创建或更改的最后时间，**Content-Length** 表示超媒体对象的字节数，**Content-Type** 表示实体体中的超媒体对象的类型，根据其值和实体体内容可以判断，报文封装的对象为 HTML 文档。

#### 2.2.4 客户端和服务器交互途径：cookie

HTTP 服务器**应该是无状态的**，这简化了 HTTP 服务器的设计。但是，有时服务器会希望鉴别用户身份，这是需要使用 **cookie** 技术。cookie 在 HTTP 之上建立了一个会话层。由于服务器可以从请求报文中获取客户端信息，并且 cookie 存在被窃取的风险，目前越来越多的 Web 项目逐渐开始使用其他技术取代 cookie 。

cookie 一般包含四个组件：

+ HTTP 响应报文包含一个或多个`Set-Cookie:`首部行，其值为 cookie 名称和值以及客户端存储 cookie 的路径，格式为`cookieName=cookieValue; path=/`，指示客户端存储 cookie
+ HTTP 请求报文包含一个`Cookie:`首部行，其值为 cookie 的字符串
+ 客户端系统保存的 cookie 文件，在浏览器中由浏览器管理
+ 服务器上的一个数据库系统，保存一些必要的用户信息，用来指示如何设置客户端 cookie

#### 2.2.5 Web 缓存

**Web 缓存（Web cache）**也叫**服务器代理（proxy server）**，这些服务器可能位于客户端本地（如 Web 本地缓存），也可能由 ISP（本地运营商和 VPN 提供方） 搭建。代理服务器位于客户端和实际服务器之间，分两种：

+ **正向代理服务器**：正向代理服务器用于代理客户端数据，代理服务器首先接收来自客户端的 HTTP 报文，将其进行处理后转发给真实服务器，接收来自真实服务器的响应报文，再发送给客户端。正向代理有隐藏客户端实际信息、绕过局域网限制的作用；
+ **反向代理服务器**：反向代理（reverse proxy）是针对真实服务器的代理，反向代理服务器接收来自客户端的请求，根据需求处理报文并决定转发。反向代理服务器具有负载均衡、攻击防范、最优节点选择的功能。

Web 缓存服务器一般是反向代理服务器。在客户端和真实服务器间存在反向代理服务器的情况下，一个客户端请求将进行如下处理：

1. **Web 浏览器**创建一个到反向代理服务器的 TCP 连接，成功后发送一个 HTTP 请求；
2. **代理服务器**截获该请求，并查看代理服务器的本地缓存是否有客户端请求对象副本。如果有，则封装该对象，向客户端返回响应报文；
3. 如果代理服务器没有缓存该对象，则向**真实服务器**发送客户端 HTTP 报文的副本，或使用其他协议发送一段数据，向真实服务器请求对象，并接收来自真实服务器的响应数据，处理后或直接转发给客户端。
4. 代理服务器缓存来自真实服务器的未缓存对象，准备响应下一次客户端请求

反向代理服务器可以大大减少客户端请求的响应时间，减少一个机构到互联网的通信量。有时安装 Web 缓存服务器可能比升级链路更加经济。

##### 内容分发网络

**CDN（Content Delivery Network，内容分发网络）**是部署在互联网边缘服务器上的虚拟网络，实现负载均衡、内容分发、通信调度功能，让用户能够就近获取需要的数据。本质上 CDN 是一种正向代理与反向代理结合的 Web 缓存器。

#### 2.2.6 条件 GET 方法

Web 缓存器中存放的缓存对象可能并不是最新的，HTTP 通过**条件 GET** 提供验证缓存对象有效性的机制。该机制运作过程如下：

1. **Web 浏览器**向 Web 缓存器发送一个带有`Last-Modified: 时间`首部行的请求报文；
2. **Web 缓存器**检查是否缓存了该对象，如果缓存，缓存器向真实服务器发送一个带有`If-modified-since: 时间`首部行的请求报文；
3. **Web 服务器**根据`If-modified-since:`首部行的值判断是否需要向 Web 缓存器发送最新的超媒体对象。如果需要则发送包含该对象的响应报文，如果不需要，Web 服务器向缓存器返回一个状态为 **304 Not Modified** 的响应。

### 2.3 因特网中的电子邮件

因特网中的**电子邮件服务**通常由三个主要部分组成：

+ **用户代理（user-agent）**
+ **邮件服务器（mail server）**
+ **简单邮件传输协议（Simple Mail Transfer Protocol，SMTP）**

一个典型的邮件发送过程如下：

1. 发送方用户代理将邮件发送至发送方邮件服务器
2. 发送方邮件服务器将邮件发送至接收方邮件服务器
3. 接收方邮件服务器将邮件发送至接收方用户代理

有时收发的邮件服务器双方可能无法正常发送邮件，比如接收方邮件服务器宕机，此时发送方邮件服务器会将邮件报文加入一个**报文队列（message queue）**，在一定时间内保存报文并定时尝试发送。

#### 2.3.1 SMTP

简单邮件传输协议 SMTP 是**用户代理与邮件服务器、邮件服务器间**相互通信的协议。SMTP 服务使用者有两方：发送邮件的邮件服务器和接收邮件的邮件服务器。该协议由 RFC 5321 定义。

SMTP 对报文体有一定限制，要求体部分只能由 7 比特 **ASCII** 码组成。SMTP 操作过程基本如下：

1. **发送方用户代理**发送报文至发送方服务器，并提供接收方**邮件地址**，双方也使用 SMTP 交流
2. **发送方服务器**接收报文，将报文放入报文队列；当需要发送报文时，发送方服务器建立一条到接收方服务器的 **TCP 连接**
3. **接收方服务器**与发送方服务器进行 **SMTP 握手**，成功后通过 TCP 连接传输报文
4. **接收方用户代理**接收来自接收方服务器发送的报文

SMTP 一般**不使用**中间服务器发送邮件。发送方服务器和接收方服务器一般是直接连接的，即邮件报文不会在中间服务器中保留。

##### 持续连接

SMTP 采用**持续连接**，TCP 连接通过**套接字端口 25** 建立，收发方服务器建立连接后可以传输多条报文，直到发送方指示关闭连接。

##### SMTP 握手

在传输报文前双方服务器将进行 **SMTP 握手**：

1. 客户端（发送方服务器）与服务器（接收方服务器）建立 TCP 连接，服务器返回 SMTP 状态码和服务器主机名
2. 客户端向服务器发送一条 HELO 命令，并提供客户端主机名
3. 服务器返回 SMTP 状态码和响应报文
4. 客户端发送一条 MAIL FROM 命令并提供发送方邮件地址
5. 服务器检查邮件地址，无错误则返回状态码和检查结果
6. 客户端发送一条 RCPT TO 命令并提供接收方邮件地址
7. 服务器检查邮件地址，无错误则返回状态码和检查结果

SMTP 握手结束后，客户端就开始传出右键内容。对应的 TCP 握手和 HTTP 一样也是三次：客户端请求连接、服务器返回确认、客户端返回确认。

##### SMTP 过程演示

下方演示一个 SMTP 报文传输过程，其中的字符串是客户端与服务端交给 TCP 套接字的行：

```SMTP
S: 220 hamburger.edu
C: HELO crepes.fr
S: 250 Hello crepes.fr, pleased to meet you
C: MAIL FROM: <alice@crepes.fr>
S: 250 alice@crepes.fr... Sender ok
C: RCPT TO: <bob@hamburger.edu>
S: 250 bob@hamburger.edu... Recipient ok
C: DATA
S: 354 Enter rnail, end with "." on a line by itself
C: Do you like ketchup?
C: How about pickles?
C:.
S: 250 Message accepted for delivery
C: QUIT
S: 221 hamburger.edu closing connection
```

客户端总共向服务端发送了 6 种 SMTP 握手协议命令：

+ HELO：第一次握手
+ MAIL FROM：邮件来源
+ RCPT TO：接收地址
+ DATA：表示正文开始
+ CRLF.CRLF：表示正文结束
+ QUIT：传输完毕，关闭连接

QUIT 命令只有在所有右键发送完毕后才会发出。每条右键从 MAIL FROM 开始至 CRLF.CRLF 结束，新的邮件再次才能从 MAIL 开始。

#### 2.3.2 与 HTTP 的区别

SMTP 是一个**推协议（push protocol）**，客户端从服务端拉取需要的数据，并由想要获得数据的端系统（即客户端）发起 TCP 连接；而 HTTP 是一个**拉协议（pull protocol）**，客户端将数据推向服务端，TCP 由将要推送数据的端系统（即客户端）发起。

SMTP 要求每个报文采用 7 比特的 ASCII 码格式，而 HTTP 对报文内容编码没有限制。

对于包含多种媒体类型的报文，HTTP 把所有媒体对象都封装在响应报文实体体中，而 SMTP 把所有对象封装在一个报文中（没有响应和请求之分）。

#### 2.3.3 邮件报文格式

邮件的报文格式由 RFC 5322 定义。右键首部行和报文体部分用一个空行分隔。首部行**必须包含**`From: <发送地址>`和`To: <接收地址>`，可以包含`Subject: <信息主题>`。

```SMTP
From: alice@crepes.fr
To: bob@hamburger.edu
Subject: Searching for the meaning of life.
```

#### 2.3.4 邮件访问协议

SMTP 是用来发送邮件的协议，要想从端系统访问服务器上的右键，则需要使用邮件访问协议，流行的邮件访问协议有：

+ **第三版邮局协议 POP3**
+ **因特网邮件访问协议 IMAP**
+ **超文本传输协议 HTTP**

##### POP3

**POP3**协议非常简单。当客户端与服务器之间的 TCP 连接在**套接字端口 110** 上建立之后，POP3 就可以提供服务。POP3 包括三个阶段：

1. **授权（authorization）**阶段：客户端提供用户名和密码
2. **事务处理**阶段：客户端可以将邮件标记为删除、解除标记、获取邮件内容和相关统计信息
3. **更新**阶段：发生在客户端发出退出请求后，根据标记更新邮件列表

POP3 服务的回答有两种：成功时的`+OK`和错误时的`-ERR`。授权阶段可以使用两个命令：`user <user name>`和`pass <password>`。授权阶段结束后进入事务处理阶段，可以使用`list`命令拉取邮件列表，使用`retr`命令获取列表中对应序号的邮件报文内容，使用`dele`将一个邮件标记为删除。更新阶段发生在客户端发出`quit`命令后，此时 POP3 服务器会根据标记操作邮件列表。

POP3 的主要问题是过于简单，并且一般只有下载后删除和下载并保留方式，前者使得一份邮件不能在多个端系统中被多次访问，而后者一次也只能下载全部邮件内容，不能访问部分信息如只获得邮件标题。

POP3 服务器只会保存一些会话中的状态信息，如删除标记，而不会保存用户的其他信息。

##### IMAP

**因特网邮件访问协议**比 POP3 复杂得多，一个 IMAP 服务器会将每个报文与一个文件夹关联起来，如第一次进入邮箱的邮件会进入`INBOX`文件夹。与 POP3 不同，IMAP 还会维护用户访问状态，如读取过的邮件会被转移到其他文件夹中。此外，通过 IMAP 可以获取报文的一部分片段。

##### HTTP

使用 **HTTP** 时客户端进程就是浏览器，用户通过浏览器访问和管理邮件，并指示服务器通过 SMTP 协议发送邮件。

### 2.4 DNS：因特网的目录服务

域名是对人类友好的一种因特网标识符。域名由**顶级域名（TLD）**、**二级域名（SLD）**和**主机名（host name，或称三级域名）**组成。以`www.amazon.com`为例：

+ `www`：主机名
+ `amazon`：二级域名
+ `com`：顶级域名

一个完整的域名只需要包括二级域名和顶级域名，称为**域（Domain）**，而同时包括了主机名的域名被称为**完全限定域名（FQDN）**，也可以被称为完整的**主机名（hostname）**。每个 FQDN 可能会获得一个独一无二的 IP 地址，也可能会被分配一个局域网地址，由局域网进行转发，但是每个包含二级域名和顶级域名的域名都会有一个 IP 地址。

对于链路层以下的路由器来说，域名对它们是不友好的，因为域名没有固定的严格格式，路由器需要使用 **IP 地址**在互联网中寻址。为了能够让域名和 IP 地址互相转换，就需要使用到 DNS 。

#### 2.4.1 DNS 提供的服务

**DNS（域名系统）**的**主要任务**就是提供一种把域名转换成 IP 地址的目录服务。DNS 是一个由 **DNS 服务器**实现的**分布式数据库**，也是一种让因特网中各存在点能够进行查询分布式数据库的**协议**。DNS 基于 **UDP**，使用套接字端口 53。DNS 不直接与用户打交道，而是为因特网上的其他进程提供服务。

DNS 通常由其他应用层协议使用，如 HTTP、SMTP、FTP。客户端进程在建立基于域名的连接前总是先请求 DNS 服务器。当 HTTP 通过一个 URL 请求一个资源时，会发生以下事情：

1. 浏览器将域名发送给本机上的 DNS 客户端进程
2. **DNS 客户端**从 URL 中提取域名部分，并将域名转发给 DNS 服务器
3. **DNS 服务器**接收到客户端请求，根据域名找到对应的 IP 地址，并封装在响应报文中返回给客户端
4. DNS 客户端接收到响应报文并取得 IP 地址，并将 IP 地址转发给浏览器
5. 浏览器将 IP 提交给套接字，由套接字发起到服务器的 TCP 连接并传输 HTTP 报文

DNS 会给 HTTP 以及其他应用层协议的传输带来额外的时延，因此客户端想要获取的 IP 地址一般会在就近的 DNS 服务器中缓存。除了域名转换，DNS 还提供以下服务：

+ 主机别名（host aliasing）：有时一台主机可能有多个域名，主要域名被称为**规范主机名**。DNS 需要提供别名对应的规范主机名以及其对应的 IP 地址
+ 邮件服务器别名：和主机别名一样，DNS 服务器需要提供别名对应的主要名称和 IP 地址
+ 负载均衡（Load Balance）：也称负载分配（Load Distribution）。如果一个服务器要负责世界范围内的所有请求，那这个服务器应该会有非常大的缓存队列和处理能力。因此实际上因特网中的服务器会存在冗余，即多个服务器负责维护和转发同样的资源。一般来说 DNS 服务器中有一张这些冗余服务器的列表，在获取处理请求时从列表中循环取出冗余服务器的 IP 地址，或者根据某些规则选择，从而分担每个服务器的负担，实现负载均衡

#### 2.4.2 DNS 工作机理

用户端系统上有许多客户端进程，这些进程为了通过域名发送报文就需要使用 DNS 客户端向 DNS 服务端请求域名对应的 IP。所有 DNS 请求和响应都通过**套接字端口 53** 发送，经 **UDP 协议**传输。

最简单的 DNS 服务器设计是在整个互联网上只部署一台服务器，由该服务器处理所有 DNS 请求。这明显是不现实的，因为：

+ 单点故障：一旦该服务器宕机，整个因特网都将崩溃
+ 通信容量：一台 DNS 服务器无法同时处理所有请求
+ 远距离的集中式服务器：世界各地的端系统都要使用同一个服务器查询数据库，时延不可接受
+ 维护：每当有新的 IP 和域名出现，集中式数据库就要进行扩展

因此，实现中的 DNS 服务器都是分布式的。为了确认在不可靠的 IP 协议上进行的 IP 查询是否正确，DNS 会使用另一个可靠的网络层协议 ICMP 来确认是否有查询错误。

##### 分布式分层数据库

没有一台 DNS 服务器拥有世界上所有的域名和 IP 映射，DNS 服务器实际上是分层且分布的。大致来说，因特网中有三层 DNS 服务器：

+ **根 DNS 服务器**：目前大致有 400 多个根服务器分布于全球，根服务器是本地 DNS 客户端首先访问的 DNS 服务器，根服务器会根据客户端提供的域名中的**顶级域名**查找出负责顶级域名查找的顶级域服务器的 IP 地址
+ **顶级域 DNS 服务器**：顶级域服务器则是根据客户端提供的域名的**二级域名**部分查找出负责的权威服务器
+ **权威 DNS 服务器**：之所以称为“权威”，是因为这类 DNS 服务器通常由一些持有域名的组织所管理，这些组织还拥有其他的完全限定域名，因此由这些组织提供权威服务器来查找 FQDN 对应的 IP 地址

在这三层结构之外还有一个**本地 DNS 服务器**。一般来说每个 ISP 都有一台或多台本地 DNS 服务器。当客户端与 ISP 连接时，会首先与 ISP 的一台主机连接，该主机上保存有 ISP 的一台或多台 DNS 服务器的 IP，该主机会通过 DHCP 服务器选择适合的 DNS 服务器。对于一个机构的 ISP 来说，DNS 服务器和客户端可能就在一个局域网中，对于地区 ISP 来说，客户端和 DNS 服务器间可能也就隔了几台路由器。

假设现在有两台端系统要通过双方的域名建立端到端的 TCP 连接，在建立 TCP 之间，发起连接的一端的套接字需要知道另一端的 IP 地址，因此需要先通过 DNS 服务器获取 IP ：

1. 首先，客户端的 **DNS 应用**进程会向本地 DNS 服务器发起请求，查询域名的 IP 地址
2. **本地 DNS 服务器**接收请求，并与根 DNS 服务器建立**连接**
3. **根 DNS 服务器**根据域名中的**顶级域名**确定了顶级域 DNS 的 IP，并将其返回给本地 DNS 服务器，本地 DNS 与顶级域 DNS 建立**连接**
4. **顶级域 DNS 服务器**根据域名中的**二级域名**确定了权威 DNS 的 IP，并将其返回给本地 DNS 服务器，本地 DNS 服务器再与权威 DNS **连接**
5. **权威 DNS 服务器**根据 **FQDN** 确定了服务端的 IP 地址，并将其**返回**给本地 DNS
6. **本地 DNS 服务器**将服务器的 IP 返回给客户端
7. 客户端根据服务器 IP 建立一条到服务器的 TCP 连接

整个过程中，客户端**只和本地 DNS 服务器进行了通信**，并从本地 DNS 的回答报文中并获取了查询域名的 IP，在这之后与服务器建立连接，多层 DNS 服务器中间的通信客户端是不知道的。本地 DNS 客户端从本地 DNS 服务器获得的回答报文内容只含有本地 DNS 服务器获取的回答，一般只包括 A、AAAA、CNAME、MX。如果本地 DNS 服务器绕过了根和顶级域 DNS 服务器，可能会向客户端返回权威 DNS 的信息，类型 NS。

客户端查找本地 DNS 服务器的 IP 地址的过程是一种**递归查询**，没有经过其他中间 DNS；而各层 DNS 间的查询是**迭代查询**，经过了多层 DNS 服务器。

##### DNS 服务器缓存

由于 DNS 间的查询是迭代的，查询链越长产生的时延将会越大，因此 DNS 服务器中还有很重要的一环：**DNS 缓存**。如果查询链中某一层 DNS 服务器缓存了整个域名指向的 IP 地址，它就会直接将该 IP 地址返回，而不用继续迭代。缓存不是永久的，DNS 服务器通常会在两天之后清除缓存信息。通过 DNS 缓存，本地 DNS 就可以绕过其他层的 DNS ，快速查找到 IP 地址。

#### 2.4.3 DNS 记录和报文

实现了 DNS 分布式数据库的 DNS 会保存**资源记录（Resource Record，RR）**，RR 提供了域名和 IP 的映射。RR 是包含以下信息的四元组：

+ Name：主机名、域名、规范主机名或邮件规范主机名，由 Type 决定
+ Value：某个主机的 IP 地址
+ Type：指示信息类型
+ TTL：记录生存时间，指示缓存信息应该存在多久

Type 会有以下几种类型：

| Type  |       Name       |          Value          |
| :---: | :--------------: | :---------------------: |
|   A   |      主机名      |    主机名对应的 IPv4    |
| AAAA  |      主机名      |    主机名对应的 IPv6    |
|  NS   |       域名       | 权威 DNS 服务器的主机名 |
| CNAME |     主机别名     |       规范主机名        |
|  MX   | 邮件服务器主机名 | 邮件服务器的规范主机名  |

##### DNS 报文格式

DNS 只有两种报文类型：**查询（query）**和**回答（answer）**，并且两种报文使用同一种格式（查询报文没有回答字段）。

DNS 头部：

+ **标识符**：16 比特的标识符，每一个查询-回答报文对的标识符是相同的
+ **标志位（flags）**：标志位可以有多个标志，总长度为 16 位，按照顺序分别为：
  1. 1 比特标志位，查询报文为 0 ，回答报文为 1
  2. 1 比特标志位，如果 DNS 是请求的主机名的权威服务器，该标志位为 1
  3. 1 比特标志位，当客户端希望进行递归查询时为 1
  4. 1比特标志位，如果服务器能够递归查询为 1
+ 问题数：所有查询数量，16 位
+ 回答 RR 数：16 位
+ 权威 RR 数：16 位
+ 附加 RR 数：16 位

DNS **问题区域**：报文该部分包含了正在查询的问题信息，包括：

+ Name 字段：正在被查询的主机名
+ Type 字段：查询类型，如 A

DNS **回答区域**：该区域包含：

+ Name 字段：被查询的主机名
+ Type 字段：查询类型
+ Value 字段：IP 地址

DNS **权威区域**：包含权威服务器的一些信息。

DNS **附加区域**：包含其他有帮助的记录。

##### nslookup

在 Linux 和 Windows 中有一个命令行软件 **nslookup**，nslookup 会查询给定主机名的 IP 地址，并将查询结果以对人友好的格式打印。

```shell
nslookup www.baidu.com
nslookup -type=MX www.baidu.com
```

##### ipconfig

命令行软件 **ipconfig** 可以查看本地 IP 相关的配置信息。

```sh
ipconfig/all
ipconfig/displaydns
ipconfig/flushdns
```

##### 向 DNS 数据库插入数据

如果要将自己的域名和 IP 地址插入 DNS 数据库，第一件事就是向**注册登记机构（registrar）**注册域名。这些机构是一些商业实体，负责验证域名的唯一性。

等级域名时，需要提供注册的域名的**基本和辅助权威 DNS 服务器的名字和 IP 地址**，注册机构会确保一个类型为 NS（域名）的 RR 与一个类型为 A（主机名）的 RR 被加入到 TLD DNS 服务器的数据库中。

由于一个域名下有多个主机名，还需要确保这些**主机名的 RR 被加入到权威 DNS 服务器的数据库中**，注册机构只负责处理 TLD DNS 事务，这些事务需要注册人完成。

一旦完成这些步骤，用户就可以通过域名访问注册人的网站或者电子邮件服务了。

##### DNS 安全

DNS 也会被攻击。**DDoS 的带宽洪泛攻击**可能会导致 DNS 接收过多的请求而难以正常运作，不过一般来说，根 DNS 受此类攻击影响较小，因为根服务器会受到下级分组交换机过滤器的保护，此外一些 DNS 缓存也会绕过根 DNS 服务器。

**中间人攻击**是另外一种攻击方式，中间人通过截获报文，伪造报文内容，向客户端发送伪造的 IP 地址。**DNS 毒害攻击**则向 DNS 服务器发送伪造的报文，使得 DNS 服务器缓存了伪造的 RR 。这两种 DNS 劫持都会导致客户端的错误重定向。

### 2.5 P2P 文件分发

**P2P（point-to-point）**是一种对中心服务器没有依赖或只有最小依赖的文件分发架构。和客户端-服务器架构不同，P2P 中的对等方是**由用户控制的机器**。一个简单的 P2P 架构实现会和客户端-服务器架构类似，即由单一服务器向大量客户端主机发送文件。而实际上的 P2P 架构允许每一个对等方向其他任何对等方**重新**发送它们已经接收的文件的**任何部分**。P2P 架构具有很强的**自扩展性**，任何用户机器都可以成为其中的一员。

#### BitTorrent

**BitTorrent（比特洪流）**是目前最为流行的 P2P 文件分发协议。BitTorrent 中参与**一个特定文件**的分发的所有对等方**集合**被称为一个**洪流（torrent）**，在一个洪流中的对等方下载的文件整体或部分被称为一个文件**块（chunk）**。每个对等方在下载完文件后，可以选择离开洪流或留在洪流中向其他对等方分发文件，因此这种鼓励交换的机制也被称为“一报换一报（tit-for-tat）”。

BitTorrent 是一个非常复杂的协议，但也基于一些基本的机制运行。每个文件的洪流都有一个**基础设施节点**，称为**追踪器（tracker）**。每当一个对等方加入洪流，就会向追踪器**注册**自己。当一个新的节点加入洪流时，追踪器会随机地从对等方集合中选取一些节点的 IP 地址发送给新的对等方，新的对等方则根据这些 IP 地址尝试向其他对等方建立 **TCP 连接**并下载文件。基础设施节点是洪流存在的前提，如果该节点离开互联网，整个洪流都会断开，因此每个洪流可能有**多个**追踪器存在，有时这些追踪器可能位于某台专注于提供 BitTorrent 服务的服务器上，这些服务器将保证洪流的运作。

BitTorrent 中还有一种被称为**最稀缺优先（rarest first）**的技术，在对等方请求一个文件的分发时，协议会选择该文件中在整个洪流中最稀缺的**块**，并优先进行传输，使得整个洪流中最稀缺的块更为迅速的重新分发。

**疏通（unchoked）**是另一项技术，当文件请求方向其他节点进行块请求时，那些对于请求节点来说具有**最大传输速率**的节点有最大优先权。这使得整个洪流中的对等方能以最快的速度分发完内容，而不会使得洪流堵塞。

### 2.6 流媒体和内容分发网络

#### 2.6.1 HTTP 流

**HTTP 流**的主要服务对象是因特网中的视频文件。每一个视频在 HTTP 服务器中只是一个简单的视频资源文件，当客户端请求该文件时，服务器就将视频封装在一个响应报文中返回给客户端。客户端通过类似流的处理方式，一旦响应报文的一部分到达就将其**缓存**，当缓存数量到达规定大小时，就对视频的帧进行解码，并在客户端中播放，因此客户端可以在没有接收到整个文件时就播放视频内容。

#### 2.6.2 DASH

简单的 HTTP 流有一个**重大缺陷**：所有用户在不同时间只能请求相同编码的视频文件。为了应对不同的客户端和带宽情况，**经 HTTP 的动态适应性流（Dynamic Adaptive Streaming over HTTP）**，也称 **DASH**，将一个视频分为不同编码的版本，这些版本将具有不同的**比特率**。当带宽较高时，向客户端发送高比特率的视频**块**，反之发送低比特率的视频块。

#### 2.6.3 CDN

对于提供流媒体访问服务的服务器来说，要在同一时间处理来自世界各地的 HTTP 请求的压力是巨大的，且面临着时延和单点故障等问题。现在，几乎所有流媒体内容提供商都使用**内容分发网络（Content Distribution Network，CDN）**。CDN 既可以是由内容提供商自己提供的**私有 CDN**，也可以是由第三方提供的**第三方 CDN**。

##### CDN 操作过程

CDN 基于 **DNS** 协议进行内容动态分发。当用户请求一个由 CDN 负责的资源时，会发生以下事情：

1. HTTP （或其他协议）**客户端**请求一个资源，并向其本地 DNS 服务器发送一个主机名查询报文，本地 DNS 服务器向权威 DNS 服务器查询 IP 地址
2. **权威 DNS**注意到这是一条资源请求，需要将其转交给某个 CDN 提供方。权威 DNS 根据找到了最适合承担分发的 CDN 服务器的**主机名**，并将其返回给本地 DNS
3. 本地 DNS 收到该主机名，并查询该 CDN 服务器主机名的 IP 地址，然后返回给客户端
4. 客户端根据该 IP 地址向 CDN 服务器请求资源

##### 集群选择策略

权威 DNS 在选择适合的 CDN 提供方服务器时会根据**集群选择策略（cluster selection strategy）**选择需要的 CDN。这种策略可能会根据客户端 IP 地址选择地理上**最接近**的 CDN，也可能会进行**流量控制**，选择压力较小的 CDN。

---

## 第三章 运输层

### 3.1 概述

运输层提供**端到端**的**逻辑通信（logical communication）**服务。所谓逻辑是指运输层能使两台端系统上的应用进程**看起来**像在进行直接的通信。实际上，两台端系统的通信经过了许多分组交换机，并由多条链路**物理（实际）连接**。

因此，运输层协议的**实现**是在端系统而不是路由器中的。应用层协议会将分组（称为报文）交给运输层封装成**报文段（segment）**，运输层再将报文段交给网络层封装为数据报。在因特网中有两种重要的运输层协议：**UDP** 和 **TCP**。

#### 运输层与网络层的关系

运输层提供**进程之间**的通信，即端到端；而网络层提供**主机之间**的通信，即点到点。运输层能够提供的服务通常受限于网络层的服务模型，但可以在网络层服务模型之上进行扩展，如 TCP 和 UDP 对网络层 IP 协议的扩展。

**因特网协议（Internet Protocol，IP）**提供的是一种**尽力交付**服务，不做任何形式的担保。IP 不确保报文段一定会被交付，不保证报文段按序交付，也不保证报文段数据完整性。因此 IP 被称为**不可靠服务**。因此运输层协议会对 IP 协议做扩展，在一定程度上保证报文段传输的可靠性。

#### 运输层协议的基本任务

运输层协议的**最基本职责**是，将主机间的分组交付扩展为进程间的分组交付。IP 协议交付的分组无法被应用层进程直接接受，因此运输层协议要负责**拆封**数据报内容，并递交给应用层进程。这一过程称为运输层的**多路复用（transport-layer multiplexing）**和**多路分解（demultiplexing）**。

与 IP 一样，UDP 也是一种不可靠服务，仅提供上述两种基本服务。而 TCP 停供更多附加服务，如可靠数据传输服务和拥塞控制。

### 3.2 多路复用和多路分解

运输层不将报文段中有效载荷的报文部分直接交给应用层进程，而是通过**套接字**进行转交。在发送源端，运输层协议从不同的套接字中接收数据，并将数据封装在报文段中并附加头部信息，然后将报文段递交给网络层，这一过程称为**多路复用**。在接收端，运输层协议将网络层递交的报文段分解，取出其中的报文部分，并根据首部信息将其递交给正确的套接字的过程，称为**多路分解**。

#### 套接字端口

运输层要识别正确的套接字，每个套接字就需要有一个**唯一标识符**，而**报文段的首部**需要包含这些标识符信息，TCP 和 UDP 报文都会包含一个**源端口字段**和**目的地端口字段**。

**端口号**是套接字唯一标识符的一部分，是一个 16 比特的数字，大小在 0 ~ 65535 之间。0 ~ 1023 间的端口号被称为**周知端口号**，这些端口号被预留给周知的应用层协议如 HTTP、FTP 等。主机上的每一个套接字都将分配到一个端口号。

#### NMAP

要监听一个位于因特网中的主机开放了哪些端口是非常容易的事情，[NMAP](https://nmap.org)是一种**端口扫描器**，可以扫描指定因特网主机上的所有端口。因此，主机的端口防护变得十分重要，如果某一套机字连接的应用程序存在缺陷，蠕虫和病毒就很容易击溃这些应用并带来更大的安全问题。

#### UDP 数据报和套接字标识符

一个 UDP 套接字的标识符由**目的地 IP 地址**和**目的地端口号**进行唯一标识。如果两个数据报的头部包含同样的标识符，就会被分解到同一个套接字。

由于套接字并没有将源端口号作为标识符的一部分，接收响应时 UDP 协议无法通过套接字标识知道应该将响应分解到哪。因此，UDP 会在发送的请求数据报的头部中包含**源端口号**信息，发送方将在响应中保留该字段，接收方在接收响应时可以得知应该把信息分解到哪个套接字上。

#### TCP 报文段和套接字标识符

TCP 套接字的标识符包含**源 IP 地址**、**源端口**、**目的地 IP 地址**和**目的地端口**。只有当四个部分完全相同时，不同的报文段才会被分解到同一套接字。

#### Web 与 TCP

Web 的基础协议 HTTP 建立在 TCP 服务模型上。当 HTTP 服务端发送请求时，会告知自己的套接字其目的地端口号（默认 80）随后，套接字会通知 TCP 建立一个到 HTTP 服务器的连接。第一次握手时，HTTP 服务器主机上的套接字会为客户端分配一个套接字端口，随后连接将在两台主机间建立。由于服务器上的套接字一次只能处理一个连接，同一台客户端发起的多个 HTTP 请求都将在服务器上分配到不同的端口，具有不同的套接字标识符。

因此，非持续连接的 HTTP 将面临严重的**性能问题**，客户端上的每个 HTTP 请求都将打开一个 TCP 连接并申请套接字。而在持续连接的 HTTP 下，客户端可以通过同一个 TCP 发送请求，减少了套接字的分配。

事实上，现在的 Web 服务器不再为每个连接建立一个进程，客户端到服务器的通讯实际上是**进程到线程**，甚至是**进程到协程**的通信。目前的高性能 Web 服务器应用通常只使用单个进程，而为每个用户申请一个线程；而单线程的 Web 服务器应用则会为每个连接创建一个协程，异步地处理这些请求。

### 3.3 UDP

**用户数据报协议（UDP）**是一种不提供不要服务的最简化运输层协议，事实上 UDP 将其运输的分组称为**数据报（datagram）**而不是报文段。UDP 除了提供少量差错检测和多路复用与分解外并没有在 IP 协议之上增加其他服务。与需要进行可靠数据传输保证的 TCP 不同，UDP 不进行握手，不维护连接状态，因此是一种**无连接**协议。UDP 将应用层报文封装后就立即递交给网络层发送，而不做其他任何事情。如：基于 UDP 的 DNS 协议如果没有收到响应，就会告知应用层进程不能获得响应，或者向另一个 DNS 发送请求。

UDP 相较于 TCP 有几个优势：

+ 更为精简和迅速：UDP 会将应用程序递交的数据直接封装并发送，而 TCP 需要进行可靠传输，并进行拥塞控制，但不注意实际交付究竟需要多少时间，这会导致过多的时延。一些能够容忍数据丢失的实时应用会选择 UDP 协议来减少时延快速；
+ 无须建立连接：UDP 不需要维护连接状态和握手，因此不像 TCP 一样有握手的三次 RTT 。HTTP 之所以使用 TCP，是因为 HTML 文本内容的可靠性非常重要。而新的 HTTP3/QUIC 协议则基于 UDP ，因此具有更快的响应速度，可靠性和其他服务则由该协议自己提供；
+ 无连接状态：TCP 为了维护连接可靠性需要保留一些连接状态信息，如接受和发送缓存、拥塞控制参数等，这些信息会被存储在服务器上。而 UDP 不需要这些状态，一般可以支持更多活跃的用户；
+ 分组首部开销小：UDP 只有 8 字节的首部大小，而 TCP 有 20 字节。

能容忍少量分组的丢失的应用，如因特网电话、视频会议等会选择 UDP 协议，因为 TCP 的拥塞控制会导致这些应用的性能变差。但正是 UDP 没有拥塞控制，可能会因为在同一时间使用最大传输速率传输大量数据，而导致路由器**分组溢出**，继而产生丢包，严重情况下甚至可能挤垮其他的 TCP 通信。因此，现在的 UDP 连接源即服务器可能会采取一些动态的自适应拥塞控制。

#### UDP 数据报结构

UDP 的数据报结构非常简单，头部仅包含四个部分：

+ **源端口号**（source port）：16 bits
+ **目的地端口号**（destination port）：16 bits
+ **长度**（length）：首部加上有效载荷数据的长度：16 bits
+ **校验和**（checksum）：校验和是用来检测数据报正确性的重要指标：16 bits

而 UDP 的**有效载荷（UDP payload）**则封装了应用层的报文，最大有效长度为 508 字节。

#### 校验和

校验和使得 UDP 能够进行**差错检测**。这种检验是针对**比特位**的。每个 UDP 数据报的校验和是将数据报中所有的 **16 比特字**进行**按位和**之后**按位非**的结果。如果按位和的过程中出现位数溢出，则溢出位**回卷**（加到第一位上）。如果一则 UDP 报文没有出现差错，其所有的 16 位字相加的结果应该是 `0xFFFF`，即 16 位的`1111111111111111`，如果出现 0 ，即说明数据报内容出现差错。

假设一个 UDP 数据报包含下列三个 16 位的字：
$$
0110011001100000\\
0101010101010101\\
1000111100001100\\
$$
前两个 16 位字的和为：
$$
0110011001100000\\
0101010101010101\\
————————\\
1011101110110101
$$
与第三个 16 位字按位和时出现溢出，进行回卷，结果为**校验和**：
$$
1011101110110101\\
1000111100001100\\
————————\\
0100101011000010
$$
如果数据报没有出错，该校验和与数据报中所有 16 位字的按位和结果应该是`0xFFFF`。

UDP 能检测差错，但是不能恢复差错结果。在遇到差错时，UDP 或是丢弃数据报，或是向应用层发出警告。

### 3.4 TCP

#### TCP 连接

TCP 是一种**面向连接（connection-oriented）**的可靠运输层传输协议，负责端系统间的逻辑连接，在两个进程建立连接前，必须进行**握手**。在握手阶段，两个端系统会交换一些**预备报文段**，以建立保证数据传输的**参数**，并初始化与连接相关的 TCP **状态变量**。

TCP 只运行在端系统上，并维护连接的状态，因此中间的网络元素不会维护任何 TCP 状态，它们看到的只有数据报，而非连接。TCP 是一种**全双工服务（full-duplex service）**，即传输是双向和同时的。TCP 也是**点对点**的，即是单个发送方和单个接收方之间的连接，如果要进行一个发送方向多个接收方的连接（即“多播”），TCP 是做不到的。在 TCP 中发起连接的进程被称为**客户进程**，而另一个进程被称为**服务器进程**。

在正式传输数据前，TCP 会进行三次握手：

1. 客户端发送一个特殊的 TCP 报文段，不包含有效载荷
2. 服务器接收客户端报文段，返回一个特殊 TCP 报文段作为响应，不包含有效载荷
3. 客户端返回一个特殊 TCP 报文段作为响应，可以包含有效载荷

应用层进程传输的报文在通过套接字后就交由运输层控制，被送入 TCP 的**发送缓存（send buffer）**中，这一过程在握手阶段进行。在传输过程中，TCP 会在方便发送时从发送缓存中取出**一小块**数据并递交到网络层。之所以要分解报文，是因为 TCP 载荷部分受到**最大报文段长度（maximum segment size，MSS）**的限制，MSS 通常由最大的链路层**帧**长度，即**最大传输单元（maximum transmission unit，MTU）**决定。MSS 指的其实是报文段中**有效载荷**的最大长度，一般来说 TCP 首部长度为 40 字节，而链路层 MTU 为 1500 字节，因此 MSS 一般长度为 **1460 字节**。

TCP 会为每个应用层报文数据块添加一个 TCP 首部进行封装，并递交给网络层再由 IP 封装。TCP 报文段在发送端和接收端上都会被放入对应的**缓存**中等待发送或接收。

因此，TCP 的组成包含六个部分：

1. 发送端 TCP 缓存
2. 发送端 TCP 状态变量
3. 发送端套接字
4. 接收端 TCP 缓存
5. 接收端 TCP 状态变量
6. 接收端套接字

而其中的网络元素不会缓存任何 TCP 数据。

#### TCP 报文段结构

TCP 一般会把应用层报文分解成若干块封装在报文段载荷中，而交互式应用为了响应速度，其报文大小一般不会超过 MSS。载荷是报文段结构的一部分，整个报文段结构包括：

1. 源端口号（src port）：16 bits
2. 目的端口号（dst port）：16 bits
3. 序号（sequence number）：32 bits，该字段用来实现可靠数据传输服务，表示当前报文序号
4. 确认号（acknowledgment number）：32 bits，该字段用来实现可靠数据传输服务，表示接下来想要接收的报文序号
5. 首部长度（length）：4 bits，以 32 bits 为单位记录 TCP 首部长度，如`0101`表示 32 * 5 = 160 bits = 20 bytes 长度，这也是典型的 TCP 首部长度
6. 空位：保留的 3 bits
7. 标记位（flags）：9 bits，每个比特标记代表一定含义，当标记位为 1 时：
   + NS（nonce sum）：该标记位用于保护接受者不受发送者的突发恶意隐藏报文侵害
   + CWR（Congestion Window Reduced）：指示应该在拥塞控制时减少窗口通过的比特数
   + ECE（Explicit Congestion Notification Echo）：表示该 TCP 连接有拥塞控制时的通知能力
   + URG（urgent）：表示报文段中包含紧急数据
   + ACK（Acknowledgment）：表示数据包被成功地接收了
   + PSH（push）：表示接收端应该把数据立刻交给上层而不是进行缓存
   + RST（reset）：表示因为发生连接错误而
   + SYN（Synchronization）：表示正在进行第一次握手
   + FIN（finished）：表示数据包发送完毕
8. 接收窗口（window）：16 bits，用于流量控制，表示希望接收的字节数
9. 校验和（checksum）：16 bits
10. 紧急数据指针（urgent point）：16 bits，当 URG 为 1 时，紧急数据指针用于指出紧急数据的最后一个字节，此时 TCP 必须通知上层存在紧急数据
11. 选项（options）：32 bits，可选，用于协调 MSS、调节窗口等，也可能包含时间戳
12. 载荷（payload）：MSS，封装的上层报文内容

##### 序号和确认号

序号和确认号是保证 TCP 可靠传输的**关键部分**。一个报文段的**序号**是该报文段首字节**在字节流中**的编号，而不是按报文段顺序进行排序的编号。如果有一个 5000 字节长的流，被分成 50 个报文段进行传输，假设第一个报文段的序号是 0 ，第二个报文段的序号就会是 100，第三个就会是 200，以此类推。

**确认号**则代表了接收方**想要接收的**下个报文段的序号。按上面的例子来说，如果接收方的确认号是 100，再接收了对应序号的报文段后，下一次响应时的确认号就会是 200，表示接收方需要接收一个序号为 200 的报文。

##### 累积确认

**累积确认（cumulative acknowledgment）**是保证 TCP 可以按序确认报文段的可靠性保证措施，TCP 把数据看成是无结构但**有序**的，但是 IP 提供的服务却**不能保障**报文段到达是有序的。假如接收方已经接收了 200 序号的报文段，接下来确认号变为 400，但是却先收到了序号为 800 的报文段，接收方对该报文段的响应中的确认号仍旧会为 200，直到序号为 200 的报文段到达，接收方才会返回一个确认号为 400 的响应。TCP 协议**没有**规定应该如何进行失序报文段的处理，一般来说的做法为将已到达的失序报文段**缓存**，并在稍后重建整个报文。

##### 初始序号的选择

一个 TCP 连接的初始序号可以为 0 ，但一般会随机选择一个数。这么做是为了避免网络中存在两台主机之前已经终止的某个 TCP 残存的报文段对现有连接的干扰。

##### Telnet 实例

Telnet 是一个基于 TCP 的用于远程登录的协议，许多操作系统都内置了 Telnet 客户端，但是由于其明文传输所有内容的安全性问题，现在大都使用 SSH（安全 Shell）代替 Telnet 。 

Telnet 协议使用一种**回显（echo back）**的方式处理用户输入。用户在 shell 软件中输入的每个字符都会被 TCP 传输到远程主机中，待远程主机处理后返回到客户端上，以此确认命令有到达远程主机。

假如在 Shell 中运行 Telnet 客户端，成功连接了服务器，接下来在交互窗口中输入`ok`两个字符，会发生以下事情：

1. 假设握手结束后客户端随机得到的初始序号（SEQ）为 42，确认号（ACK）为 79
2. 客户端输入一个`o`，这个字符随即被 TCP 封装发送到远程主机，报文段的 SEQ 为 42，ACK 为 79 
3. 远程主机接收报文段，回显`o`，此时远程主机的响应的 ACK 变为 43，SEQ 为 79
4. 客户端接收到响应报文段，发送`k`，SEQ 为 43，ACK 为 80
5. 远程主机接收到报文段，回显`k`，SEQ 为 80，ACK 为 44

可以看出其序号和确认号在累积确认中的表现。
