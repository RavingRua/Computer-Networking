# 计算机网络

---

## 第一章 计算机网络和因特网

**计算机网络（Computer Networking）**是指将[地理](https://baike.baidu.com/item/地理)位置不同的具有独立功能的多台[计算机](https://baike.baidu.com/item/计算机/140338)及其外部设备，通过通信线路连接起来，在[网络操作系统](https://baike.baidu.com/item/网络操作系统/3997)，[网络管理软件](https://baike.baidu.com/item/网络管理软件/6579078)及[网络通信协议](https://baike.baidu.com/item/网络通信协议/4438611)的管理和协调下，实现[资源共享](https://baike.baidu.com/item/资源共享/233480)和信息传递的**计算机系统**。

### 1.1 因特网

**因特网（Internet）**是一个**世界范围内的计算机网络**，互联了全世界的电子设备，包括计算机、个人终端、非传统因特网物品。

#### 1.1.1 具体构成

这些设备被称为**主机（host）**或**端系统（end system）**。端系统通过**通信链路（communication link）**和**分组交换机（packet switch）** **连接** 在一起。

通信链路的**传输速率（transmission rate）**以比特秒（bit/s，或bps）度量。当一台端系统向另一台端系统发送信息时，会将数据分段成多个信息包，称为**分组（packet）**。

常见的分组交换机是**路由器（router）**和**链路层交换机（link-layer switch）**，两者的作用是向目的地转发分组。路由器通常用于网络核心中，链路层交换机通常用于接入网络。一个分组经过的通信链路和分组交换机被称为**路径（route）**。以交通运输系统类比分组交换网络：

+ 分组：货物
+ 端系统：目的地
+ 通信链路：高速公路
+ 分组交换机：交叉路口和引导牌

端系统通过**因特网服务提供商（Internet Service Provider，ISP）** **接入互联网**，每个 ISP 自身就是一个由多台分组交换机和多段通信链路组成的网络。ISP 之间也分等级，并需要互联，以此接入全球互联网。

端系统、分组交换机和其他因特网部件需要运行一系列**协议（protocol）**，控制因特网信息的接收和发送。**TCP（Transmission Control Protocol，传输控制协议）**和 **IP（Internet Protocol，因特网协议）**是最重要的因特网协议。IP 定义了路由器和端系统之间发送和接收的分组的**格式**。主要协议统称 **TCP/IP** 协议。

**因特网标准（Internet Standard）**由因特网工程任务组（Internet Engineering Task Force，IETF）研发，他们的标准文档称为**请求评论（Request For Comment，RFC）**。

#### 1.1.2 服务

从 *为应用程序提供服务的基础设施*  的角度描述因特网，各种端系统被称为**分布式应用程序（distributed application）**。这些程序运行在各个端系统而不是网络核心的分组交换机中。这些应用程序使用特定语言编写，并互相发送数据，而因特网则是提供数据传输服务的平台。

连接因特网的端系统提供了一个**套接字接口（socket interface）**，规定了各端之间**交换数据的方式**。

#### 1.1.3 协议

**协议（protocol）**各方协商后制定的一套标准，人类语言日常交流的用语规范就是一套“提问与回答”的协议标准。**网络协议**类似于人类协议，区别在于通信双方是端系统。

计算机网络协议简称协议，定义了两个或多个通信实体之间交换的**报文**的格式和顺序，以及报文发送或接受一条报文或其他事件时采取的**动作**。如：向 Web 服务器请求网页，发送一条 GET （动作）请求，包含 HTTP 请求报文（报文），Web 服务器返回一个 HTML 文件（响应）。

### 1.2 网络边缘

一些因特网部件位于因特网的边缘，，因此它们被称为端系统。端系统也被称为 host（主机），因为它们容纳和运行一些应用程序，如 Web 浏览器与服务器。主机又可以分为**客户端（client）**与**服务器（server）**两类，如今一些提供数字媒体服务的服务器属于大型**数据中心（data center）**。

#### 1.2.1 接入网络

**接入网络**是将端系统物理连接到其**边缘路由器（edge router）**的网络，而边缘路由器是端系统连接到其他端系统时经过的**第一台**路由器。以下是常见的接入网场景：

+ 传统的家庭接入：DSL（用户数据线，利用现有的电话线路设施）、电缆接入（利用现有的有线电视设施）、FTTH（光纤到户，分为有源和无源）、拨号（和DSL模式相同）、卫星接入
+ 企业和现代家庭接入：以太网（Ethernet，由 Xerox 公司发明，现有 IEEE 802.3标准）、Wi-Fi（无线通信技术）
+ 广域无线接入：3G、4G、5G 以及其他蜂窝网络技术

现在家庭接入网络通常包括：

+ 外部接入物理媒体
  + 双绞铜线：是一种通过双绞构造增强干扰性、在百米内有效的媒体，一般用于局域网（LAN），可能需要与放大器一起工作
  + 同轴电缆：类似双绞铜线的媒体，拥有更强的抗干扰能力和更远的可靠传输距离，是过去主要的因特网接入手段
  + 光纤：是目前速度最快、传输距离最长、安全性最高的媒体，需要使用特殊的调制解调器（光猫）
+ **调制解调器（modem）**：也称“猫”，用于将媒体中传输的模拟信号转为计算机硬件可识别的数字信号。对于光纤，需要使用数字调制解调器将光信号转换为数字信号
+ **防火墙（firewall）**：用于在外网和内网之间构建一道安全屏障，保护用户资料和信息安全
+ **路由器（router）**：家庭用交换机一般为路由器，起到网关的作用。路由器处理分组，将非 TCP/IP 地址转为 TCP/IP 地址并发送分组。由于家用宽带入线通常只有一根，路由器起到建立家庭局域网的作用，多台家用设备通过路由器向外转发分组，由路由器根据转发表确认这些分组去向。在接到响应分组时，根据分组首部信息，确定分组内网中去向，转发给指定设备。目前光纤到户技术已经普及，一些路由器已经内置调制解调器功能，可以直接和光线连接并进行转发
+ **局域网（LAN）**：局域网一般是覆盖范围比较小的计算机网络。**以太网（Ethernet）**是家庭局域网技术的一种，是最普遍的局域网络。现代路由器将局域网建立功能内置，通过有线或无线媒体的方式连接家用局域网中的设备
+ **无线局域网（WLAN）**：利用无线通信技术（Wi-Fi）可以建立通过无线媒体连接设备的局域网
+ 家用设备：常见的家用联网设备有个人计算机、移动终端、智能家具、网络摄像头等

#### 1.2.2 物理媒体

数字比特需要通过**物理媒体（physical media）**传输。物理媒体分为两种类型：

+ 导引型媒体：guided media，沿固体媒体前行，如光纤
+ 非导引型媒体：unguided media，以电磁波形式在空气或外层空间传播，如无线电

### 1.3 网络核心

**网络的核心部分**是由分组交换机和通信链路构成的网状网络。数据传输的方式有**分组交换**和**电路交换**。现代的因特网是**网络的网络**。

#### 1.3.1 分组交换

在网络应用中，端系统彼此交换**报文（message）**。报文用于执行控制功能（如 Restful 状态转移），也可以包含数据（如 HTTP 传输超媒体）。发送源将长报文划分为较小的数据块，称为**分组（packet）**，这些分组通过通信链路和**分组交换机**（**packet switch**，本意是转换光电信号的“开关”，主要为**路由器（router）**和**链路层交换机（link-layer switch）**）传输。前者是网络层设备，后者是链路层设备。

分组交换使用**最大传输速率**发送分组，如果一个大小为 L 比特的分组通过速率为 R 比特/秒的链路传输，那么传输时间就是 L/R 秒。

分组交换不会预留任何链路需要的资源，分组需要承受**排队延迟**，因特网不会保证分组实时交付。

##### 存储转发传输

多数分组交换机采用**存储转发传输（store-and-forward transmission）**机制。该机制在向传输链路输出第一个比特前，**必须接受到一个完整的分组**，在转发前接收到的比特会先被**缓存（即 store，存储）**。

与接收到比特就转发（流）的方式相比，假设链路速率为 R ，比特数为 L，转发接收延迟为 2L/R（接收 L/R + 转发 L/R），而流无需等待，为 L/R 。

##### 排队延迟和分组丢失

分组交换机会为每条有最大传输速率限制的通信链路准备**输出缓存（output buffer，也称输出队列（output queue））**。如果一个完整分组已到达，而链路忙于传输其他分组，该到达分组会被缓存等待，直到链路空闲。因此，除了分组交换机的转发过程延迟，分组还需承受输出缓存过程的**排队延迟（queuing delay）**。

由于缓存空间有限，当通信链路传输过慢时，会出现缓存空间不足的情况。此时如果有新分组到达，处于输出缓存中的某个分组或新到达的分组会被丢弃，即**分组丢失（或丢包，packet loss ，PL）**

##### 转发表和路由协议选择

在因特网中，每个端系统有一个 **IP 地址（Internet Protocol Address）**。每个分组的首部包含了传输目的地的 IP，IP 有一种等级结构，这个结构决定各级路由器如何转发分组。路由器会检查分组首部包含的 IP 信息，根据路由器内部的**转发表（forwarding table，用于将目的地地址（或地址一部分）映射到通信链路）**找到适合的输出链路。

这些转发表无需手动设置（静态路由），因特网具有一些特殊的**路由选择协议（routing protocol）**，用于自动设置转发表（动态路由）。

#### 1.3.2 电路交换

交换机移动数据的另一种方法是**电路交换（circuit switching）**。与分组交换按需分配模式不同，电路交换会预留端系统沿路径通信时需要的**资源**（缓存，链路传输速率）。在端系统向另一端系统发送消息前，两者会建立连接，路径上的交换机需要维护这些**连接状态**（用电话术语来讲即是**电路（circuit）**）。

##### 电路交换网络中的复用

电路交换网络中的**复用**是指每条链路会为多个连接使用。有两种复用方式：

+ **频分复用（Frequency-Division Multiplexing，FDM）**将一条链路的频谱按一定的频段宽度分开，该频段宽度被称为**带宽（band-width）**，多个连接在同时共用同一条链路
+ **时分复用（Time-Division Multiplexing，TDM）**在固定时间内将一条链路分为固定期间的**帧**，每个帧又被划分为固定数量的**时隙**。每个时隙有一个连接**独享**，多个连接在固定周期中排队使用链路

##### 与分组交换对比

分组交换因为没有预留资源，其端到端时延是可变与不可预测的，不适合实时通讯服务。但与电路交换相比，分组交换**动态按需分配资源**，更简单、有效、低成本，在**低并发**场景下有近似于电路交换的效率。此外，分组交换在链路空闲时，可为单个连接提供最大传输效率，而不是浪费空闲资源。目前来看，分组交换是现在的趋势。

> [Traceroute](https://www.traceroute.org) 提供一些源，并能进行端到端路由线路跟踪

#### 1.3.3 网络的网络

网络边缘上的端系统通过**接入 ISP** 与因特网连接，这只是整个互联网需要解决的问题的一小部分，接入 ISP 自身必须能够互联，这个问题通过创建**“网络的网络”**来解决。网络的网络是有层级的结构，不同层级的节点不仅与高层节点连接，还可能与同级甚至跨级连接，整个网络是**图状结构**而非树状结构。

目前因特网的网络结构是一种多层结构，由**接入 ISP**、**区域 ISP（regional ISP）**、**第一层 ISP（tier-1 ISP）**、**PoP（Point of Presence，存在点）**、**多宿（multi-home）**、**对等（peer）**、**因特网交换点（Internet Exchange Point，IXP）**和**内容提供商网络（content provider network，CPN）**组成。

+ 接入 ISP：将端系统连接到因特网的 ISP
+ 区域 ISP：在一些区域中有一些 ISP 连接这各个接入 ISP，这些 ISP 会与更大的区域 ISP 或第一层 ISP 连接
+ 第一层 ISP：在第一层 ISP 看来，与之连接的 ISP 是**客户**，而自己是**提供商**，第一层 ISP 是全球范围的 ISP，并不向任何人收取结算费用。全球范围内有多个第一层 ISP 存在并互联
+ PoP ：PoP 是一个 ISP 网络中的一台或多台路由器群组，通常位于同一位置。客户 ISP 或其 PoP 可以通过第三方提供的链路连接到提供商 ISP 的某个最近的 PoP
+ 多宿：一个客户 ISP 与多个提供商 ISP 连接的行为称为多宿，当其中一个提供商 ISP 故障时客户 ISP 依旧可以交换数据
+ 对等：位于同一层级结构且物理邻近的 ISP 可以直接连接，而不需要通过上一级 ISP 交换数据，称为对等。通常对等时 ISP 之间不结算费用
+ 因特网交换点：IXP 是一个汇合点，通常位于第三方提供有着自己独立交换机的建筑中，各级 ISP 及其 PoP 可能位于 IXP 中并对等
+ 内容提供商网络：内容提供商网络（如 Google）与第一层 ISP 同级。Google 的数据中心网络通过专用的 TCP/IP 通道连接，独立于公共因特网，与同级或较低层的 ISP 直接互联（在 IXP 处互联或直接连接），并不收取结算费用。内容提供商通过这种方式减少了向顶层提供商支付的费用，并加强了其对服务如何交付给客户的过程的控制权

### 1.4 分组交换网中的时延、丢包、吞吐量

计算机网络必定要限制端系统之间的**吞吐量（每秒能够传输的数据量）**，在端系统中引入**时延**，并产生**丢包**。

#### 1.4.1 分组交换网络的时延（点到点时延）

分组交换网络的**时延（delay）**是分组从一个**节点（node，路由器或主机）入口**至另一个节点**入口**之间受到的时延，对于路由器而言就是从一个路由器入端口到另一个路由器入端口。主要有一下几种类型：

+ **节点处理时延（nodal processing，d~proc~）**：节点处理延迟来自路由器检查分组首部和决定分组去向需要的时间，也可能包括检查比特级差错所需要的时间。一般为**微秒**或更低数量级。这之后分组会被送入缓存队列等待；
+ **排队时延（queue delay，d~queue~）**：分组在队列中等待时的时延，取决于等待向链路中传输的分组**数量**。一般为**毫秒至微秒**量级；
+ **传输时延（transmission delay，d~trans~）**：大部分路由器采取分组按先到先服务的规则进行传输，传输时延是路由器在检查和排队后将分组**推到出链路**所需要的时间。一般为**毫秒至微秒**量级；
+ **传播时延（propagation delay，d~prop~）**：是分组从链路起点到下一个路由器所需要的时间。该时延取决于**物理媒体**，是两节点之间**距离的函数**。在广域网中，该时延一般为**毫秒**量级；

**节点总时延（total nodal delay，d~nodal~）**是上述延迟的和：
$$
d_{nodal} = d_{proc} + d_{queue} + d_{trans} + d_{prop}
$$

#### 1.4.2 排队时延和丢包

**排队时延**是路由器**内部**的时延，也是**丢包**发生的位置，很大程度上取决于**流量到达队列的速率**（接收分组速率）、**链路的传输速率**（网速）、**到达流量的性质**（周期性或突发性到达）。设 **L** 为分组的比特大小，**a** 为分组到达速率，**R** 为链路传输速率，则**流量强度（traffic intensity）**为：
$$
La\ /\ R\ \  (bps)
$$
流量强度越大，排队时延增加越快，分组**丢失（lost）**比例也就越大。

#### 1.4.3 端到端时延

**端到端时延（end-to-end delay）**是分组从端系统到端系统需要的时间。假设端到端传输经过 **N** 台路由器，则端到端时延为：
$$
d_{end-end}=N(d_{proc}+d_{trans}+d_{prop})
$$

##### Traceroute

[Traceroute](https://www.traceroute.org) 程序可以由用户指定一个目标端系统，并统计经过的所有路由器。当一个接收到一个分组时，会向发送源返回一个**报文**。该报文包括路由器的名字以及地址，因此程序可以重建分组由源到目的地所经过的路由。该程序总共测试三次分组转发。

Windows 提供了一个名为 tracert 的命令行软件用于跟踪路由，请求网易首页可以得到如下结果：

```
> tracert www.163.com

通过最多 30 个跃点跟踪
到 z163picipv6.v.qdyd03.longclouds.com [2409:8c20:3c42:21::103] 的路由:

  1     2 ms     1 ms     2 ms  2409:8028:10:1::7105
  2     1 ms     1 ms     2 ms  2409:8028:10:1::7104
  3     2 ms     2 ms     2 ms  2409:8080:0:2:1105:1151:300:0
  4     8 ms     8 ms     7 ms  2409:8080:0:1:405:1105::
  5    11 ms    11 ms    12 ms  2409:8080:0:2:405:461:600:1
  6    11 ms    11 ms    11 ms  2409:8020:3042:102::1
  7    17 ms    14 ms    13 ms  2409:8020:3042:516::1
  8    13 ms    12 ms    12 ms  2409:8c20:3c42:21::101
  9    11 ms    11 ms    12 ms  2409:8c20:3c42:21::103
```

##### 端系统、应用程序和其他时延

有时传输分组的端系统可能会有意的产生时延，并将此作为端系统媒体共享协议的一部分。另外一些时延来自应用程序处理过程，如 VoIP 语音应用需要一定时间来处理声音源以提高声音质量。

#### 1.4.4 计算机网络中的吞吐量

除了时延和丢包，计算机网络中另一个重要的性能度量是**端到端吞吐量（end-to-end throughout）**。在任何时间瞬间接收到的吞吐量称为**瞬时吞吐量（instantaneous throughout）**，以 bps 计。一个文件的平均吞吐量则是以文件比特数除以传输时间得到的吞吐量 F/T bps，即传输速率 R 。如果一个端到端路径包含多段链路层链路，整条路径的吞吐量将由链路中的**最低**吞吐量决定，最慢的那条链路拖慢了整个链路的吞吐速度。

**流量强度（traffic intensity）**表示分组到达主机的强度，值为 La/R ，其中 a 指分组到达主机入口队列的速率，单位分组/秒（pkt/s）。

### 1.5 协议层次及其服务模型

#### 1.5.1 协议分层

网络设计者以**分层（layer）**的形式组织**协议（protocol）**以及实现这些协议需要的**网络硬件和软件**。每个协议层（除顶层）会向上层提供**服务（service）**，即**服务模型（service model）**。分层协议具有概念化和结构化（模块化）的特点，这使得更新系统组件变得更加容易。分层有两个潜在缺点：高层可能冗余较低层的功能（如许多协议栈在基于每段链路和基于端到端的两种情况下都提供差错恢复）、某层功能可能需要其他层出现的信息。

因特网的各层协议组成了一个**协议栈（protocol stack）**，该栈自顶向下为**应用层**、**运输层**、**网络层**、**链路层**、**物理层**。

##### 应用层

**应用层**是应用程序以及其协议停留的地方。应用层解决**端到端（在发送端与接收端之间直接建立数据连接，忽略其他中间设备）**传输问题，应用层协议几乎总是通过**软件**实现。

应用层包括**应用程序（program）**、**服务（service）**和实现服务的**协议（protocol）**。应用程序提供**创建消息的方法**，服务创建与网络交互的**接口**，协议提供**处理数据的规则和格式**。

应用层将**用户的输入**通过应用程序转换为服务，匹配合适的服务协议，按照协议规定的方式处理报文。接下来，发送报文给运输层，由运输层进行下一步报文封装和传输。

常用的应用层协议有：

+ HTTP：超文本传输协议
+ SMTP：简单邮件传输协议
+ FTP：文件传输协议
+ HTTPS：超文本传输安全协议

一些网络功能，如将对人友好的端系统名（如**域名（Domain Name）**是因特网中的计算机或计算机组的名字）转换为网络地址（如 32位的 **IPv4**、128位的 **IPv6**）的 **DNS（Domain Name System，域名系统，将域名与 IP 地址互相映射）**也是借助特定的协议（**UDP**）完成。

应用层中端到端传输的信息分组被称为**报文（message）**。

##### 运输层

**运输层**负责传送端到端之间的应用层报文，运输层协议几乎总是通过**软件**实现。运输层要负责**为应用程序提供连接**，**管理和转发**报文，并**维护连接**。接下来的点到点连接由网络层处理。

因特网中有两种协议用于传输应用层报文：

+ **TCP（Transmission Control Protocol）**：传输控制协议，这是一种**面向连接**的服务，TCP 先在端与端之间建立连接，然后将长报文划分成短报文，确保报文的传递，并进行流量控制和拥塞控制
+ **UDP（User Datagram Protocol）**：用户数据报协议，这是一种**无连接**的协议，不提供不必要的服务，没有可靠性、流量控制与拥塞控制。

运输层的分组被称为**报文段（segment）**。

##### 网络层

网络层负责将被称为**数据报（datagram）**的网络层分组从一台路由器或主机传输到另一台路由器或主机中，即**点对点传输（基于 IP 或 MAC）**，网络层通常是**硬件与软件的混合体**，如路由器。

和运输层不同，网络层**为不同的路由器或主机提供连接的方式**，通过网络地址和路由表将各个路由器或主机**关联**起来。但关联并不代表已经连接，主机的连接由接下来的链路层负责。

源将报文段通过 TCP 或 UDP 协议向网络层递交该**报文段和其目的地地址**。因特网的网络层包括 **IP（Internet Protocol）**协议和决定路由去向的**路由选择协议**。通常也称网络层为 **IP 层**，证明 IP 是将因特网连接在一起的**粘合剂**。

##### 链路层

因特网的网络层通过源和目的地之间的一系列路由器来传输数据报，这需要依靠点对点传输的**链路层**服务。链路层解决具体的传输问题，将在网络层中关联的路由器或主机连接起来并传输数据报。这些数字信号需要交给物理层以物理方式在现实中运输。

链路层物理设备通过一个48位的硬件物理地址 **MAC（Media Access Control Address，媒体存取控制地址）**互相识别，MAC 也称**局域网地址（LAN Address）**、**以太网地址（Ethernet Address）**、**物理地址（Physical Address）**。计算机网络中的每个设备，如网卡，都有一个独一无二的 MAC 。

**局域网没有网络层**，其中设备都是通过链路层协议的 MAC 或不连接外网的**内网 IP** 寻址通信，这些设备不会经过网络层连接互联网。

链路层的服务取决于该链路层的特定**链路层协议**，这些协议由**硬件**实现，如：

+ **Ethernet**：以太网
+ **Wi-Fi**：无线通信
+ **DOCSIS**：电缆接入网

一个数据报在沿途链路上可能经过不同协议处理，如家用设备可能通过无线信号连接家用局域网，再通过电缆或光纤网络向目的地传输数据。链路层分组被称为**帧（frame）**。

##### 物理层

物理层的任务是将帧的一个个比特从点传输到点，以物理的方式**处理数字信号中的比特位**，并**物理连接**各链路层实体（如蜂窝网络节点）。这层中的协议仍是链路相关的，并进一步与**实际传输媒体**相关。如以太网具有许多物理层协议，由诸如双铜绞线、同轴电缆和光纤的**硬件**实现。物理层的分组被称为**比特流（bits stream）**。

##### 自顶向下

转换用户输入为特定数据结构（应用层）；为多端间的数据建立可靠连接以运输（运输层）；为物理上非直接连接的端系统所依赖的网络节点提供相互识别和寻找最佳路径的方式（网络层）；用硬件设备将已经关联的网络节点连接起来，传递离散的数字信号（链路层）；将离散的数字信号置于连续的物理世界传输（物理层）。

##### 自底向上

以特定物理方式传递更高效的数字信号（物理层）；使得数字信号能在各个网络节点中传输（链路层）；作为向导，引导数据走向（网络层）；维护数字世界中的连接，并将数据置于连接中传输给端系统（运输层）；将报文按照协议约定进行解读，并呈现给用户（应用层）。

#### 1.5.2 OSI 模型

因特网协议栈并不是唯一的协议栈。**国际标准化组织（ISO）**提出计算机网络围绕 7 层来组织，称为**开放互联系统（OSI）模型**。OSI 模型比因特网协议栈更加具体，分为以下 7 层：

+ 应用层
+ 表示层
+ 会话层
+ 运输层
+ 网络层
+ 数据链路层
+ 物理层

**会话层**和**表示层**是 OSI 中附加的两个层。表示层的作用是使进行通信的应用程序能够**理解交换数据的含义**。会话层提供**数据交换的定界**和**同步**，包括**建立检查点**和**恢复方案**的方法。因特网协议栈选择将这两层的内容交给应用程序开发者处理。

#### 1.5.3 封装

因特网协议栈的每层都将自己的分组交至下一层或上一层传输。在向下传递时，下层会在上传分组的首部添加自己的信息，对上层分组进行了**封装（encapsulation）**。封装后的分组具有两部分：**首部字段（header，头部）**和**有效载荷字段（payload file，或称 body，体）**，后者通常是来自于上一层的分组。一个大报文可能被拆分成多个小报文并被封装成多个具有首部信息的报文段，接收端必须能将这些报文段重构为大报文。

### 1.6 面对攻击的网络

因特网已经成为人类社会的重要组成部分，也面临这恶意攻击的风险。**网络安全**是一个非常重要的议题。

#### 1.6.1 攻击者可以植入有害程序

攻击者可以通过因特网向用户计算机植入**恶意软件（malware）**，受害主机也可能被恶意软件利用，向因特网中继续传播这种软件。这些计算机群体被称为**僵尸网络（botnet）**。

目前多数恶意软件是**自我复制（self-replication）**的，并以**病毒（virus）**或**蠕虫（worm）**的形式扩散。病毒是需要某种形式的用户交互来感染用户设备的恶意软件，通常来自恶意下载链接或电子邮件附件。蠕虫是一种无须任何用户交互就能感染设备的恶意软件，通常来自对脆弱网络应用的攻击导致应用使用者被感染。

#### 1.6.2 攻击者可以攻击服务器或网络基础设施

一种宽泛类型的安全性威胁被称为**拒绝服务攻击（Denial-of-Service （DoS） attack）**，这种攻击会导致网络、主机或其他网络设施拒绝（不能够正常地）向合法用户提供服务。大多数 DoS 攻击为一下类型：

+ 弱点攻击：通过一段精细制作的**报文**按照适当顺序发送给具有缺陷的服务器，使服务器处理出错，自我保护机制导致服务器**停止运行**或**崩溃**
+ 带宽洪泛：攻击者发送大量分组，导致接入链路阻塞，无法提供正常服务
+ 连接洪泛：攻击者与目标主机创建大量 TCP 连接，导致服务器超载，无法提供正常服务

单一且“有前科”的攻击源很容易被上游路由器检测并拦截，阻止其到达服务器。而在**分布式拒绝服务攻击（DDoS）**中，攻击者通过控制僵尸网络中的主机连续对目标服务器发起攻击，这是目前屡见不鲜而且难以主动防范的攻击之一，著名的 MyDoom 病毒曾经利用僵尸网络导致过大范围的服务器停机。

#### 1.6.3 攻击者可以嗅探分组

对于无线传输设备，攻击者可以在传输设备附近放置一台被动的接收机，并接受该设备发送的每一个分组的副本。这种接收机被称为**分组嗅探器（packet sniffer）**。嗅探器也可以被部署在有线网络中，如以太网和有线广播环境。攻击者会通过获取网络接入权并收集分组副本，进行离线分析，得到敏感信息。

分组嗅探器是被动的，因此不向信道中注入分组，因此难以检测。这些嗅探器也可以用于软件测试和故障排除，如 **Wireshark** 就是一种常用的分组嗅探器。

#### 1.6.4 攻击者可以伪装并进行哄骗

攻击者可以生成具有任意源地址、分组内容和目的地址的伪造分组，对于没有防范性的接收方，分组内的命令或恶意内容可能导致各种安全问题，如修改转发表从而导致更多的数据泄漏。将虚假源地址注入分组的能力称为 **IP 哄骗（IP spoofing）**，这是伪装能力的一种。

### 1.7 因特网历史

#### 1.7.1 分组交换的发展 1961~1972

1960年前世界上最大的通信网络是电话网。随着计算机重要性的增加，人们开始考虑如何将计算机连接到一起，计算机产生的流量往往具有突发性，即活动间断性，这使得分组交换开始被讨论和验证。

+ 1964：分组交换技术首次公开发表，MIT 的 Kleinrock 使用排队论体现了分组交换在处理突发流量上的有效性
+ 1967：第一个分组交换计算机网络、因特网的直接祖先：ARPAnet 总体计划公布
+ 1969：已有四个分组交换网络节点，这个网络最早执行的远程注册任务导致了系统的崩溃
+ 1972：ARPAnet 端系统间的第一台主机到主机协议——网络控制协议（NCP）完成；第一个电子邮件程序被编写
+ 1970s中期：其他分组交换网络开始出现：ALOHAnet 卫星微波网络、Telnet 等商用网络

#### 1.7.2 网络的激增 1980~1990

到了20世界80年代，连接公共因特网的主机数量达到了十万量级，联网主机数开始急剧增长。

+ 1983.1.1：TCP/IP 协议作为 ARPAnet 新的标准主机协议正式部署
+ 1980s后期：TCP 进行了重要扩展，实现基于主机的拥塞控制；DNS 被研制出

#### 1.7.3 因特网爆炸 1990s

20世纪90年代发生了许多事件，ARPAnet 已经不复存在，因特网开始走向商业化，主干流量开始由多个 ISP 提供。

+ 1989~1991：欧洲粒子物理研究所（CERN）的 TimBL（Tim Berners-Lee）发明了 Web（万维网），并研制了 HTML、HTTP、Web 服务器和浏览器的初始版本
+ 1996：微软开始研制浏览器，几年后在与网景公司的竞争中胜出
+ 20世纪末：Web 相关标准开始交由 W3C 与 ECMA 组织制定，Web 开始有了一个统一标准
+ 2000：电子邮件、Web、即时讯息、对等文件共享称为最受欢迎的因特网应用程序

#### 1.7.4 目前

+ 光纤到户技术开始普及，代替老旧的电缆传输技术
+ 高速无线蜂窝网越来越普及
+ 在线社交网络取得巨大成功和影响
+ 一些公司开始建立自己的专用网络，绕过公共因特网和较低层 ISP 直接对等
+ “云”开始为应用提供可扩展的计算与存储环境，并用于保证访问安全

---

## 第二章 应用层

### 2.1 应用层协议原理

#### 2.1.1 网络应用程序架构

**应用程序架构（application architecture）**规定了如何在端系统上组织应用程序。对于网络应用程序，有两种主流架构：

+ **客户端-服务器架构**：client-server architecture 。该架构拥有一个总是开机的主机，称为**服务器**，服务器服务于来自其他称为**客户端**的主机的**请求**。在该架构下，客户端之间不直接通信，而是通过服务器交换数据，每个服务器有一个固定且周知的地址，称为 **IP 地址**。一个服务器可能运行在单独的主机上，也可能是一个**虚拟服务器**，多个虚拟服务器运行在一台物理主机上，配备大量主机的**数据中心（data center）**通常用来创建这些虚拟服务器；
+ **P2P 架构**：point-to-point architecture 。该架构对位于数据中心中的服务器有最小或没有依赖。应用程序之间**直接通信**，这些应用程序所在的主机称为**对等方**。P2P 架构面临着安全性、性能和可靠性挑战；

#### 2.1.2 进程间的通信

对于操作系统而言，进行通信的实际上是**进程（process）**而不是程序，这些进程可能在单个操作系统上通信，也可能在多个端系统间通信。跨越计算机网络的进程通信交换的是**报文（message）**。

##### 客户端和服务器进程

网络应用程序由**成对**的进程组成，这些进程通过网络互相发送报文。通常将进程其中之一称为**客户（client）**，另一称为**服务器（server）**。在 Web 中，浏览器是客户，Web 服务器是服务器；在 P2P 中，下载方是客户，上传方是服务器。

+ **客户端**：**发起通信**的进程
+ **服务器**：在会话开始时**等待联系**的进程

##### 套接字

**套接字（socket）**是进程和计算机网络间的**接口（API）**，在因特网中即**应用层应用程序和运输层协议**间的接口。一个应用程序进程可能有一个或多个套接字。

一个端系统上的软件需要把报文推送到套接字，套接字假设两台端系统间存在运输的基础设施，即运输层的服务，通过该服务将报文传递到另一个端系统的套接字，再由套接字转交给应用程序解读。应用程序开发者可以控制套接字在应用层的部分，如：

+ 选择应用层协议
+ 设定部分运输层参数

##### 进程寻址

进程对间要想传输报文，就需要找到另一个进程的地址。该地址需要包含两种信息：

+ **主机的地址**：在因特网中，主机由其 **IP 地址**标识，这是一个 32 位（IPv4）或 128 位（IPv6）的值；
+ **接收进程的标识符**：发送报文的进程需要指定接收主机上的**接收套接字**，目的地**端口号（port number）**用于指示应该接收报文的套接字。在 Web 中，发送和接收报文的套接字端口为 80，而邮件服务器进程则使用 25。

#### 2.1.3 运输层向应用层提供的服务

套接字是应用层与运输层间的接口，运输层通过套接字向应用层提供**服务**。运输层主要提供下列服务：

+ 提供可靠数据传输服务：确保数据**正确**、**完整**的交付
+ 吞吐量保证：保证吞吐量（向接收进程交付比特的**速率**）
+ 传输时间保证：控制报文到达端系统的时间在一定范围内
+ 安全性保证：提供加密解密报文的服务

#### 2.1.4 因特网中运输层提供的服务

因特网的运输层为应用层提供一些服务，因此应用层开发者无需考虑这些问题。因特网运输层提供了两种协议：**TCP** 和 **UDP** 。

##### TCP

**TCP（Transmission Control Protocol，传输控制协议）** 协议的**服务模型**包含**面向连接**服务和**可靠数据传输**服务：

+ 面向连接的服务：在应用层数据报文开始流动前，TCP 会让客户端和服务器交换运输层控制信息，即**握手**，提醒两者为大量分组的到来做好准备。握手结束后，一个 **TCP 连接（TCP connection）**会在进程对的套接字之间建立。这条连接是**全双工**（连接双方可以**同时**进行报文转发）的。当报文转发结束后，该连接被关闭
+ 可靠数据传输服务：TCP 会无差错的、按适当顺序交付所有转发的分组，不会存在数据丢失和冗余。但是 TCP **不提供**加密服务

##### SSL

**SSL（Safe Sockets Layer，安全套接字层）**由网景公司研发，旨在解决不提供加密服务的 TCP/UDP 协议的安全问题。SSL 是 TCP 的加强版，提供**加密**、**数据完整性保证**、**端点鉴别**服务。使用 SSL 需要获取 SSL 证书。

SSL 协议加密报文过程：

1. 进程向 SSL 发送明文数据
2. SSL 加密数据，并传递给 TCP 套接字
3. TCP 套接字将密文传输到另一个端系统中进程的 TCP 套接字
4. TCP 套接字发送密文给 SSL，SSL 解密数据，向进程发送明文

##### UDP

**UDP（User Datagram Protocol，用户数据报协议）**是一种**不提供**不必要服务的轻量运输层协议，仅提供最小服务，**无连接**，提供不可靠数据传输服务。选择 UDP 协议的两个进程间**没有握手**。UDP 不保证数据能够到达，也不保证数据到达的顺序。UDP 不包含拥塞控制机制，可以以任何熟虑向其下层（网络层）注入数据。

##### 因特网中运输层不提供的服务

因特网运输层协议并没有提供吞吐量保证和传输时间保证，应用层应用程序开发者需要考虑这两个问题。

#### 2.1.5 应用层协议

**应用层协议（application-layer protocol）**定义了端系统之间如何传递报文，包括：

+ **报文类型**：如**请求**和**响应**两种类型
+ **报文语法**：如报文中各个字段应该如何描述
+ **字段语义**：字段中的**信息含义**
+ **报文规则**：何时发送报文，如何发送报文，以及如何响应报文

一些应用层协议由 RFC 文档定义，如 Web 所使用的 HTTP 协议。

### 2.2 Web 和 HTTP

**Web（World Wide Web）**，即**万维网**，是20世纪90年代兴起的新型应用，采用客户端-服务器架构。Web 按需操作、开放、使用简单。

#### 2.2.1 HTTP

**HTTP（Hype-Text Transform Protocol，超文本传输协议）**是 Web 的核心。HTTP 是一种**半双工协议**，即传输是双向的，但是不能是同时的，必须等到请求到达才能发送响应。HTTP 由两个程序实现：Web 客户端和 Web 服务器。

**Web 页面（Web page）**，也叫文档，由**超媒体对象**组成，包括 HTML 文件、图片、视频、程序等。HTML 通过 **URL（统一资源定位器）**标识其内部资源，URL 包括存放对象的**主机名**和对象在主机中的**路径名**，一个完整的 URL 如下：

```url
protocol://hostname[:port]/path[;parameters][?query]#fragment
```

HTTP 建立在 TCP 之上，在建立进程对之间的 TCP 连接后，HTTP 请求才会发起。客户端向服务器发送 HTTP 的过程大致为：

1. 客户端的套接字与服务器的套接字建立 TCP 连接
2. 客户端套接字通过该连接向服务器发送 HTTP 请求
3. 服务器套接字通过该连接向客户端发送 HTTP 响应

TCP 协议提供的服务向 HTTP 进行了数据完整性的保障，HTTP 不用担心数据丢失，也不用关注数据恢复的细节。

HTTP 是**无状态协议（stateless protocol）**，服务器只向客户端返回被请求的文件，而不存储用户状态。

#### 2.2.2 非持续连接和持续连接

如果每个请求/响应对是经过一个**单独**的 TCP 发起的，这种连接称为**非持续连接（non-persistent connection）**。如果所有请求/响应对经过**相同**的 TCP 发起，这种连接称为**持续连接（persistent connection）**。HTTP 既能使用前者也能使用后者。

##### 非持续连接的 HTTP

HTTP 1.0 协议采取非持续连接，假设有一个包含 10 张图片的 HTML 网页，在向该 HTML URL 进行请求时，将发生：

1. HTTP **客户端进程**通过80套接字端口发起一个到服务器进程套接字的 **TCP** 连接；
2. TCP 连接**建立后**，HTTP 客户端进程经过套接字发送一个 HTTP 请求报文，由服务器进程套接字接收；
3. HTTP **服务器进程**套接字将报文传递给服务器进程，服务器进程从其内存或外存中根据请求报文 URL 中引用的超媒体对象（HTML 文档）路径获取该对象，并将其**封装**在响应报文中；
4. HTTP 服务器进程通过套接字向客户端进程发送响应报文，并通知 TCP 连接在客户端完整接收报文后关闭该 TCP 连接；
5. HTTP 客户端进程**接收响应报文后**，**TCP 关闭连接**。响应报文指出报文实体体封装的是一个 HTML 文档对象。客户端进程将解析这个对象，并在其中得到 10 张图片的引用；
6. 客户端进程对每张图片建立一个**新的 TCP 连接**并发起 HTTP 请求，重复上述过程。

在非持续连接中，报文首部将包含一个 `Connection: close`首部行，代表 TCP 连接已经关闭。

###### RTT

为了评价非持续连接，需要引入**往返时间（RTT，Round-Trip Time）**，RTT 指的是一个短分组从客户端到服务再返回客户端所花费的时间。RTT 包括：

+ 处理时延
+ 排队时延
+ 传输时延
+ 传播时延

###### HTTP 的 TCP 三次握手

使用非持续连接的 HTTP 将经历**“三次握手”**过程，占用 2 个 RTT：

+ 第一次握手：**客户端**向服务器发送一个小 **TCP 报文段**；
+ 第二次握手：**服务器**用一个小 **TCP 报文**段作为回应；
+ 第三次握手：**客户端**向服务器返回确认连接的报文。

前两次握手占用一个 RTT，最后的确认（确认的请求和响应实际上可以包含 HTTP 数据）占用另一个 RTT 。HTTP 报文的发送包含在**第三次握手**中。总的响应时间两个 RTT 加上服务器内部时延（处理、排队、传输）和服务器到客户端的传播时延。

##### 持续连接的 HTTP

非持续连接的 HTTP 的缺点非常明显：

+ 每一个请求都需要建立一个 TCP 连接，这将导致服务器开销过大
+ 每一个请求都要经历两倍的 RTT 时延

HTTP 1.1 以及其升级版本 HTTP 2.0 协议采取持续连接。在使用持续连接的情况下，服务器在发送第一个 HTTP 响应报文后，TCP **保持**连接状态，后续的 HTTP 请求和响应报文都通过该连接发送。因此，一个或多个完整的 HTML 页面中的所有内容都可以通过一个 TCP 连接发送。

使用持续请求的 HTTP 将在报文首部行包括`Connection: keep-alive`，表示 TCP 持续开启。一般来说如果间隔一段时间仍未使用，服务器会关闭该 TCP 连接，此时响应报文的首部行将包含`Connection: close`。

#### 2.2.3 HTTP 报文格式

HTTP 规范由 RFC 1945、RFC 2616、RFC 7540规定，包含了对 HTTP 报文格式的规范。HTTP 包含两种类型的报文：**请求报文**和**响应报文**。

##### HTTP 请求报文

HTTP 请求包含一个**请求行（request line）**、一个或多个**首部行（header line）**、一个**空行**和**实体体（entity body）**。每个行使用一个空格和一个回车（**CRLF**，Carriage-Return Line-Feed）分隔。

+ 请求行：请求行包括三部分，**HTTP 请求方法**、**URL**、**HTTP 协议版本**，每个字段用空格分隔，最后加上 CRLF；
+ 首部行：首部行包括两部分，**首部名**字段和**首部值**，两者用冒号分隔，最后加上 CRLF；
+ 实体体：**实体体**包含要发送的数据，也称请求体，各种超媒体对象会被**编码并封装**在实体体中。

以下是一个 HTTP GET 请求报文：

```http
GET /hello.txt HTTP/1.1
User-Agent: curl/7.16.3 libcurl/7.16.3 OpenSSL/0.9.7l zlib/1.2.3
Host: www.example.com
Connection: keep-alive
Accept-Language: en, mi

```

**User-Agent** 首部行表示发送的客户端类型，**Connection** 表示 TCP 连接状态，**Host** 表示超媒体对象所在主机名，**Accept-Language** 表示请求的语言类型。

##### HTTP 响应报文

HTTP 响应包含一个**状态行（status line）**，以及一个或多个**首部行**、**空行**和**实体体**。状态行包括：

+ HTTP 协议
+ 响应状态码
+ 状态消息

以下是一个 HTTP GET 响应报文：

```http
HTTP/1.1 200 OK
Connection: keep-alive
Date: Mon, 27 Jul 2009 12:28:53 GMT
Server: Apache
Last-Modified: Wed, 22 Jul 2009 19:15:56 GMT
Content-Length: 51
Content-Type: text/html

<html><head><title>Hello</title></head><body></body></html>
```

**Date** 首部行表示服务器发送该报文的时间，**Server** 表示发送该报文的服务器进程类型，**Last-Modified** 指示超媒体对象创建或更改的最后时间，**Content-Length** 表示超媒体对象的字节数，**Content-Type** 表示实体体中的超媒体对象的类型，根据其值和实体体内容可以判断，报文封装的对象为 HTML 文档。

#### 2.2.4 客户端和服务器交互途径：cookie

HTTP 服务器**应该是无状态的**，这简化了 HTTP 服务器的设计。但是，有时服务器会希望鉴别用户身份，这是需要使用 **cookie** 技术。cookie 在 HTTP 之上建立了一个会话层。由于服务器可以从请求报文中获取客户端信息，并且 cookie 存在被窃取的风险，目前越来越多的 Web 项目逐渐开始使用其他技术取代 cookie 。

cookie 一般包含四个组件：

+ HTTP 响应报文包含一个或多个`Set-Cookie:`首部行，其值为 cookie 名称和值以及客户端存储 cookie 的路径，格式为`cookieName=cookieValue; path=/`，指示客户端存储 cookie
+ HTTP 请求报文包含一个`Cookie:`首部行，其值为 cookie 的字符串
+ 客户端系统保存的 cookie 文件，在浏览器中由浏览器管理
+ 服务器上的一个数据库系统，保存一些必要的用户信息，用来指示如何设置客户端 cookie

#### 2.2.5 Web 缓存

**Web 缓存（Web cache）**也叫**服务器代理（proxy server）**，这些服务器可能位于客户端本地（如 Web 本地缓存），也可能由 ISP（本地运营商和 VPN 提供方） 搭建。代理服务器位于客户端和实际服务器之间，分两种：

+ **正向代理服务器**：正向代理服务器用于代理客户端数据，代理服务器首先接收来自客户端的 HTTP 报文，将其进行处理后转发给真实服务器，接收来自真实服务器的响应报文，再发送给客户端。正向代理有隐藏客户端实际信息、绕过局域网限制的作用；
+ **反向代理服务器**：反向代理（reverse proxy）是针对真实服务器的代理，反向代理服务器接收来自客户端的请求，根据需求处理报文并决定转发。反向代理服务器具有负载均衡、攻击防范、最优节点选择的功能。

Web 缓存服务器一般是反向代理服务器。在客户端和真实服务器间存在反向代理服务器的情况下，一个客户端请求将进行如下处理：

1. **Web 浏览器**创建一个到反向代理服务器的 TCP 连接，成功后发送一个 HTTP 请求；
2. **代理服务器**截获该请求，并查看代理服务器的本地缓存是否有客户端请求对象副本。如果有，则封装该对象，向客户端返回响应报文；
3. 如果代理服务器没有缓存该对象，则向**真实服务器**发送客户端 HTTP 报文的副本，或使用其他协议发送一段数据，向真实服务器请求对象，并接收来自真实服务器的响应数据，处理后或直接转发给客户端。
4. 代理服务器缓存来自真实服务器的未缓存对象，准备响应下一次客户端请求

反向代理服务器可以大大减少客户端请求的响应时间，减少一个机构到互联网的通信量。有时安装 Web 缓存服务器可能比升级链路更加经济。

如果缓存服务器返回的是缓存资源，响应报文将**不带有** Content-Length 头和实体体，因为没有没有资源从真实服务器返回。如果缓存资源在**本地**，本地客户代理（浏览器）将带有 Last-Modified 头的请求发向真实服务器后，真实服务器在缓存未过期时返回的响应码和响应状态为 304 Not Modified，但用户代理可能会考虑向用户显示 200 OK 的响应状态（浏览器调试控制台）。

如果缓存资源在某个**远程代理**服务器上，对于用户代理而言，对代理的请求和对真实服务器的请求的响应是一致的，用户代理并不知道在于远程代理沟通。如果远程代理返回的是远程代理上的缓存资源，客户代理收到的响应状态码和状态**仍为** 200 OK 或其他，而不是 304 Not Modified 。

##### 内容分发网络

**CDN（Content Delivery Network，内容分发网络）**是部署在互联网边缘服务器上的虚拟网络，实现负载均衡、内容分发、通信调度功能，让用户能够就近获取需要的数据。本质上 CDN 是一种正向代理与反向代理结合的 Web 缓存器。

#### 2.2.6 条件 GET 方法

Web 缓存器中存放的缓存对象可能并不是最新的，HTTP 通过**条件 GET** 提供验证缓存对象有效性的机制。该机制运作过程如下：

1. **Web 浏览器**向 Web 缓存器发送一个带有`Last-Modified: 时间`首部行的请求报文；
2. **Web 缓存器**检查是否缓存了该对象，如果缓存，缓存器向真实服务器发送一个带有`If-modified-since: 时间`首部行的请求报文；
3. **Web 服务器**根据`If-modified-since:`首部行的值判断是否需要向 Web 缓存器发送最新的超媒体对象。如果需要则发送包含该对象的响应报文，如果不需要，Web 服务器向缓存器返回一个状态为 **304 Not Modified** 的响应。

### 2.3 因特网中的电子邮件

因特网中的**电子邮件服务**通常由三个主要部分组成：

+ **用户代理（user-agent）**
+ **邮件服务器（mail server）**
+ **简单邮件传输协议（Simple Mail Transfer Protocol，SMTP）**

一个典型的邮件发送过程如下：

1. 发送方用户代理将邮件发送至发送方邮件服务器
2. 发送方邮件服务器将邮件发送至接收方邮件服务器
3. 接收方邮件服务器将邮件发送至接收方用户代理

有时收发的邮件服务器双方可能无法正常发送邮件，比如接收方邮件服务器宕机，此时发送方邮件服务器会将邮件报文加入一个**报文队列（message queue）**，在一定时间内保存报文并定时尝试发送。

#### 2.3.1 SMTP

简单邮件传输协议 SMTP 是**用户代理与邮件服务器、邮件服务器间**相互通信的协议。SMTP 服务使用者有两方：发送邮件的邮件服务器和接收邮件的邮件服务器。该协议由 RFC 5321 定义。

SMTP 对报文体有一定限制，要求体部分只能由 7 比特 **ASCII** 码组成。SMTP 操作过程基本如下：

1. **发送方用户代理**发送报文至发送方服务器，并提供接收方**邮件地址**，双方也使用 SMTP 交流
2. **发送方服务器**接收报文，将报文放入报文队列；当需要发送报文时，发送方服务器建立一条到接收方服务器的 **TCP 连接**
3. **接收方服务器**与发送方服务器进行 **SMTP 握手**，成功后通过 TCP 连接传输报文
4. **接收方用户代理**接收来自接收方服务器发送的报文

SMTP 一般**不使用**中间服务器发送邮件。发送方服务器和接收方服务器一般是直接连接的，即邮件报文不会在中间服务器中保留。

##### 持续连接

SMTP 采用**持续连接**，TCP 连接通过**套接字端口 25** 建立，收发方服务器建立连接后可以传输多条报文，直到发送方指示关闭连接。

##### SMTP 握手

在传输报文前双方服务器将进行 **SMTP 握手**：

1. 客户端（发送方服务器）与服务器（接收方服务器）建立 TCP 连接，服务器返回 SMTP 状态码和服务器主机名
2. 客户端向服务器发送一条 HELO 命令，并提供客户端主机名
3. 服务器返回 SMTP 状态码和响应报文
4. 客户端发送一条 MAIL FROM 命令并提供发送方邮件地址
5. 服务器检查邮件地址，无错误则返回状态码和检查结果
6. 客户端发送一条 RCPT TO 命令并提供接收方邮件地址
7. 服务器检查邮件地址，无错误则返回状态码和检查结果

SMTP 握手结束后，客户端就开始传出右键内容。对应的 TCP 握手和 HTTP 一样也是三次：客户端请求连接、服务器返回确认、客户端返回确认。

##### SMTP 过程演示

下方演示一个 SMTP 报文传输过程，其中的字符串是客户端与服务端交给 TCP 套接字的行：

```SMTP
S: 220 hamburger.edu
C: HELO crepes.fr
S: 250 Hello crepes.fr, pleased to meet you
C: MAIL FROM: <alice@crepes.fr>
S: 250 alice@crepes.fr... Sender ok
C: RCPT TO: <bob@hamburger.edu>
S: 250 bob@hamburger.edu... Recipient ok
C: DATA
S: 354 Enter rnail, end with "." on a line by itself
C: Do you like ketchup?
C: How about pickles?
C:.
S: 250 Message accepted for delivery
C: QUIT
S: 221 hamburger.edu closing connection
```

客户端总共向服务端发送了 6 种 SMTP 握手协议命令：

+ HELO：第一次握手
+ MAIL FROM：邮件来源
+ RCPT TO：接收地址
+ DATA：表示正文开始
+ CRLF.CRLF：表示正文结束
+ QUIT：传输完毕，关闭连接

QUIT 命令只有在所有右键发送完毕后才会发出。每条右键从 MAIL FROM 开始至 CRLF.CRLF 结束，新的邮件再次才能从 MAIL 开始。

#### 2.3.2 与 HTTP 的区别

SMTP 是一个**推协议（push protocol）**，客户端从服务端拉取需要的数据，并由想要获得数据的端系统（即客户端）发起 TCP 连接；而 HTTP 是一个**拉协议（pull protocol）**，客户端将数据推向服务端，TCP 由将要推送数据的端系统（即客户端）发起。

SMTP 要求每个报文采用 7 比特的 ASCII 码格式，而 HTTP 对报文内容编码没有限制。

对于包含多种媒体类型的报文，HTTP 把所有媒体对象都封装在响应报文实体体中，而 SMTP 把所有对象封装在一个报文中（没有响应和请求之分）。

#### 2.3.3 邮件报文格式

邮件的报文格式由 RFC 5322 定义。右键首部行和报文体部分用一个空行分隔。首部行**必须包含**`From: <发送地址>`和`To: <接收地址>`，可以包含`Subject: <信息主题>`。

```SMTP
From: alice@crepes.fr
To: bob@hamburger.edu
Subject: Searching for the meaning of life.
```

#### 2.3.4 邮件访问协议

SMTP 是用来发送邮件的协议，要想从端系统访问服务器上的右键，则需要使用邮件访问协议，流行的邮件访问协议有：

+ **第三版邮局协议 POP3**
+ **因特网邮件访问协议 IMAP**
+ **超文本传输协议 HTTP**

##### POP3

**POP3**协议非常简单。当客户端与服务器之间的 TCP 连接在**套接字端口 110** 上建立之后，POP3 就可以提供服务。POP3 包括三个阶段：

1. **授权（authorization）**阶段：客户端提供用户名和密码
2. **事务处理**阶段：客户端可以将邮件标记为删除、解除标记、获取邮件内容和相关统计信息
3. **更新**阶段：发生在客户端发出退出请求后，根据标记更新邮件列表

POP3 服务的回答有两种：成功时的`+OK`和错误时的`-ERR`。授权阶段可以使用两个命令：`user <user name>`和`pass <password>`。授权阶段结束后进入事务处理阶段，可以使用`list`命令拉取邮件列表，使用`retr`命令获取列表中对应序号的邮件报文内容，使用`dele`将一个邮件标记为删除。更新阶段发生在客户端发出`quit`命令后，此时 POP3 服务器会根据标记操作邮件列表。

POP3 的主要问题是过于简单，并且一般只有下载后删除和下载并保留方式，前者使得一份邮件不能在多个端系统中被多次访问，而后者一次也只能下载全部邮件内容，不能访问部分信息如只获得邮件标题。

POP3 服务器只会保存一些会话中的状态信息，如删除标记，而不会保存用户的其他信息。

##### IMAP

**因特网邮件访问协议**比 POP3 复杂得多，一个 IMAP 服务器会将每个报文与一个文件夹关联起来，如第一次进入邮箱的邮件会进入`INBOX`文件夹。与 POP3 不同，IMAP 还会维护用户访问状态，如读取过的邮件会被转移到其他文件夹中。此外，通过 IMAP 可以获取报文的一部分片段。

##### HTTP

使用 **HTTP** 时客户端进程就是浏览器，用户通过浏览器访问和管理邮件，并指示服务器通过 SMTP 协议发送邮件。

### 2.4 DNS：因特网的目录服务

域名是对人类友好的一种因特网标识符。域名由**顶级域名（TLD）**、**二级域名（SLD）**和**主机名（host name，或称三级域名）**组成。以`www.amazon.com`为例：

+ `www`：主机名
+ `amazon`：二级域名
+ `com`：顶级域名

一个完整的域名只需要包括二级域名和顶级域名，称为**域（Domain）**，而同时包括了主机名的域名被称为**完全限定域名（FQDN）**，也可以被称为完整的**主机名（hostname）**。每个 FQDN 可能会获得一个独一无二的 IP 地址，也可能会被分配一个局域网地址，由局域网进行转发，但是每个包含二级域名和顶级域名的域名都会有一个 IP 地址。

对于链路层以下的路由器来说，域名对它们是不友好的，因为域名没有固定的严格格式，路由器需要使用 **IP 地址**在互联网中寻址。为了能够让域名和 IP 地址互相转换，就需要使用到 DNS 。

#### 2.4.1 DNS 提供的服务

**DNS（域名系统）**的**主要任务**就是提供一种把域名转换成 IP 地址的目录服务。DNS 是一个由 **DNS 服务器**实现的**分布式数据库**，也是一种让因特网中各存在点能够进行查询分布式数据库的**协议**。DNS 基于 **UDP**，使用套接字**端口 53**。DNS 不直接与用户打交道，而是为因特网上的其他进程提供服务。

DNS 通常由其他应用层协议使用，如 HTTP、SMTP、FTP。客户端进程在建立基于域名的连接前总是先请求 DNS 服务器。当 HTTP 通过一个 URL 请求一个资源时，会发生以下事情：

1. 浏览器将域名发送给本机上的 DNS 客户端进程
2. **DNS 客户端**从 URL 中提取域名部分，并将域名转发给 DNS 服务器
3. **DNS 服务器**接收到客户端请求，根据域名找到对应的 IP 地址，并封装在响应报文中返回给客户端
4. DNS 客户端接收到响应报文并取得 IP 地址，并将 IP 地址转发给浏览器
5. 浏览器将 IP 提交给套接字，由套接字发起到服务器的 TCP 连接并传输 HTTP 报文

DNS 会给 HTTP 以及其他应用层协议的传输带来额外的时延，因此客户端想要获取的 IP 地址一般会在就近的 DNS 服务器中缓存。除了域名转换，DNS 还提供以下服务：

+ 主机别名（host aliasing）：有时一台主机可能有多个域名，主要域名被称为**规范主机名**。DNS 需要提供别名对应的规范主机名以及其对应的 IP 地址
+ 邮件服务器别名：和主机别名一样，DNS 服务器需要提供别名对应的主要名称和 IP 地址
+ 负载均衡（Load Balance）：也称负载分配（Load Distribution）。如果一个服务器要负责世界范围内的所有请求，那这个服务器应该会有非常大的缓存队列和处理能力。因此实际上因特网中的服务器会存在冗余，即多个服务器负责维护和转发同样的资源。一般来说 DNS 服务器中有一张这些冗余服务器的列表，在获取处理请求时从列表中循环取出冗余服务器的 IP 地址，或者根据某些规则选择，从而分担每个服务器的负担，实现负载均衡

#### 2.4.2 DNS 工作机理

用户端系统上有许多客户端进程，这些进程为了通过域名发送报文就需要使用 DNS 客户端向 DNS 服务端请求域名对应的 IP。所有 DNS 请求和响应都通过**套接字端口 53** 发送，经 **UDP 协议**传输。

最简单的 DNS 服务器设计是在整个互联网上只部署一台服务器，由该服务器处理所有 DNS 请求。这明显是不现实的，因为：

+ 单点故障：一旦该服务器宕机，整个因特网都将崩溃
+ 通信容量：一台 DNS 服务器无法同时处理所有请求
+ 远距离的集中式服务器：世界各地的端系统都要使用同一个服务器查询数据库，时延不可接受
+ 维护：每当有新的 IP 和域名出现，集中式数据库就要进行扩展

因此，实现中的 DNS 服务器都是分布式的。为了确认在不可靠的 IP 协议上进行的 IP 查询是否正确，DNS 会使用另一个可靠的网络层协议 ICMP 来确认是否有查询错误。

##### 分布式分层数据库

没有一台 DNS 服务器拥有世界上所有的域名和 IP 映射，DNS 服务器实际上是分层且分布的。大致来说，因特网中有三层 DNS 服务器：

+ **根 DNS 服务器**：目前大致有 400 多个根服务器分布于全球，根服务器是本地 DNS 客户端首先访问的 DNS 服务器，根服务器会根据客户端提供的域名中的**顶级域名**查找出负责顶级域名查找的顶级域服务器的 IP 地址
+ **顶级域 DNS 服务器**：顶级域服务器则是根据客户端提供的域名的**二级域名**部分查找出负责的权威服务器
+ **权威 DNS 服务器**：之所以称为“权威”，是因为这类 DNS 服务器通常由一些持有域名的组织所管理，这些组织还拥有其他的完全限定域名，因此由这些组织提供权威服务器来查找 FQDN 对应的 IP 地址

在这三层结构之外还有一个**本地 DNS 服务器**。一般来说每个 ISP 都有一台或多台本地 DNS 服务器。当客户端与 ISP 连接时，会首先与 ISP 的一台主机连接，该主机上保存有 ISP 的一台或多台 DNS 服务器的 IP，该主机会通过 DHCP 服务器选择适合的 DNS 服务器。对于一个机构的 ISP 来说，DNS 服务器和客户端可能就在一个局域网中，对于地区 ISP 来说，客户端和 DNS 服务器间可能也就隔了几台路由器。

假设现在有两台端系统要通过双方的域名建立端到端的 TCP 连接，在建立 TCP 之间，发起连接的一端的套接字需要知道另一端的 IP 地址，因此需要先通过 DNS 服务器获取 IP ：

1. 首先，客户端的 **DNS 应用**进程会向本地 DNS 服务器发起请求，查询域名的 IP 地址
2. **本地 DNS 服务器**接收请求，并与根 DNS 服务器建立**连接**
3. **根 DNS 服务器**根据域名中的**顶级域名**确定了顶级域 DNS 的 IP，并将其返回给本地 DNS 服务器，本地 DNS 与顶级域 DNS 建立**连接**
4. **顶级域 DNS 服务器**根据域名中的**二级域名**确定了权威 DNS 的 IP，并将其返回给本地 DNS 服务器，本地 DNS 服务器再与权威 DNS **连接**
5. **权威 DNS 服务器**根据 **FQDN** 确定了服务端的 IP 地址，并将其**返回**给本地 DNS
6. **本地 DNS 服务器**将服务器的 IP 返回给客户端
7. 客户端根据服务器 IP 建立一条到服务器的 TCP 连接

整个过程中，客户端**只和本地 DNS 服务器进行了通信**，并从本地 DNS 的回答报文中并获取了查询域名的 IP，在这之后与服务器建立连接，多层 DNS 服务器中间的通信客户端是不知道的。本地 DNS 客户端从本地 DNS 服务器获得的回答报文内容只含有本地 DNS 服务器获取的回答，一般只包括 A、AAAA、CNAME、MX。如果本地 DNS 服务器绕过了根和顶级域 DNS 服务器，可能会向客户端返回权威 DNS 的信息，类型 NS。

客户端查找本地 DNS 服务器的 IP 地址的过程是一种**递归查询**，没有经过其他中间 DNS；而各层 DNS 间的查询是**迭代查询**，经过了多层 DNS 服务器。

##### DNS 服务器缓存

由于 DNS 间的查询是迭代的，查询链越长产生的时延将会越大，因此 DNS 服务器中还有很重要的一环：**DNS 缓存**。如果查询链中某一层 DNS 服务器缓存了整个域名指向的 IP 地址，它就会直接将该 IP 地址返回，而不用继续迭代。缓存不是永久的，DNS 服务器通常会在两天之后清除缓存信息。通过 DNS 缓存，本地 DNS 就可以绕过其他层的 DNS ，快速查找到 IP 地址。

#### 2.4.3 DNS 记录和报文

实现了 DNS 分布式数据库的 DNS 会保存**资源记录（Resource Record，RR）**，RR 提供了域名和 IP 的映射。RR 是包含以下信息的四元组：

+ Name：主机名、域名、规范主机名或邮件规范主机名，由 Type 决定
+ Value：某个主机的 IP 地址
+ Type：指示信息类型
+ TTL：记录生存时间，指示缓存信息应该存在多久

Type 会有以下几种类型：

| Type  |       Name       |          Value          |
| :---: | :--------------: | :---------------------: |
|   A   |      主机名      |    主机名对应的 IPv4    |
| AAAA  |      主机名      |    主机名对应的 IPv6    |
|  NS   |       域名       | 权威 DNS 服务器的主机名 |
| CNAME |     主机别名     |       规范主机名        |
|  MX   | 邮件服务器主机名 | 邮件服务器的规范主机名  |

##### DNS 报文格式

DNS 只有两种报文类型：**查询（query）**和**回答（answer）**，并且两种报文使用同一种格式（查询报文没有回答字段）。

DNS 头部：

+ **标识符**：16 比特的标识符，每一个查询-回答报文对的标识符是相同的
+ **标志位（flags）**：标志位可以有多个标志，总长度为 16 位，按照顺序分别为：
  1. 1 比特标志位，查询报文为 0 ，回答报文为 1
  2. 1 比特标志位，如果 DNS 是请求的主机名的权威服务器，该标志位为 1
  3. 1 比特标志位，当客户端希望进行递归查询时为 1
  4. 1比特标志位，如果服务器能够递归查询为 1
+ 问题数：所有查询数量，16 位
+ 回答 RR 数：16 位
+ 权威 RR 数：16 位
+ 附加 RR 数：16 位

DNS **问题区域**：报文该部分包含了正在查询的问题信息，包括：

+ Name 字段：正在被查询的主机名
+ Type 字段：查询类型，如 A

DNS **回答区域**：该区域包含：

+ Name 字段：被查询的主机名
+ Type 字段：查询类型
+ Value 字段：IP 地址

DNS **权威区域**：包含权威服务器的一些信息。

DNS **附加区域**：包含其他有帮助的记录。

##### nslookup

在 Linux 和 Windows 中有一个命令行软件 **nslookup**，nslookup 会查询给定主机名的 IP 地址，并将查询结果以对人友好的格式打印。

```shell
nslookup www.baidu.com
nslookup -type=MX www.baidu.com
```

##### ipconfig

命令行软件 **ipconfig** 可以查看本地 IP 相关的配置信息。

```sh
ipconfig/all
ipconfig/displaydns
ipconfig/flushdns
```

##### 向 DNS 数据库插入数据

如果要将自己的域名和 IP 地址插入 DNS 数据库，第一件事就是向**注册登记机构（registrar）**注册域名。这些机构是一些商业实体，负责验证域名的唯一性。

等级域名时，需要提供注册的域名的**基本和辅助权威 DNS 服务器的名字和 IP 地址**，注册机构会确保一个类型为 NS（域名）的 RR 与一个类型为 A（主机名）的 RR 被加入到 TLD DNS 服务器的数据库中。

由于一个域名下有多个主机名，还需要确保这些**主机名的 RR 被加入到权威 DNS 服务器的数据库中**，注册机构只负责处理 TLD DNS 事务，这些事务需要注册人完成。

一旦完成这些步骤，用户就可以通过域名访问注册人的网站或者电子邮件服务了。

##### DNS 安全

DNS 也会被攻击。**DDoS 的带宽洪泛攻击**可能会导致 DNS 接收过多的请求而难以正常运作，不过一般来说，根 DNS 受此类攻击影响较小，因为根服务器会受到下级分组交换机过滤器的保护，此外一些 DNS 缓存也会绕过根 DNS 服务器。

**中间人攻击**是另外一种攻击方式，中间人通过截获报文，伪造报文内容，向客户端发送伪造的 IP 地址。**DNS 毒害攻击**则向 DNS 服务器发送伪造的报文，使得 DNS 服务器缓存了伪造的 RR 。这两种 DNS 劫持都会导致客户端的错误重定向。

### 2.5 P2P 文件分发

**P2P（point-to-point）**是一种对中心服务器没有依赖或只有最小依赖的文件分发架构。和客户端-服务器架构不同，P2P 中的对等方是**由用户控制的机器**。一个简单的 P2P 架构实现会和客户端-服务器架构类似，即由单一服务器向大量客户端主机发送文件。而实际上的 P2P 架构允许每一个对等方向其他任何对等方**重新**发送它们已经接收的文件的**任何部分**。P2P 架构具有很强的**自扩展性**，任何用户机器都可以成为其中的一员。

#### BitTorrent

**BitTorrent（比特洪流）**是目前最为流行的 P2P 文件分发协议。BitTorrent 中参与**一个特定文件**的分发的所有对等方**集合**被称为一个**洪流（torrent）**，在一个洪流中的对等方下载的文件整体或部分被称为一个文件**块（chunk）**。每个对等方在下载完文件后，可以选择离开洪流或留在洪流中向其他对等方分发文件，因此这种鼓励交换的机制也被称为“一报换一报（tit-for-tat）”。

BitTorrent 是一个非常复杂的协议，但也基于一些基本的机制运行。每个文件的洪流都有一个**基础设施节点**，称为**追踪器（tracker）**。每当一个对等方加入洪流，就会向追踪器**注册**自己。当一个新的节点加入洪流时，追踪器会随机地从对等方集合中选取一些节点的 IP 地址发送给新的对等方，新的对等方则根据这些 IP 地址尝试向其他对等方建立 **TCP 连接**并下载文件。基础设施节点是洪流存在的前提，如果该节点离开互联网，整个洪流都会断开，因此每个洪流可能有**多个**追踪器存在，有时这些追踪器可能位于某台专注于提供 BitTorrent 服务的服务器上，这些服务器将保证洪流的运作。

BitTorrent 中还有一种被称为**最稀缺优先（rarest first）**的技术，在对等方请求一个文件的分发时，协议会选择该文件中在整个洪流中最稀缺的**块**，并优先进行传输，使得整个洪流中最稀缺的块更为迅速的重新分发。

**疏通（unchoked）**是另一项技术，当文件请求方向其他节点进行块请求时，那些对于请求节点来说具有**最大传输速率**的节点有最大优先权。这使得整个洪流中的对等方能以最快的速度分发完内容，而不会使得洪流堵塞。

### 2.6 流媒体和内容分发网络

#### 2.6.1 HTTP 流

**HTTP 流**的主要服务对象是因特网中的视频文件。每一个视频在 HTTP 服务器中只是一个简单的视频资源文件，当客户端请求该文件时，服务器就将视频封装在一个响应报文中返回给客户端。客户端通过类似流的处理方式，一旦响应报文的一部分到达就将其**缓存**，当缓存数量到达规定大小时，就对视频的帧进行解码，并在客户端中播放，因此客户端可以在没有接收到整个文件时就播放视频内容。

#### 2.6.2 DASH

简单的 HTTP 流有一个**重大缺陷**：所有用户在不同时间只能请求相同编码的视频文件。为了应对不同的客户端和带宽情况，**经 HTTP 的动态适应性流（Dynamic Adaptive Streaming over HTTP）**，也称 **DASH**，将一个视频分为不同编码的版本，这些版本将具有不同的**比特率**。当带宽较高时，向客户端发送高比特率的视频**块**，反之发送低比特率的视频块。

#### 2.6.3 CDN

对于提供流媒体访问服务的服务器来说，要在同一时间处理来自世界各地的 HTTP 请求的压力是巨大的，且面临着时延和单点故障等问题。现在，几乎所有流媒体内容提供商都使用**内容分发网络（Content Distribution Network，CDN）**。CDN 既可以是由内容提供商自己提供的**私有 CDN**，也可以是由第三方提供的**第三方 CDN**。

##### CDN 操作过程

CDN 基于 **DNS** 协议进行内容动态分发。当用户请求一个由 CDN 负责的资源时，会发生以下事情：

1. HTTP （或其他协议）**客户端**请求一个资源，并向其本地 DNS 服务器发送一个主机名查询报文，本地 DNS 服务器向权威 DNS 服务器查询 IP 地址
2. **权威 DNS**注意到这是一条资源请求，需要将其转交给某个 CDN 提供方。权威 DNS 根据找到了最适合承担分发的 CDN 服务器的**主机名**，并将其返回给本地 DNS
3. 本地 DNS 收到该主机名，并查询该 CDN 服务器主机名的 IP 地址，然后返回给客户端
4. 客户端根据该 IP 地址向 CDN 服务器请求资源

##### 集群选择策略

权威 DNS 在选择适合的 CDN 提供方服务器时会根据**集群选择策略（cluster selection strategy）**选择需要的 CDN。这种策略可能会根据客户端 IP 地址选择地理上**最接近**的 CDN，也可能会进行**流量控制**，选择压力较小的 CDN。

### 附：HTTPS 加密技术

早期的 HTTP 技术将报文内容以明文形式在网络中进行传输，任何中间节点都可以截获报文内容，客户端和服务端通信安全无法得到保障。为了防范**中间人攻击**（来自数据路径中任意节点），一种新型 HTTP 传输协议：HTTP + SSL/TLS，也称**安全的超文本传输协议 HTTPS** 被提出。HTTPS 基于对称加密和非对称加密技术，可以有效防范中间人攻击问题。

#### 对称加密

**对称加密**是使用单个密钥进行加密和解密的密码技术，对称加密一般有一个实际无法破解的密码函数，每一对加密方都必须实现约定双方的密钥。

1. 通信双方协商一个私钥 **K**；
2. 发送方使用 K 加密明文；
3. 接收方使用 K 解密密文。

#### 非对称加密

**非对称加密**也被称为**公钥加密**，在非对称加密场景下，有两个密钥，加密函数允许使用一个密钥进行加密，另一个密钥进行解密，两个密钥间有某种数学性关联。一般来说，两个密钥中有一个密钥需要公开，被称为**公钥**，另一个私有密钥称为**私钥**。

1. 接收方生成一个公钥 **K** 和私钥 **K'**；
2. 接收方将 K 给予发送方；
3. 发送方使用 K 加密明文；
4. 接收方使用 K' 解密密文；
5. 如果通信是双向的，双方各自生成一对私钥和公钥。

#### HTTPS 中的非对称加密与对称加密

对于 HTTP 而言，任何报文内容都以明文传输，如果服务器和浏览器在一开始需要使用对称加密，就必须事先在浏览器中存储任何可能网站的密钥，这显然是不现实的。因此，在 HTTPS **握手**阶段，服务器会以 HTTP 方式明文发送一个**公钥**到客户端，客户端将使用该公钥加密任何**请求**，并只有服务器能够使用其私钥解密。非对称加密的运算是**昂贵**的，因此不可能用作每次交互的安全保证。在 HTTPS 的握手阶段结束后，**客户端**会选择一个**私钥**包含在一个响应报文中，使用公钥对报文内容加密，因此只有服务器能解密该私钥，之后所有的交互都使用该私钥进行**对称加密**。

1. 客户端发起 HTTPS 握手，服务器返回一个对应自己的私钥 **A'** 的公钥 **A**
2. 客户端获取 A，生成一个私钥 **K** 用于之后的对称加密传输，发送给服务器；
3. 服务器获取私钥 K，使用 K 加密和解密之后所有的请求和响应。

#### 可能的中间人攻击

现在考虑只有对称加密和非对称加密下的 HTTPS 的安全性。如果服务器和浏览器间存在中间人攻击，中间人就可以截获 HTTPS 握手阶段中发送的公钥，并生成一个中间人的公钥发送给客户端。整个攻击过程大致如下：

1. 客户端向服务器发起 HTTPS 连接请求，服务器以明文响应自己的私钥 **A'** 对应的公钥 **A**；
2. **中间人**截获该公钥报文，生成一个自己的公钥 **B** 和私钥 **B'**，将前者发送给客户端；
3. 客户端误认为 B 是正确的公钥，生成了一个私钥 **K** 用于之后的对称加密传输，使用 B 加密，将其发送给**中间人**；
4. 中间人使用 B' 解密 K，另外选择一个 K' 或使用当前 K 封装请求，使用公钥 A 加密请求并发送给服务器；
5. 服务器误认为自己在与客户端进行安全通信，之后所有信息全部通过 K 或 K' 对称加密传输，中间人因此可以解密所有信息明文。

#### CA 数字证书

可以看出，上述中间人攻击反映的**问题**是：客户端无法确认自己收到的公钥一定是服务器的公钥。为了解决该问题，就需要对公钥进行验证，即使用由 **CA 机构**颁发的 **CA 数字证书**。CA 证书中包括证书持有者（服务器）的信息，如域名，以及公钥本身的信息。在进行公钥传输之前，服务器会先将数字证书传输至客户端进行缓存，用于验证公钥合法性。

#### 用于 CA 证书的非对称加密

证书本身也可能像公钥一样被中间人篡改。为了进行证书本身的验证，就需要使用一种基于**哈希函数**和非对称加密的安全保证。在 CA 机构颁发证书时，会根据证书内容生成一个唯一哈希值，并使用 CA 机构自己的**私钥**对哈希值进行一次非对称加密，对应的**公钥**会事先被客户端**持有**，加密结果称为**数字签名**。如果存在任何对证书的中间人攻击，尝试篡改公钥字段或直接用另一份修改过的证书进行替换，都会导致哈希值变化，而中间人在没有私钥的情况下将无法生成正确的签名。客户端使用持有的 CA 机构的公钥解密证书的签名字段并与自己生成的哈希对比，如果出现篡改，则两者不相等，丢弃该证书。

#### CA 机构根证书

客户端实现持有的 CA 哈希公钥自身的真实性由 CA 机构**根证书**保证。大部分客户端，包括操作系统和浏览器都会存有这些根证书，一个 CA 机构的根证书认证又可能来自于其他 CA 机构，以形成一条**数字证书链**。如果证书颁发机构没有被客户端信任，可能需要手动安装证书，并且客户端在法律上不再对后续风险负责。

#### HTTPS 加密全过程

考虑到每次哈希和非对称加密解密的性能问题，一般客户端会缓存所有计算结果，而服务器会使用一个数据库维护一些**会话 ID（session ID）**记录客户端产生的对称加密密钥。因此整个 HTTPS 加密过程如下：

1. 客户端预先持有受信任的 CA 机构发布的 **CA 公钥** K~ca~；
2. 服务器向 CA 机构申请 **CA 证书**，将其非对称加密**公钥** K~s~ 纳入证书，CA 机构使用 **CA 私钥** K~ca~' 非对称加密**证书哈希值**并存在证书哈希字段中；
3. 客户端向服务器发起 HTTPS 请求，服务器返回其 CA 证书和非对称加密公钥 K~s~，客户端使用 K~ca~ 验证证书合法性并对比 K~s~合法性；
4. 如果 K~s~ 合法，客户端生成一个**对称加密密钥** K，使用 K~s~ 对其加密并发送给服务器，并缓存该证书和解密后哈希值；
5. 服务器使用 K~s~' 解密获取 K，并在缓存或数据库中为客户端生成一个临时**会话 ID** uid，在本次 HTTPS 会话中均使用该 uid 获取对应的 K，在会话结束时销毁该映射；
6. 之后客户端和服务器使用对称加密进行所有通信。

思考：

+ 为什么使用对称加密和非对称加密结合的方式？
+ 为什么不只用非对称加密？
+ 为什么要使用数字证书？
+ 为什么要使用数字签名？

---

## 第三章 运输层

### 3.1 概述

运输层提供**端到端**的**逻辑通信（logical communication）**服务。所谓逻辑是指运输层能使两台端系统上的应用进程**看起来**像在进行直接的通信。实际上，两台端系统的通信经过了许多分组交换机，并由多条链路**物理（实际）连接**。

因此，运输层协议的**实现**是在端系统而不是路由器中的。应用层协议会将分组（称为报文）交给运输层封装成**报文段（segment）**，运输层再将报文段交给网络层封装为数据报。在因特网中有两种重要的运输层协议：**UDP** 和 **TCP**。

#### 运输层与网络层的关系

运输层提供**进程之间**的通信，即端到端；而网络层提供**主机之间**的通信，即点到点。运输层能够提供的服务通常受限于网络层的服务模型，但可以在网络层服务模型之上进行扩展，如 TCP 和 UDP 对网络层 IP 协议的扩展。

**因特网协议（Internet Protocol，IP）**提供的是一种**尽力交付**服务，不做任何形式的担保。IP 不确保报文段一定会被交付，不保证报文段按序交付，也不保证报文段数据完整性。因此 IP 被称为**不可靠服务**。因此运输层协议会对 IP 协议做扩展，在一定程度上保证报文段传输的可靠性。

#### 运输层协议的基本任务

运输层协议的**最基本职责**是，将主机间的分组交付扩展为进程间的分组交付。IP 协议交付的分组无法被应用层进程直接接受，因此运输层协议要负责**拆封**数据报内容，并递交给应用层进程。这一过程称为运输层的**多路复用（transport-layer multiplexing）**和**多路分解（demultiplexing）**。

与 IP 一样，UDP 也是一种不可靠服务，仅提供上述两种基本服务。而 TCP 停供更多附加服务，如可靠数据传输服务和拥塞控制。

### 3.2 多路复用和多路分解

运输层不将报文段中有效载荷的报文部分直接交给应用层进程，而是通过**套接字**进行转交。在发送源端，运输层协议从不同的套接字中接收数据，并将数据封装在报文段中并附加头部信息，然后将报文段递交给网络层，这一过程称为**多路复用**。在接收端，运输层协议将网络层递交的报文段分解，取出其中的报文部分，并根据首部信息将其递交给正确的套接字的过程，称为**多路分解**。

**多路**本身是指将多个低速信道，TCP 协议会将报文段分段在网络层中进行传输，因此多路复用实际上是将低速信道合并为高速信道的过程，多路分解正好相反。

#### 套接字端口

运输层要识别正确的套接字，每个套接字就需要有一个**唯一标识符**，而**报文段的首部**需要包含这些标识符信息，TCP 和 UDP 报文都会包含一个**源端口字段**和**目的地端口字段**。

**端口号**是套接字唯一标识符的一部分，是一个 16 比特的数字，大小在 0 ~ 65535 之间。0 ~ 1023 间的端口号被称为**周知端口号**，这些端口号被预留给周知的应用层协议如 HTTP、FTP 等。主机上的每一个套接字都将分配到一个端口号。

#### NMAP

要监听一个位于因特网中的主机开放了哪些端口是非常容易的事情，[NMAP](https://nmap.org)是一种**端口扫描器**，可以扫描指定因特网主机上的所有端口。因此，主机的端口防护变得十分重要，如果某一套机字连接的应用程序存在缺陷，蠕虫和病毒就很容易击溃这些应用并带来更大的安全问题。

#### UDP 数据报和套接字标识符

一个 UDP 套接字的标识符由**目的地 IP 地址**和**目的地端口号**进行唯一标识。如果两个数据报的头部包含同样的标识符，就会被分解到同一个套接字。

由于套接字并没有将源端口号作为标识符的一部分，接收响应时 UDP 协议无法通过套接字标识知道应该将响应分解到哪。因此，UDP 会在发送的请求数据报的头部中包含**源端口号**信息，发送方将在响应中保留该字段，接收方在接收响应时可以得知应该把信息分解到哪个套接字上。

#### TCP 报文段和套接字标识符

TCP 套接字的标识符包含**源 IP 地址**、**源端口**、**目的地 IP 地址**和**目的地端口**。只有当四个部分完全相同时，不同的报文段才会被分解到同一套接字。

#### Web 与 TCP

Web 的基础协议 HTTP 建立在 TCP 服务模型上。当 HTTP 服务端发送请求时，会告知自己的套接字其目的地端口号（默认 80）随后，套接字会通知 TCP 建立一个到 HTTP 服务器的连接。第一次握手时，HTTP 服务器主机上的套接字会为客户端分配一个套接字端口，随后连接将在两台主机间建立。由于服务器上的套接字一次只能处理一个连接，同一台客户端发起的多个 HTTP 请求都将在服务器上分配到不同的端口，具有不同的套接字标识符。

因此，非持续连接的 HTTP 将面临严重的**性能问题**，客户端上的每个 HTTP 请求都将打开一个 TCP 连接并申请套接字。而在持续连接的 HTTP 下，客户端可以通过同一个 TCP 发送请求，减少了套接字的分配。

事实上，现在的 Web 服务器不再为每个连接建立一个进程，客户端到服务器的通讯实际上是**进程到线程**，甚至是**进程到协程**的通信。目前的高性能 Web 服务器应用通常只使用单个进程，而为每个用户申请一个线程；而单线程的 Web 服务器应用则会为每个连接创建一个协程，异步地处理这些请求。

### 3.3 UDP

**用户数据报协议（UDP）**是一种不提供不要服务的最简化运输层协议，事实上 UDP 将其运输的分组称为**数据报（datagram）**而不是报文段，因为 UDP 只对 IP 进行了简单扩展，传输带有用户自定义内容的 IP 数据报。UDP 除了提供少量差错检测和多路复用与分解外并没有在 IP 协议之上增加其他服务。与需要进行可靠数据传输保证的 TCP 不同，UDP 不进行握手，不维护连接状态，因此是一种**无连接**协议。UDP 将应用层报文封装后就立即递交给网络层发送，而不做其他任何事情。如：基于 UDP 的 DNS 协议如果没有收到响应，就会告知应用层进程不能获得响应，或者向另一个 DNS 发送请求。

UDP 相较于 TCP 有几个优势：

+ 更为精简和迅速：UDP 会将应用程序递交的数据直接封装并发送，而 TCP 需要进行可靠传输，并进行拥塞控制，但不注意实际交付究竟需要多少时间，这会导致过多的时延。一些能够容忍数据丢失的实时应用会选择 UDP 协议来减少时延快速；
+ 无须建立连接：UDP 不需要维护连接状态和握手，因此不像 TCP 一样有握手的三次 RTT 。HTTP 之所以使用 TCP，是因为 HTML 文本内容的可靠性非常重要。而新的 HTTP3/QUIC 协议则基于 UDP ，因此具有更快的响应速度，可靠性和其他服务则由该协议自己提供；
+ 无连接状态：TCP 为了维护连接可靠性需要保留一些连接状态信息，如接受和发送缓存、拥塞控制参数等，这些信息会被存储在服务器上。而 UDP 不需要这些状态，一般可以支持更多活跃的用户；
+ 分组首部开销小：UDP 只有 8 字节的首部大小，而 TCP 有 20 字节。

能容忍少量分组的丢失的应用，如因特网电话、视频会议等会选择 UDP 协议，因为 TCP 的拥塞控制会导致这些应用的性能变差。但正是 UDP 没有拥塞控制，可能会因为在同一时间使用最大传输速率传输大量数据，而导致路由器**分组溢出**，继而产生丢包，严重情况下甚至可能挤垮其他的 TCP 通信。因此，现在的 UDP 连接源即服务器可能会采取一些动态的自适应拥塞控制。

#### UDP 数据报结构

UDP 的数据报结构非常简单，头部仅包含四个部分：

+ **源端口号**（source port）：16 bits
+ **目的地端口号**（destination port）：16 bits
+ **长度**（length）：首部加上有效载荷数据的长度：16 bits
+ **校验和**（checksum）：校验和是用来检测数据报正确性的重要指标：16 bits

而 UDP 的**有效载荷（UDP payload）**则封装了应用层的报文。当以太网 MTU 为 576 字节时，UDP 载荷**最大有效长度**为 548 字节（576 - 20（IP 首部） - 8（UDP 首部））；当以太网 MTU 为 1500 字节时，UDP 载荷**最大有效长度**为 1472 字节。

#### 校验和

校验和使得 UDP 能够进行**差错检测**。这种检验是针对**比特位**的。每个 UDP 数据报的校验和是将数据报中所有的 **16 比特字**进行**按位和**之后**按位非**的结果。如果按位和的过程中出现位数溢出，则溢出位**回卷**（加到第一位上）。如果一则 UDP 报文没有出现差错，其所有的 16 位字相加的结果应该是 `0xFFFF`，即 16 位的`1111111111111111`，如果出现 0 ，即说明数据报内容出现差错。

假设一个 UDP 数据报包含下列三个 16 位的字：
$$
0110011001100000\\
0101010101010101\\
1000111100001100\\
$$
前两个 16 位字的和为：
$$
0110011001100000\\
0101010101010101\\
————————\\
1011101110110101
$$
与第三个 16 位字按位和时出现溢出，进行回卷，结果为**校验和**：
$$
1011101110110101\\
1000111100001100\\
————————\\
0100101011000010
$$
如果数据报没有出错，该校验和与数据报中所有 16 位字的按位和结果应该是`0xFFFF`。

UDP 能检测差错，但是不能恢复差错结果。在遇到差错时，UDP 或是丢弃数据报，或是向应用层发出警告。TCP 与 IP 协议也使用该方法结算校验和。

### 3.4 可靠数据传输原理

一个**可靠数据传输协议（reliable data transfer protocol，RDT protocol）**需要保证数据能够通过一条可靠信道传输，并不会受到比特数据丢失和差错的影响。这种服务的抽象往往需要在不可靠的下层服务（如 IP）上实现。

#### 可靠数据信道

**自动重传请求协议（Automatic Repeat reQuest，ARQ）**为了确保发送方知道接收方的情况，接收方需要向发送方进行**肯定确认（positive acknowledgment，ACK）**和**否定确认（negative acknowledgment，NAK）**。ARQ 需要实现三种功能以确保数据的可靠传输：

+ 差错检测：检查每个比特是否存在丢失或更改的问题，UDP 和 TCP 都使用校验和进行差错检测
+ 接收方反馈：发送方需要知道接收方信息，TCP 使用 SEQ 和 ACK 序号来交流数据信息
+ 重传：对于由差错的分组，发送方需要重传这些分组

由于 ACK 和 NAK 信息本身也可能会受损，使用差错检测可以进行这些信息完整性的判断。为了让发送方知道接收方接收了有问题的分组，或整个分组存丢失，接收方将发送**冗余分组**，在 TCP 体现为发送具有同一个累积确认下的确认号的响应报文段，因此发送方可以知道中间的分组出现了问题。

如果接收方面临的问题体现为接收到的分组存在差错，即返回一个冗余分组，告知发送方进行**重传**；如果分组在传输中丢失（可能由于下层协议缓存溢出导致），接收方就需要一个**定时器**来检测超时时间，并在合适时间发送冗余分组通知发送方重传。

为了保证数据有序，最简单的做法是实现一种**停等（stop-and-wait）**协议，即在接收方返回确认前发送方不会发送下一个分组。这么做会带来非常大的时延，因此实际上 TCP 使用了一种流水线形式的传输方式。

#### 流水线可靠传输

为了避免停等协议带来的问题，**流水线（pipeline）**方式的可靠传输信道允许发送方发送多个分组而无需等待确认。在这种情况下，为了保证分组按序到达，发送和接收方就需要增加一些**序号**（TCP 中体现为 SEQ 和 ACK 号）来维持连接状态；此外，如果分组失序到达，接收方还需要能够**缓存**已到达分组，并在稍后重新组装它们；最后，流水线需要恢复差错，最常使用的方式是回退 N 步和选择重传。

#### 回退 N 步

**回退 N 步**（Go-Back-N，**GBN**）协议中，允许发送方发送多个分组而无需等待确认，因此发送方需要维护一个**基序号（base）**和一个**下一个序号（nextseqnum）**。基序号表示发送方**已经发送而未得到确认**的最小序号，下一个序号为接下来需要发送的分组序号。GBN 有一个**窗口大小**（window size），表示一次能够处理的发送但未确认分组数和还未发送并等待发送的分组数和，该窗口会逐渐向后滑动，因此 GBN 也被称为滑动窗口协议。

GBN 需要响应三种事件：

+ 上层协议的调用：上层协议传递的数据需要被封装
+ 收到 ACK：GBN 对分组序号采用**累计确认**（在 TCP 中，即接收方的确认号永远只是最后按需到达的分组的序号）
+ 超时：GBN 在超时时需要采取一些行为保证可靠数据传输，比如重传

#### 选择重传

**选择重传**（Selective Repeat，**SR**）通过让发送方重传那些它认为存在问题的分组来实现可靠传输。SR 接收方将确认每一个正确的分组而**不管**是否按序到达，直到所有预期分组都已到达，接收方才组装所有数据并交给上层。如果发送方没有接收到发送分组的确认，就会选择性地重传这些分组，可能会设置一个超时时间来决定重传，在一个窗口中的所有分组都被确认前窗口不会继续向后移动。

### 3.5 TCP

#### TCP 连接

TCP 是一种**面向连接（connection-oriented）**的可靠运输层传输协议，负责端系统间的逻辑连接，在两个进程建立连接前，必须进行**握手**。在握手阶段，两个端系统会交换一些**预备报文段**，以建立保证数据传输的**参数**，并初始化与连接相关的 TCP **状态变量**。

TCP 只运行在端系统上，并维护连接的状态，因此中间的网络元素不会维护任何 TCP 状态，它们看到的只有数据报，而非连接。TCP 是一种**全双工服务（full-duplex service）**，即传输是双向和同时的。TCP 也是**点对点**的，即是单个发送方和单个接收方之间的连接，如果要进行一个发送方向多个接收方的连接（即“多播”），TCP 是做不到的。在 TCP 中发起连接的进程被称为**客户进程**，而另一个进程被称为**服务器进程**。

在正式传输数据前，TCP 会进行三次握手：

1. 客户端发送一个特殊的 TCP 报文段，不包含有效载荷
2. 服务器接收客户端报文段，返回一个特殊 TCP 报文段作为响应，不包含有效载荷
3. 客户端返回一个特殊 TCP 报文段作为响应，可以包含有效载荷

应用层进程传输的报文在通过套接字后就交由运输层控制，被送入 TCP 的**发送缓存（send buffer）**中，这一过程在握手阶段进行。在传输过程中，TCP 会在方便发送时从发送缓存中取出**一小块**数据并递交到网络层。之所以要分解报文，是因为 TCP 载荷部分受到**最大报文段长度（maximum segment size，MSS）**的限制，MSS 通常由最大的链路层**帧**长度，即**最大传输单元（maximum transmission unit，MTU）**决定。MSS 指的其实是报文段中**有效载荷**的最大长度，一般来说 TCP 首部长度为 20 字节，IP 首部长度 20 字节，而链路层 MTU 为 1500 字节，因此 MSS 一般长度为 **1460 字节**。

TCP 会为每个应用层报文数据块添加一个 TCP 首部进行封装，并递交给网络层再由 IP 封装。TCP 报文段在发送端和接收端上都会被放入对应的**缓存**中等待发送或接收。

因此，TCP 的组成包含六个部分：

1. 发送端 TCP 缓存
2. 发送端 TCP 状态变量
3. 发送端套接字
4. 接收端 TCP 缓存
5. 接收端 TCP 状态变量
6. 接收端套接字

而其中的网络元素不会缓存任何 TCP 数据。

#### TCP 报文段结构

TCP 一般会把应用层报文分解成若干块封装在报文段载荷中，而交互式应用为了响应速度，其报文大小一般不会超过 MSS。载荷是报文段结构的一部分，整个报文段结构包括：

1. 源端口号（src port）：16 bits
2. 目的端口号（dst port）：16 bits
3. 序号（sequence number）：32 bits，该字段用来实现可靠数据传输服务，表示当前报文序号
4. 确认号（acknowledgment number）：32 bits，该字段用来实现可靠数据传输服务，表示接下来想要接收的报文序号
5. 首部长度（length）：4 bits，以 32 bits 为单位记录 TCP 首部长度，如`0101`表示 32 * 5 = 160 bits = 20 bytes 长度，即该字段的十进制值乘 4 就是首部字节长度，这也是典型的 TCP 首部长度
6. 空位：保留的 3 bits
7. 标记位（flags）：9 bits，每个比特标记代表一定含义，当标记位为 1 时：
   + NS（nonce sum）：该标记位用于保护接受者不受发送者的突发恶意隐藏报文侵害
   + CWR（Congestion Window Reduced）：指示应该在拥塞控制时减少窗口通过的比特数
   + ECE（Explicit Congestion Notification Echo）：表示该 TCP 连接有拥塞控制时的通知能力
   + URG（urgent）：表示报文段中包含紧急数据
   + ACK（Acknowledgment）：表示数据包被成功地接收了
   + PSH（push）：表示接收端应该把数据立刻交给上层而不是进行缓存
   + RST（reset）：表示因为发生连接错误而重置，一般是发起方 TCP 选择了一个错误套接字，此时确认报文段会将此位设置为 1
   + SYN（Synchronization）：表示正在进行第一次握手
   + FIN（finished）：表示数据包发送完毕
8. 接收窗口（window）：16 bits，用于流量控制，表示希望接收的字节数
9. 校验和（checksum）：16 bits
10. 紧急数据指针（urgent point）：16 bits，当 URG 为 1 时，紧急数据指针用于指出紧急数据的最后一个字节，此时 TCP 必须通知上层存在紧急数据
11. 选项（options）：32 bits，可选，用于握手时协调 MSS、调节窗口等，也可能包含时间戳，一般只在第一次和第二次连接握手时出现，不会和载荷同时出现
12. 载荷（payload）：受 MSS 限制，封装的上层报文内容

##### 序号和确认号

序号和确认号是保证 TCP 可靠传输的**关键部分**。一个报文段的**序号**是该报文段首字节**在字节流中**的编号，而不是按报文段顺序进行排序的编号。如果有一个 5000 字节长的流，被分成 50 个报文段进行传输，假设第一个报文段的序号是 0 ，第二个报文段的序号就会是 100，第三个就会是 200，以此类推。

**确认号**则代表了接收方**想要接收的**下个报文段的序号。按上面的例子来说，如果接收方的确认号是 100，在接收了对应序号的报文段后，下一次响应时的确认号就会是 200，表示接收方需要接收一个序号为 200 的报文。

##### 累积确认

**累积确认（cumulative acknowledgment）**是保证 TCP 可以按序确认报文段的可靠性保证措施，TCP 把数据看成是无结构但**有序**的，但是 IP 提供的服务却**不能保障**报文段到达是有序的。假如接收方已经接收了 200 序号的报文段，接下来确认号变为 400，但是却先收到了序号为 800 的报文段，接收方对该报文段的响应中的确认号仍旧会为 200，直到序号为 200 的报文段到达，接收方才会返回一个确认号为 400 的响应。TCP 协议**没有**规定应该如何进行失序报文段的处理，一般来说的做法为将已到达的失序报文段**缓存**，并在稍后重建整个报文。

##### 初始序号的选择

一个 TCP 连接的初始序号可以为 0 ，但一般会随机选择一个数。这么做是为了避免网络中存在两台主机之前已经终止的某个 TCP 残存的报文段对现有连接的干扰。

##### Telnet 实例

Telnet 是一个基于 TCP 的用于远程登录的协议，许多操作系统都内置了 Telnet 客户端，但是由于其明文传输所有内容的安全性问题，现在大都使用 SSH（安全 Shell）代替 Telnet 。 

Telnet 协议使用一种**回显（echo back）**的方式处理用户输入。用户在 shell 软件中输入的每个字符都会被 TCP 传输到远程主机中，待远程主机处理后返回到客户端上，以此确认命令有到达远程主机。

假如在 Shell 中运行 Telnet 客户端，成功连接了服务器，接下来在交互窗口中输入`ok`两个字符，会发生以下事情：

1. 假设握手结束后客户端随机得到的初始序号（SEQ）为 42，确认号（ACK）为 79
2. 客户端输入一个`o`，这个字符随即被 TCP 封装发送到远程主机，报文段的 SEQ 为 42，ACK 为 79 
3. 远程主机接收报文段，回显`o`，此时远程主机的响应的 ACK 变为 43，SEQ 为 79
4. 客户端接收到响应报文段，发送`k`，SEQ 为 43，ACK 为 80
5. 远程主机接收到报文段，回显`k`，SEQ 为 80，ACK 为 44

可以看出其序号和确认号在累积确认中的表现。

#### 往返时间估计和超时

为了保证可靠数据传输，TCP 需要在合适的时间考虑重传，因此需要设置超时时间。一般来说，超时时间需要大于一个 RTT 加上接收方处理报文段的时间，该时间是动态的，因此需要进行动态估计和设置超时时间。

##### 估计 RTT

报文段的**样本 RTT（Sample RTT）**是最近一个时刻发送报文段的 RTT，发送方**不会**在每个报文段上测量 RTT，而是在某个时刻（一般有一个周期）进行测量，且**不会**用重传报文段的 RTT 作为样本。每个 RTT 样本都是非典型的动态的，因此需要计算样本 RTT 的**均值**，被称为 **Estimated RTT**。样本均值是上一个时刻的均值和当前样本的加权求和结果，统计学上称为**指数加权平均值（EWMA）**，公式如下：
$$
EstimatedRTT=(1-α)·EstimatedRTT+α·SampleRTT
$$
RFC 中建议的 α 值为 0.125，因此该公式为：
$$
EstimatedRTT=0.875·EstimatedRTT+0.125·SampleRTT
$$
此外，还需测量每个样本和均值的偏离程度，称作 **Dev RTT**：
$$
DevRTT=(1-β)·DevRTT+β·|SampleRTT-EstimatedRTT|
$$
RFC 中建议的 β 值为 0.25，因此该公式为：
$$
DevRTT=0.75·DevRTT+0.25·|SampleRTT-EstimatedRTT|
$$

##### 设置超时

估算了样本 RTT 的均值并计算偏离度后，就可以根据两者设置一个含有余量**超时时间（Timeout Interval）**，偏离度大时获取更多的时间余量，超时计算公式如下：
$$
TimeoutInterval=EstimatedRTT+4·DevRTT
$$
RFC 推荐的超时时间初始为 1 秒。

#### TCP 可靠数据传输

由于 IP 停供的服务是不可靠的，TCP 需要保证数据流无损坏、无间隙、非冗余、按序进行交付给上层进程。

##### 重传

TCP 使用**校验和**确保已经到达的数据不存在比特级差错，如果有错误则需要重传。而对于可能存在的分组丢失问题，TCP 将根据超时时间进行重传。当报文段发送时，发送方就会启动定时器。如果在超时时间内未接受响应报文段，则重传可能是丢失的分组。

TCP 可能面临以下情况，并作出对应行为：

+ 一个报文段在超时时间内**没有接收到**对应确认号的响应：发送方将进行该分组的重传
+ 接收方**同时**接收了多组按序到达的报文：接收方不会为每个报文段都进行响应，而是直接返回一个包含最后按序到达报文段序号的**累积确认 ACK**，这样发送方就知道之前没有接到响应的报文段也正常到达了
+ 一组报文段被发送，在最早的报文段的响应超时时发送方进行了重传，但实际上接收方已经接收了所有报文段，只是**响应迟到**了：发送方会重传它认为丢失的报文，而接收方在接收到重传内容并确认是冗余内容后，会直接**丢弃**重传内容
+ 已经确认需要重传，并需要**为重传的报文段设置超时**时间：一般来说，需要进行重传的报文段会获得**双倍**的超时时间，并且这种情况只出现在需要重传的报文段上，其他报文段还是根据之前的公式设置超时。如果重传的报文段再次超时，则再将超时时间加倍
+ **接收方**发现没有在一定时间内接受到报文段：接收方将返回**冗余的 ACK**，这个响应报文段的 ACK 号和之前那些报文段的 ACK 号是相同的，因此发送方可知有一些报文没有正常到达，并进行重传。如果发送方连续接收到 **3 个**冗余 ACK，就将其视作一个 NAK，并进行重传，这也被称为**快速重传（fast retransmit）**

##### 是回退 N 步还是选择重传

TCP 发送方仅需维护一个未确认的最小序号（即基序号 base）和下一个要发送的字节序号（即 nextseqnum），因此是一种 GBN 风格的协议。最近对 TCP 提出的一种修改意见认为 TCP 应该进行 SR ，因此 TCP 最好被视作两种协议的混合体。

#### TCP 流量控制

TCP 提供的**流量控制服务（flow-control service）**和**拥塞控制（congestion control）**，前者是速度匹配服务，使发送方发送速率匹配接收方接收速率，防止分组**溢出**；后者是为了避免 IP 层拥塞而提供的服务。

##### 接收窗口

为了让发送方知道接收方有多少可用的缓存，全双工的 TCP 双方会在每个 TCP 确认报文段的 16 位**接收窗口（receive window）**字段给出自己的可用缓存值，也被称为窗口。由于窗口只有 16 位，其能表示的最大数字也只有 65536，因此还需要一个**窗口缩放因数（window size scaling factor）**，该 24 位因子会在前两次握手阶段被放置在可选的**选项**字段中，握手双方都可能会包含该选项，并可能具有不同的缩放因子。该选项有三个部分：

+ 类型（kind）：8 位，表示选项类型，3 代表是一个窗口缩放
+ 长度（length）：一般为 8 位，表示选项的长度
+ **位移计数**（shift count）：一般为 8 位，表示对于窗口大小的十六进制数应该左移（即相乘）的位数

如果没有缩放，16 位的窗口表示可用最大缓存的字节数，在第一次握手时发送方窗口会是`0xFFFF`，没有实际意义，请求发起方**只会**在第三次握手中表面自己的窗口大小和缩放因子；如果有缩放因子，实际窗口大小就是窗口乘以缩放因子的结果，十六进制运算中，只需将窗口大小的十六进制数左移窗口缩放选项的位移计数代表的十进制数位，对于十进制运算，两者直接相乘。

窗口大小是**动态**的，因此 TCP 双方必须使用一些连接变量动态计算窗口大小。

##### 流量控制

TCP 为了进行流量控制，连接双方会各自维护一些**连接变量**。其中**接收方**会维护两个变量：

+ `LastByteRead`：接收方从上层缓存流中读取的最后一个字节编号
+ `LastByteRcvd`：从网络中到达接收方并已经放入缓存中的最后一个字节编号

由于 TCP 不允许缓存溢出，**窗口大小**（表示为`rwnd`）应该为：
$$
rwnd=RcvBuffer-[LastByteRead-LastByteRead]
$$
而**发送方**则会维护：

+ `LastByteSent`：最后发送的字节编号
+ `LastByteAcked`：已经被接收方确认的最后字节编号

很明显，**两者之差**则是仍然存在网络或接收方缓存中还未被接收方确认的流量大小。发送方只需要保证两者之差满足：
$$
LastByteSent-LastByteAcked\leq rwnd
$$
就可以确保接收方不会发生缓存溢出，每次确认报文段中的 ACK 都会使得运算结果改变，以保证流量控制的实时性。UDP 协议并不提供 TCP 的流量控制服务，因此存在缓存溢出和导致 IP 层拥塞的风险。

假如接收方已经**没有**任何剩余缓存，就会返回一个窗口为 0 的确认报文段。为了避免发送方不知道何时再发送数据，发送方会**持续发送**一个只有一个字节长的特殊报文段。如果接收方依旧没有缓存空间，该特殊报文段就会溢出而不产生任何确认；如果接收方的缓存已经得到清理，就会返回该特殊报文段的确认，因此发送方就知道自己可以继续发送数据了。

#### TCP 连接管理

为了维护连接状态，TCP 需要建立一些连接变量或常量，常量（如窗口缩放因子、MMS）需要在连接建立时的**三次握手**阶段协商，而变量可能在连接过程中改变（如窗口相关的字节序号信息）。

##### 发起连接的三次握手

TCP 三次握手指：

1. 连接发起方即**客户端**向服务器发送一个特殊的 TCP 报文段，该报文段首部包含一个置于 1 的 **SYN**（同步）比特，并随机选择一个**初始 SEQ** 序号，一防止网络中残留的报文段和安全攻击影响。而一些**连接状态常量**会包含报文段的选项字段中。该特殊报文段**不会**包含任何上层载荷，被称为 **SYN 报文段**；
2. TCP SYN 报文段到达服务器，**服务器**将返回一个 **SYN** 比特同样置为 1 的特殊报文段，并随机选择一个**初始 SEQ** 序号（通过某个散列函数计算得出），将确认号设置为第一次握手的序号加一返回。该报文段同样**不包含**任何上层载荷，被称为 **SYNACK 报文段**。发送第二次握手报文后，服务器**可能**会开始为连接**分配**变量和缓存，也可能推后分配；
3. **客户端**收到 SYNACK 报文段，并为连接**分配**变量和缓存，向服务器返回确认。因为连接已经建立，SYN 字段会为 0 ，如果使用 cookie，在该阶段服务器收到确认后才会分配缓存。该报文段将**可能包含**上层载荷。

之后该连接的每一个报文的 SYN 标记都将为 0 。

##### 结束连接的四次握手

为了结束连接，连接双方同样需要进行协商，该过程有四次握手：

1. **客户端**发送一个特殊报文段指示服务器关闭连接，该报文段的 **FIN** 标记位将置为 1；
2. **服务器**接收到关闭连接报文段，返回确认；
3. **服务器**发起一个表示即将关闭的特殊报文段，该报文段的 **FIN** 标记位将置为 1，并清空连接缓存；
4. **客户端**接收到该报文段，返回确认，进入定时等待状态

在等待一段时间后，客户端就会清除所有与连接相关的缓存内容。

##### 连接状态

在一个 TCP 的生命周期中，TCP 会在各种 **TCP 状态（TCP state）**间变迁。发起连接时，**客户端**会发生以下状态变迁：

1. **客户端**一开始处于`CLOSED`状态；
2. **客户端**发送第一次握手报文段，进入`SYN_SENT`状态，等待第二次握手确认；
3. **服务器**发送第二次握手报文段，客户端接收并进入`ESTABLISHED`状态，为连接**分配**缓存，开始进行通讯；
4. **客户端**需要关闭连接，发送结束连接的第一次握手报文段，进入`FIN_WAIT_1`状态；
5. **服务器**发送第二次结束握手报文段，客户端接收并进入`FIN_WAIT_2`状态；
6. **客户端**发送第三次结束握手报文段，进入`TIME_WAIT`状态；
7. 服务器此时不会给出确认响应，**客户端**在等待一定时间（通常为 30 秒）后正式关闭连接，清空所有连接缓存。

服务器会发生类似的状态变迁：

1. **服务器**一开始处于`CLOSED`状态；
2. **服务器进程**创建了一个套接字并持续监听指定端口，进入`LISTEN`状态；
3. **客户端**进程向服务器发起第一次握手，服务器返回第二次握手，进入`SYN_RCVD`状态，此时可能会**分配**缓存；
4. **客户端**返回第三次握手，服务器进入`ESTABLISHED`状态，此时可能会**分配**缓存；
5. **客户端**发送第一次结束握手，服务器返回确认并进入`CLOSE_WAIT`状态；
6. **服务器**发送第三次结束握手，进入`LAST_ACK`状态；
7. **客户端**返回第四次结束握手，服务器进入`LISTEN`状态，清除与连接相关缓存；
8. 如果需要关闭服务器，将进入`CLOSED`状态，并清除应用进程的缓存。

##### 连接重置

假如 TCP 连接发起方向服务器的错误套接字发起了第一握手，如果错误套接字能够处理 TCP 请求，就会返回一个 **RST 标识符**置为 1 的特殊重置报文段，表示**连接已重置**，不要继续向该套接字发起 TCP 请求。而 UDP 没有该功能，UDP 的端口错误不由套接字负责，而是由下层 ICMP 协议负责。

##### SYN 洪泛攻击

由于服务器会在第二次握手期间就分配缓存，将很可能受到一种被称为 **SYN 洪泛攻击（SYN flood attack）**的拒绝服务攻击。SYN 洪泛攻击将在短时间发起大量第一次握手报文段而不进行第三次握手，导致服务器在第二次握手时分配大量缓存而无法正常进行其他通讯。为了避免该问题，TCP 服务器一般会在**第三次握手结束**后才**分配**连接缓存，并使用一个特殊的 **SYN cookie**。

SYN cookie 由一个足够健壮的**散列**函数算法得出，该算法会利用**套接字唯一标识符**（即连接的源端口、源 IP 、目的端口、目的 IP 四元组）和一个私有的**服务器密钥**计算出 cookie 值，并将其作为初始**序号**，因此可以保证每个初始序号的唯一性，从而防范伪造攻击。服务器不会记录该 cookie 和其他任何状态信息，因此不存在缓存分配。假如第一次握手不是一次 SYN 攻击，客户端将返回一个正常的确认号（值为序号 + 1），服务器将利用套接字标识符再次计算之前的 cookie 并进行核对，之后才分配连接缓存。

因此，第一次握手不会造成任何危害，服务器唯一要付出的代价只是计算一个 cookie 值。

##### NMAP

NMAP 端口嗅探器利用了类似 SYN 洪泛攻击的原理，即通过发起嗅探请求寻找服务器上开放的套接字，但是对于可用的套接字端口会主动发起第三次握手并随后立刻关闭连接。NMAP 在发送嗅探报文段后大致会有三种结果：

1. NMAP 收到一个 SYNBACK 报文段，说明端口可用
2. NMAP 收到一个 RST 报文段，表示端口不可用，并且源套接字到目的地套接字之间**没有**防火墙阻挡
3. NMAP 什么也没收到，说明端口不可能用，并且套接字之间的流量被防火墙**拦截**了

## 第四章 网络层：数据平面

### 4.1 网络层概述

**网络层**是一种**点到点**的通信，即各个互联网存在点之间的通信，用以向上层提供服务，实现逻辑上的端到端通信功能。网络层可以分为两个部分：

+ **数据平面（data plane）**：数据平面提供的功能即是网络层分组交换机——**路由器**提供的功能，即将到达路由器的输入链路**数据报**转发到该路由器合适的输出链路中；
+ **控制平面（control plane）**：控制平面决定了数据报在不同路由器间的**路由**方式，通过**路由选择算法**选择合适的路由，即协调路由器的转发动作。

#### 转发和路由选择

网络层的作用即是将分组从一台主机移动到另一台主机上。为此，网络层需要提供两种功能：

+ **转发（forwarding）**：数据平面的功能，即将分组从路由器输入链路移动到输出链路的过程，数据平面实际上只提供这一种功能。这是单个路由器本地的动作，通常耗时只有几纳秒，并由硬件实现；
+ **路由选择（routing）**：控制平面的功能，网络层必须决定分组去往目的地才去的**路由**，即路径，通过**路由选择算法（routing algorithm）**计算，计算过程通常耗时几秒，并由软件实现。

##### 转发表

每台路由器中有一个关键元素：**转发表（forwarding table）**。转发表是路由器中的一个**键值对**映射（Map）数据结构，存储了索引键和**输出链路接口**的映射信息。索引键会被包含在数据报的**首部**字段中，因此路由器可以根据数据报内容选择转发表中对应的路由输出链路接口。转发表是**数据平面**的内容，由控制平面的路由选择算法**计算**得出。

##### 控制平面：传统方法

为了能够配置转发表，不同路由器的控制平面之间需要通过**路由选择协议**进行相互**通信**。在这种传统方法中，控制平面和数据平面在同一台物理路由器上，并且在许多实现中是由人类手动配置转发表的。

##### 控制平面：SDN 方法

手动配置转发表会有众多问题。现代方法将数据平面与控制平面从物理上分离，由一个**远程控制器**负责计算转发表并分发到每一台路由器上，而每台路由器通过**软件定义网络（Software-Defined Networking，SDN）**与远程控制器通信。远程控制器通常在某个互联网数据中心中，由 ISP 或第三方进行管理。在 SDN 方法中，路由器仅执行转发功能，数据平面和控制平面物理分离。

#### 网络层服务模型

**网络层服务模型**包括：

+ 确保交付：确保分组到达目的地
+ 具有时延上限的确保交付：确保在一定时间内交付分组
+ 有序交付；确保分组按序到达
+ 确保最小带宽：保证最小传输速率下界
+ 安全性：确保报文运输机密性

网络层还可能有其他多种服务存在。**因特网**的网络层只提供了**尽力而为的服务（best-effort service）**，不保证分组完整到达，不保证分组按时、按序到达，也不保证有最小带宽和时延上限。在这种服务模式下，网络层实际上可以完全不提供服务。因此，运输层在不可靠的网络层协议上拥有一定的差错处理机制。

#### 分组交换机

**分组交换机**指通用分组交换设备。在网络层中，其为**路由器**，因为路由器根据网络层数据报的首部信息决定分组如何交换；在链路层中，其为**链路层交换机**，因为链路层交换机根据链路层帧的字段值决定分组如何交换。分组交换机的工作内容可以简单地概括为输入分组、选择目的地、输出分组的过程，整个过程都在交换机内部进行。

### 4.2 路由器工作原理

#### 数据平面组成部分

为了进行**转发**，路由器一般包含 4 个**组成部分**：

+ **输入端口（input port）**：输入端口需要执行几项重要功能：
  + 将物理链路接入路由器的物理层功能
  + 查询输入端口对应的输出端口的**查找功能**，为了实现该功能，在路由器中可能存在特殊的**控制分组**携带控制信息（如携带路由选择协议信息的分组）
  + 将数据报从输入端口移动到输出端口的数据链路层功能
+ **交换结构**：连接输入端口的输出端口的中间部分，这种结构完全包含在路由器中
+ **输出端口**：输出端口**缓存**并**转发**从交换结构中获取的分组，并执行必要的链路层和物理层功能在输出链路上传输这些分组。因为链路可能是**双向**的，输出端口和输入端口可能出现在同一线路卡上
+ **路由处理选择器**：路由处理选择器是控制平面的内容，在传统路由器中，它执行**路由选择协议**；在 SDN 路由器中，路由选择处理器则与**远程控制器**通信

数据平面的部分几乎总是由**硬件**实现。因特网中的高速率传输链路的传输速率一般都高达几十甚至几百 GBs ，而路由器数据平面各部分仅有纳秒级的时间来处理数据报，硬件的运行速度将远快于软件。而路由处理控制器并不需要实时配置转发表，一般更新周期以分钟计，因此可以使用软件实现。

一般来说，转发功能要面临两种情况下的转发：

+ 基于目的地的简单转发：输入端口根据数据报首部目的地信息决定输出端口
+ 更为复杂的通用转发：可能需要考虑拥塞、最短路径、安全流量控制及其他问题

#### 输入端口处理和基于目的地转发

对于基于目的地转发而言，输入端处理包含三个部分：

1. **线路端接**：将物理链路与路由器端口连接的过程
2. **数据链路处理**：包括对链路层帧和网络层数据报的拆封处理
3. **输入交换结构**：在输入交换结构前，输入端口将**查询**对应的输出端口信息，然后再将分组送入交换结构以**转发**到输出端口。如果出现**阻塞**（根据交换结构类型有多种原因），还需要进行分组**排队**

为了让输入端口找到对应输出端口，最暴力的做法是为每个可能的 IP 地址都建立一个二元组存放在转发表中，但建立 40 亿个二元组的转发表是不现实的。一种转发表风格采用**前缀（prefix）**形式，即根据 IP 地址二进制的前几位来决定转发到哪个链路输出端口，一般会按目的 IP 地址的数字范围进行划分。因为 IP 的二进制形式**不是**一种前缀编码，可能出现重复前缀项，此时根据**最长前缀匹配规则**在表中寻找：假如存在索引`1101~1111`和`11010000~11010001`，对于`110100000101`优先选择后者，即选择多个可能索引项中数值更大的索引项。

由于留给输入端口的时间只有纳秒级，对于转发表的搜索将不是简单地线性搜索算法，且几乎必须通过硬件进行。

一旦查找确定了输出端口，一个分组就能进入交换结构，根据交换结构的类型，这些分组可能在某时阻塞交换结构的进入，因此需要**排队**。输入端口的处理实际上是**查找**与**一组动作**的抽象，其他必须的动作还包括：

+ 进行链路层和物理层处理，以确保分组能够进入路由器和在路由器内部移动
+ 检查分组的版本号、校验和、寿命字段，并重写校验和和寿命
+ 更新用于网络管理的计数器，如接收的数据报数量

而分组进入交换结构的过程是一种**匹配**（查找 IP 地址）加**动作**的抽象，在进入交换结构时可能有以下动作：

+ 除了定位输出端口，还要查找链路层帧的目的地址
+ 防火墙可能要进行分组安全过滤
+ 网络地址转换器（NAT）可能需要在分组转发前重写一些目的地址信息，以改变分组去向

#### 交换结构

**交换结构**是路由器的核心部分。交换结构有多种实现方式，常见的有三种：

+ **经内存交换**：经过内存交换的交换结构是最简单也是最早的路由器内部实现。这一类路由器就是一台冯诺依曼式的计算机，输入端口与输出端口间的交换结构就是**内存**，控制这一过程的路由选择处理器就是 **CPU** 。输入端口将分组放入内存，再由 CPU 提取分组的目的地信息，从转发表中找出对应的输出端口，并由内存转交给输出端口的**缓存**。输入和输出端口缓存、内存和 CPU 性能直接影响了路由器的交换能力；
+ **经总线交换**：在该方法中，所有输入端口共用一根**总线**传输分组到输出端口，因此**不需要**选择处理器干预，而是**预先**计划一个指示对应输出端口内部标签并放入数据报**首部**中，引导总线将数据报传输至输出端口。在输出端口向链路层递交数据前，会清除该首部。因为只有一根总线，同时**只能**有一个分组在交换结构中移动，其他分组将被阻塞，对于一些小型局域网路由器来说已经足够了；
+ **经互联网络交换**：这里的互联网指交换结构中的由多条总线组成的**纵横网络**，总线间的交点由**交换结构控制器**（交换结构逻辑上的一部分）控制，这些控制器可以控制交叉点的开闭，因此可以改变分组流向。这种类型的交换结构可以**并发**多个分组，且在交换结构中是非阻塞的，但是仍然可能因为拥塞而排队。在简单的实现中，一个输出端口一次**只能**接收一个分组，因此当纵横网络中的多个分组到达输出端口时必须进入输入端口缓存**排队**，在输出端口空闲时再进入交换结构；复杂的多层纵横网络则允许多个分组向同一个输出端口移动。

#### 输出端口处理

输出端口处理包含三个部分：

1. **缓存管理**：存放和管理正在排队的分组
2. **数据链路处理**：封装数据报
3. **线路端接**：让路由器连接到物理链路层

#### 何时出现排队

在路由器的输入和输出端口中都可能出现**排队**，排队的位置和程度直接**取决于**流量负载、交换结构的相对速率和线路速率。此外，随着缓存队列的增长，路由器的缓存空间将会耗尽，然后就会出现**丢包（packet loss）**，这一现象正是发生在**路由器**中。

##### 输入排队

以最常用的互联网络交换结构为例，输入端口上可能造成阻塞原因主要有：

+ 同输出端口阻塞：由于多个分组指向同一输出端口，其余分组必须在输入端口缓存中排队
+ 线路前部阻塞（HOF 阻塞）：由于存在同输出端口阻塞分组，这些分组后方的分组也需要在输入端口缓存中排队

##### 输出排队

一个输出端口每次只能将一个分组推出路由器到链路层中，因此其余分组需要排队等待。当缓存不足时，可以采取**弃尾（drop-tail）**策略，即丢弃最后到达输出端口缓存队列尾部的分组；也可以从排队分组中选取某个分组丢弃。在某系情况下，输出缓存满前就会丢弃一个分组，剩下的空位将留给一个带有**拥塞信号**的分组来告知发送方出现丢包，这些分组标记和丢弃策略称为**主动队列管理（AQM）**算法，**随机早期检测（RED）**是使用的最广泛的 AQM 之一。

##### 缓存大小指定

根据经验方法的总结，一般来说，需要的缓存数量（B）是平均 RTT 和链路传输速率的积。如对于一条平均 RTT 为 250 ms 、传输速率（C）为 10 Gbps 的链路来说，需要 2.5 GB 的缓存量，即：
$$
B=RTT\cdot C
$$
而最新的研究表明，所需缓存数会和链路中的 **TCP 流**数量（N）相关：
$$
B=\frac{RTT\cdot C}{\sqrt{N}}
$$

#### 分组调度

**分组调用**用于解决排队中的输出缓存分组的优先级问题。

##### 先进先出

最简单的处理方式是将缓存队列视作一个先进先出（FIFO）的队列，根据输入顺序决定输出顺序，溢出的分组则被直接丢弃。

##### 优先权排队

在**优先权排队（priority queuing）**情况下，到达输出端口的分组会根据优先级进行分类，优先输出优先级高的分组，如一些涉及实时应用的 TCP/UDP 报文段、携带网络管理信息的分组将具有较高优先级。同优先级的分组内部按照 FIFO 规则处理。

##### 循环加权公平排队

**循环加权公平排队（Weighted Fair Queuing，WFQ）**是一种**保持工作排队（work-conserving queuing）**的规则，即不允许链路在还有分组等待的情况下保持空闲。循环调度指的是分组会按权重进行分类，并按照类型被循环输出。根据特定规则，不同权重的分组类会获得不同的**服务部分空间**：在总权重为 ∑w~j~ 的循环队列中，对于一个权重为 w~i~ 的分组类，需要确保该类有 w~i~ / ∑w~j~ 的**带宽**部分。

### 4.3 Internet 协议

**Internet 协议**也称作网络协议或网际协议。目前最广泛部署的 IP 为 **IPv4** 即第四版协议，而 IPv6 则被提议以替代 IPv4 。

#### IPv4 数据报格式

网络层分组被称为**数据报**，IP 数据报大致包含以下内容：

+ **版本号**：4 比特，规定 IP 协议版本；
+ **首部长度**：4 比特，单位为 4 字节，即`0101`表示二进制 5 ，即 20 字节。大部分 IP 数据报不包含可选的选项，因此**一般**都为 20 字节；
+ **服务类型**：8 比特，服务类型（TOS）字段用于区分不同类型的数据报，如区分实时和非实时流量、标记一个控制报文段；
+ **数据报长度**：16 比特，数据报总长度，理论最大长度为 65535 。受 MTU 限制，一般来说数据报长度都是 1500 字节，包含 20 字节首部和 1480 字节载荷；
+ **标识**：16 比特，是数据报的唯一标识符，与分片相关；
+ **标志位**：3 比特，分别为：
  + 保留位；
  + Don't Fragment：置 1 表示不希望进行分片传输，置 0 表示可以进行分片；
  + More Fragment：置 1 表示该数据报是分片数据报的一部分且不是最后一片；
+ **片偏移**：13 比特，偏移（Offset）表示分片数据报之前已有多少有效载荷比特到达；
+ **寿命**：8 比特，即 Time-To-Live（**TTL**），用于确保数据报不会永远留在网络中。每当一台路由器处理数据报，都会将 TTL 字段减 1 ，并丢弃 TTL 为 0 的数据报并返回响应。tracert 程序使用一组不同 TTL 的数据报以跟踪路由信息；
+ **协议**：8 比特，表示服务的上层协议，常见的有：
  + 6：TCP
  + 17：UDP
  + 1：ICMP
  + 89：OSPF
+ **首部校验和**：16 比特，用于检测数据报中的比特级差错。计算过程和 UDP、TCP 校验和一致，将 2 字节当做一个数（即 16 比特字）进行按位和运算，溢出回卷，最后按位非即是校验和。如果数据报没有差错，校验和和数据报所有 16 位字的和运算应该全为 1 。需要注意的是 IP 的校验和在每台路由器中都需要**重新运算**，因为 TTL 每次都会改变。此外，IP **只会**计算自己的首部的校验和，因此上层 UDP 和 TCP 仍需计算一个首部校验和，这是为了保证 IP 是一个与上层无关的通用协议；
+ **源地址**：32 比特源 IP 地址
+ **目的地址**：32 比特目的 IP 地址
+ **选项**：可选扩展部分，一般数据报都不会包括选项，且选项的出现会使得数据报处理变得复杂。IPv6 已经弃用了选项字段；
+ **有效载荷**：封装的上层报文段部分。

一般来说，IP 数据报首部长度都是固定的，因此一个**典型**的携带 TCP 载荷的 IP 数据报的长度为：20 字节 IP 首部 + 20 字节 TCP 首部 + TCP 有效载荷。

#### IP 数据报分片

受链路层**最大传输单元（MTU）**限制，大部分以太网帧能承载的字节数只有 **1500 字节**，因此大部分 IP 数据报都为 20 + 1480 的结构。当数据报过大时，需要进行**分片**，较小的数据报被称为**片（fragment）**。这些片需要到达目的地时被重新组装后再交给上层，为了避免路由器设计过于复杂和影响性能，分片重组任务**一般**放在端系统上，因此 TCP 和 UDP 可以收到完整的报文段内容。

为了能够执行重组任务，IPv4 将相关信息放在了数据报首部的**标识符**、**标志位**和**片偏移**字段中，而 IPv6 不允许进行分片。发送主机通常在发送数据报时将每个分片数据报的标识符**加一**，将 MF 位置 1 表示接下来还有分片数据报，置 0 表示分片以全部发送。而片偏移则记录之前已有多少字节的有效载荷到达。

以一个总长度为 4000 字节，头部长度 20 ，片大小为 1500 的 IP 数据报为例，每次分片的数据报首部包含以下信息：

| 序号 | Total Length | 载荷长（Total - Head） | More Fragment | Offset |
| ---- | ------------ | ---------------------- | ------------- | ------ |
| 1    | 1500         | 1480                   | 1             | 0      |
| 2    | 1500         | 1480                   | 1             | 1480   |
| 3    | 1040         | 1020                   | 0             | 2960   |

#### IPv4 编址

一台主机通常只有一条与物理链路直接连接的**接口（interface）**；而路由器为了进行输入和输出转发，至少需要两个接口，因此一般路由器会有多个接口与物理链路相连。为了分辨网络中的主机与路由器，各个主机和路由器的接口就需要一个唯一 **IP 地址**进行区分。事实上，IP 地址与一个**接口**关联，而不是与一个主机或路由器关联。

每个 IP 地址长度为 **32 比特**，因此大致有 2^32^ 个（约 40 亿）可能的 IP 地址，这些地址采用**点分十进制记法**书写，各字节（8 比特）用一个点隔开。互联网中每台主机和路由器上的**每个接口**都必须有一个全球**唯一**的 IP 地址，且每个接口的 IP 地址规则会和其所在的**子网**相关。

##### 子网

通常情况下，一台路由器的一个**接口**会和一些主机在一个较小的**子网（subnet）**中连接，这个子网的具体形式可能是以太网 LAN ，也可能是一个无线接入点 WLAN 。IP 编址组织会为该子网分配一个 **IP 地址区间**，并由子网决定每台主机和路由器接口的具体 IP 地址。

##### 子网掩码

子网中的每个接口 IP 地址都分为**网络部分**和**主机（接口）部分**。为了在 CIDR 中区分两部分内容，每个子网 IP 都带有一个 **32 位**的**子网掩码（network mask）**。子网掩码的值表示 IP 地址中哪些部分是网络部分，如一个 IP 地址`223.1.1.0/24`中的`/24`就是子网掩码的十进制值形式，表示该 IP 的前 24 位（从左向右，从高位到低位）为网络部分，而后面的 8 位为主机部分，是子网可以为设备自由分配的**地址范围**。子网掩码“掩盖”了子网中的主机部分 IP 地址，因此是一层“掩码”。

子网掩码的 32 位二进制的**格式**为：值为 1 的部分所对应的 IP 比特为网络部分比特，为 0 的部分对应的 IP 比特为主机部分比特。如`/24`表示子网掩码`255.255.255.0`，只需将子网掩码和 IP 主机的地址进行**按位与（AND）**运算，计算结果就是网络部分的 IP 地址，**按位非（NOT）**就是子网中的主机地址。

如果要根据需要分配的子网数量计算子网掩码，首先应求出需要的子网数的二进制数的比特位数，如 27 个子网需要 5 比特的子网掩码位（`11011`）。因此对于一个 A 类地址，其子网掩码应为 `/8 + 5`，B 类为 `/16 + 5`，C 类为 `/24 + 5` ，CIDR 下处理方式相同。即当前子网掩码为 M~0~，需要继续划分 N 个子网的子网，需要的十进制子网掩码 M 有以下公式：
$$
M=M_0+\lceil log_2 N \rceil\\向上取整
$$
如果要根据需要的主机 IP 数量计算子网掩码，首先应求出需要的主机数的二进制数的比特位数，如一个子网的 700 台主机需要 10 比特的子网掩码位（`1010111100`），其子网掩码应为 `/(32 - 10)`，CIDR 下处理方式相同。即对于 N 台主机，需要的十进制子网掩码 M 有以下公式：
$$
M=32 - \lceil log_2 N \rceil\\向上取整
$$
在过去，子网标准规定 IP 的主机部分不能全为 1 或 0，用作子网广播地址。要注意计算后的 2^N^ 的值，如果小于主机数 + 特殊地址数，要额外扩充一位。对于一个 C 类网，如果遵守该规则，主机地址应为`x.x.x.1 ~ x.x.x.254`，而不是`x.x.x.0 ~ x.x.x.255`。

没有子网掩码的 IP 地址对于中间路由器来说是没有意义的，因为路由器将不知道根据哪个部分的地址在路由表中选择转发出口。

##### CIDR

**无类别域间路由选择**（Classless Interdomain Routing，**CIDR**）是目前因特网的路由分配和解析策略。一个**组织外部**的路由器**只会**关注数据报中 IP 地址的网络部分，并将目的链路指向对应的组织内部路由器；而**组织内部**路由器**只会**关注 IP 的主机部分，并将数据报转发至对应的主机接口。通过使用子网掩码将主机和路由器接口的 IP 地址分为网络和主机部分，为每个组织的**路由器**分配一个固定的唯一 IP，使得组织内部主机的 IP 地址可以灵活配置，并减少了路由器中的转发表长度和检索时间。

IP 地址的网络部分也称为 IP **前缀（prefix）**。这种使用单个网络前缀通告多个网络的能力被称为**地址聚合（address aggregation）**或**路由聚合（route aggregation）**。

##### 分类编址

在 CIDR 采用前，互联网管理组织使用**分类编址（classful addressing）**的方式按照 8 、16 、24 比特网络部分长度的分类方式发放被称为 A 、B 、C 、类的 IP 地址。一个 C 类地址只能容纳 2^7^ 个（256） IP 地址，一般被发放给小型组织，而 B 类和 C 类则分别可以容纳更多的主机。然而，A 类地址对于中小组织来说并不总是足够，B 、A 地址对于大型（地区 ISP）和区域组织（国家）而言又可能过多，这种分配方式造成了极大的资源浪费，因此提出了 CIDR 分配方式。

在分类编址下，IP 被分为**公有地址**和**私有地址**两类，私有地址留给组织内部分配使用（经过 NAT 处理），就像 CIDR 中的子网地址一样，同样通过子网掩码标识，与 CIDR 不同的是子网掩码将**只会**是`/8`、`/16`和`/24`。

最初设计 IP 协议时，总共定义了 5 种（A ~ E）类型的 IP 地址，其中 D 和 E 类为特殊地址，其他三类地址的分配有以下规则：

| 类别 | 最大网络数     | IP地址范围                | 最大主机数 | 私有IP地址范围（本地局域网） | 其他                       |
| ---- | -------------- | ------------------------- | ---------- | ---------------------------- | -------------------------- |
| A    | 126(2^7^ - 2)  | 1.0.0.1-127.255.255.254   | 16777214   | 10.0.0.0-10.255.255.255      | 127.255.255.255 为广播地址 |
| B    | 16384(2^14^)   | 128.0.0.1-191.255.255.254 | 65534      | 172.16.0.0-172.31.255.255    | 191.255.255.255 为广播地址 |
| C    | 2097152(2^21^) | 192.0.0.1-223.255.255.254 | 254        | 192.168.0.0-192.168.255.255  | 223.255.255.255 为广播地址 |

其中 C 类私有地址常用于 NAT 下的子网设备 IP 分配。

D 类地址在历史上称为**多播地址（multicast address）**，范围从 224.0.0.0 到 239.255.255.255 。

此外还有一些**特殊规则**：

1. 每一个字节都为 0 的地址`0.0.0.0`对应于**本机地址**；
2. IP 地址中的每一个字节都为 1 的地址`255．255．255．255`是当前子网的**广播地址**；
3. IP 地址中凡是以`11110`开头的 E 类 IP 地址（`240.0.0.0`~`255.255.255.255`）都**保留**用于将来和实验使用；
4. IP 地址中不能以十进制`127`作为开头，该类地址中数字`127．0．0．1`到`127．255．255．255`用于**回路测试**（检测本机网络服务是否正常），如：`127.0.0.1`可以代表**本机 IP 地址**，对该地址发送请求 ping 可测试本机 TCP/UDP 服务是否开启。用`http://127.0.0.1`就可以测试本机中配置的 Web 服务器（在 windows 系统中`localhost`是该地址的别名）；
5. IP 的第一个 6 位组也不能全置为 0 ，全 0 表示**本地网络**（`127.0.0.1`）。

##### IP 广播地址

**IP 广播地址**`255.255.255.255`是一个特殊的不会被分配给任何特定接口的特殊广播地址。当一个主机发出一个地址为广播地址的数据报时，子网的路由器会将该数据报发送给子网中的所有互联主机，并有选择的向路由器连接的其他子网广播。许多恶意病毒和蠕虫程序会利用广播地址进行传播，因此子网中的任意主机在感染病毒和蠕虫后很容易造成其他子网主机感染。

##### IP 管理组织

对于某个接入互联网的组织来说，其 IP 地址范围通常是从本地 ISP 获取的，而本地 ISP 所管理的 IP 范围授权则来自于更高层的管理机构。实际上，存在一个全球性的权威机构负责管理所有 IP 地址空间的分配，并管理根 DNS 服务器，该机构是 **ICANN**（The Internet Corporation for Assigned Names and Numbers）互联网名称与数字地址分配机构，是一个国际间的非盈利性组织。国内的域名管理和分配组织是中国互联网络信息中心（China Internet Network Information Center，**CNNIC**）。

##### DHCP

某组织一旦获取了一个范围的 IP 地址，就会为组织中的路由器与主机接口分配一个唯一的 IP 地址。网络管理员可以手动分配该地址，但为了子网主机的安全性和最大化利用 IP（子网中的主机并不一定时刻联网，且子网 IP 是有限的），更多的时候是使用**动态主机配置协议（Dynamic Host Configuration Protocol，DHCP）**进行动态分配。DHCP 是应用层协议，由 UDP 封装，在 IP 协议中广播。

DHCP 是一个**客户端-服务器**架构的协议，客户通常是**需要联网的主机**，该主机需要获取自身联网时包括 IP 地址在内所需的信息；而服务器则是子网中一台单独存在的 **DHCP 服务器**，负责子网中 IP 地址的分发；如果没有一台 DHCP 服务器位于子网，就会有一个 **DHCP 代理**（通常是一个路由器）到局域网范围内寻找其他 DHCP 服务器。

对于一台新到达的需要联网的主机，DHCP 服务器分配 IP 地址的过程大概包括 **4 个步骤**：

1. **DHCP 服务器发现**：客户主机在联网时需要**发现**子网中的 DHCP 服务器。由于此时还没有 IP，客户主机会在一个 **UDP 分组**中向**端口 67**发送一个 **DHCP 发现报文**，并将**源地址**置为`0.0.0.0`，**目的地址**为 IP 广播地址`255.255.255.255`。路由器将广播该消息到子网中每台主机接口上。如果路由器是一个 **DHCP 代理**，则不进行广播，而是将请求转发到自己所知道的局域网 DHCP 服务器中；
2. **DHCP 服务器提供**：DHCP 服务器收到一个 DHCP 发现报文时就需要提供自身的 IP 地址信息。为了进行响应，服务器会在 **DHCP 提供报文**中使用 IP 广播地址作为**目的地址**向子网广播消息，并包含自身 IP 作为**源地址**。此外，提供报文中还包括发现报文的**事务 ID**供客户主机确认，并提供一些**推荐**给客户的 IP 地址以及其**租期**，租期一般为几小时或者几天；
3. **DHCP 请求**：客户主机从服务器提供的 IP 地址中选择一个，并以此作为源端口向服务器返回一个 **DHCP 请求报文**以**回显**；
4. **DHCP ACK**：服务器接收到请求后发送一个 **DHCP ACK 报文**响应。

使用 DHCP 协议动态配置主机接口 IP 可以使子网 IP 资源最大化利用，但当一台主机需要在不同子网中移动时，就必须更换新的 IP 地址，因此不能维持原有的 TCP 连接。移动 IP 技术可以使用一个单一永久的地址解决该问题。

##### 实例：Ping 命令

Windows 和 Linux 中提供一个命令行程序 Ping，用于向目的 IP 发送请求 Ping 以检查网络状态。该程序还可以用于本机回路测试。

假设客户端向服务器发送一个请求 Ping ，客户主机连续发送了两个 Ping Request 报文，它们的 IP 数据报部分的首部的十六进制字节流分别为：

+ `45 00 05 dc 84 27 20 00 80 01 d6 1e c0 a8 00 64 60 2c 99 a2`
+ `45 00 02 24 84 27 00 b9 80 01 f9 1d c0 a8 00 64 60 2c 99 a2`。

1. 承载 Ping 请求的 ICMP 报文的 IP 数据报的载荷长度为：

   观察第 17 ~ 32 比特，值为`0x05dc`，即典型长度 1500 。观察整个首部，长度为 20 字节，因此载荷长度为 1480 字节；

2. 目的主机的 IP 地址为：

   观察第 129 ~ 160 比特，值为`0x602c99a2`；

3. 该链路的 MTU 为：

   观察 49 ~ 56 字节，即`0x20`，前三个字节为标志位，值为`001`，More Fragment 为 1，说明该数据报被分片，因此有两个连续的报文被发出；观察第 17 ~ 32 比特，值为`0x05dc`，即典型长度 1500 ，因为分片，上层 MTU 为 1500 字节；

4. 此 IP 数据报的 16 比特标志位为：

   观察 33 ~ 48 比特，值为`0x8427`

5. 两个 IP 首部不同的地方有：

   由于进行了分片，两个数据报不同的地方有：

   1. 数据报长度字段
   2. 标志位第三位 More Fragment
   3. 片偏移
   4. 校验和

此外，Ping 程序还常用于网络故障检测：

+ Ping `127.0.0.1`/`localhost`：

  `127.0.0.1`是本地的循环地址，Ping 通则说明本机 TCP/IP 协议工作正常，否则 TCP/IP 就不正常；

+ Ping 本机的 IP 地址：

  若 Ping 通，说明网络适配器工作正常，否则就不正常；

+ Ping 同子网计算机 IP 地址：

  Ping 不通则说明网络线路出现故障（包括网线，HUB，交换机，路由器）

+ Ping 域名：

  Ping 目标主机的域名，正常情况下会出现该网址所指向的 IP 地址，这表明本机的 DNS 设置正确而且 DNS 服务器工作正常

#### 网络转换协议

现在，网络用户数量不断增加，越来越多的办公和家庭网络端系统开始接入互联网，原先的 IPv4 在网络部分分配时已经出现了数量不足的问题，因此为每个子网准备的 IP 范围也越来越少。如果一个子网中的联网设备数量超过了分配的地址范围，就需要考虑进行**扩展**。一种在不扩展子网 IP 下的解决方案则是使用**网络地址转换（Network Address Translation，NAT）**，NAT 是一种**网关（gateway）**服务。

现在，大部分的路由器如家用路由器都内置了 NAT 功能，因此是**具对于有 NAT 使能的路由器**。例如，通过 NAT ，可以使一个被子网掩码`255.255.255.0`约束的子网 IP 范围在子网中扩展为子网掩码`255.0.0.0`的约束，因此可以有更多子网设备接入互联网。对于广域网中的路由器和设备而言，NAT 使能的路由器就像一台具有**单一** IP 地址的主机。

##### NAT 转换表

为了让提供给广域网的 IP 地址和 NAT 下的子网 IP 对应，NAT 使能路由器中需要有一张 **NAT 转换表（NAT translation table）**。该表中包含了两个表，**广域网（WAN）**部分和**本地局域网（LAN）**部分。

在 WAN 表中，存储了**实际 IP 地址**和代表不同主机的**套接字端口**的映射关系键值对，NAT 会使用一个实际没有执行套接字作用的端口号用于子网**主机寻址**。在这种情况下，一个 IP 地址实际上对应了**多台主机**接口，而一个端口号则对应一个唯一的子网主机。WAN 表与 LAN 表的关系是 **IP 和端口**这一二元组与**主机**的映射。在 LAN 表中，存储了扩展的**子网 IP 地址**和主机**进程套接字端口**映射关系键值对。就像在没有 NAT 时一样，经 NAT 路由器转发的分组通过该映射来寻找对应的主机和主机进程。WAN 表中的端口会和 LAN 表中的每个映射相关联，用于响应分组的转换。

假设在 NAT 情境下，扩展子网 IP 和端口为`10.0.0.1:3345`的一个主机**进程**（浏览器）要向 IP 地址和端口为`128.119.40.186:80`的 Web **服务器**请求一个页面，并经过一台 IP 地址为`138.76.29.7`的 **NAT 使能路由器**进行 NAT，整个过程中大致会发生以下事情：

1. **浏览器**发送一个源为`10.0.0.1:3345`，目的地为`128.119.40.186:80`的 IP 数据报，该报文段先到达 NAT 路由器；
2. **NAT**在 LAN 表中记录子网 IP 和进程端口的信息，处理 IP 数据报和运输层报文段**首部**，选择一个**端口号**`5001`作为主机的映射，将源改为`138.76.29.7:5001`；
3. **NAT**在 WAN 表中记录修改后的源映射信息，并**关联** WAN 中的端口号和 LAN 中的映射，将数据报发送给`128.119.40.186:80`；
4. **服务器**返回一个目的地为`138.76.29.7:5001`的 IP 数据报，NAT 根据 WAN 表查找到了用于**主机寻址**的端口号，并根据该端口号找到了 LAN 表中的主机信息，将目的地址改为`10.0.0.1:3345`发送给浏览器所在主机；
5. 浏览器所在主机的**接口**解析 IP 首部信息，并将载荷向上层套接字端口提交，最终将页面递交给浏览器。

虽然 NAT 的 WAN 表中的 套接字端口没有直接用于任何进程寻址，但是为了避免服务器解析端口时出现合法性问题，也应该满足套接字端口的规则，即为一个 16 比特的数。因此，通过 NAT 最多可以将一个 IP 地址用于 65535 个子网主机扩展 IP 的分发。

##### 关于 NAT 的讨论

在正常的计算机网络通信中，IP 地址被网络层用于路由器和主机接口寻址，而套接字端口被运输层用于进程寻址。NAT 作为一个类似主机的存在打破了这些关系，将端口号用于主机寻址。这种做法引发了一些问题和讨论。

由于服务器收到的运输层报文段首部中的**端口**是修改过的，在一些应用场景下，运输层协议会期待接收一个来源于特定周知端口的报文段，如 P2P 。此时修改的报文段首部端口字段可能会被服务器拒收。对应的解决方案是使用 **NAT 穿越（NAT traversal）**或**通用即插即用（UPnP）**。

此外，OSI 模型的支持者认为 NAT 违反了网络模型原理：在路由器中的 NAT 服务是属于网络层的，因此应该只关注和处理网络层的内容，并应该只处理到达的数据报，更不应该修改运输层报文段中的信息。

事实上，目前的 NAT 技术的使用已经非常广泛，成为因特网中重要的**中间盒**，起着负载均衡、流量防火墙等功能。

##### 防火墙和 IDS

如果网络攻击者知道自己攻击目标的精确 IP 地址或其范围，就可以通过各种手段获取目标主机信息（如通过 ping 搜索与端口试探扫描生成攻击目标的网络图），并发送非法分组达到对应攻击目的。对于恶意攻击，常见的防御手段有**防火墙（Firewall）**和**入侵检测系统（IDS）**，两者都是**网络层**应用或设备。

防火墙是一种用于**阻止或通过**特定分组以达到防御目的地防御手段。防火墙通常位于路由器中，也可能位于直接和互联网连接的主机中，是广域网和本地局域网/主机间的安全屏障。防火墙会检查数据报和报文段的首部，拒绝可疑分组进入。如，一台防火墙设备可以被设置为阻挡大部分的 ICMP 回显请求分组以阻止攻击者进行 IP 范围内的端口扫描。

IDS 一般位于网络的边界，即端系统主机或边界子网的路由器中，并执行**深度**分组检查：不仅检查首部，还检查有效载荷。IDS 具有一个庞大的分组特征数据库网络，记录了所有已知攻击的分组特征，并不断更新最新的攻击分组特征。如果 IDS 发现可疑分组，就将其阻挡在目的地外。相比防火墙，IDS 的实现开销一般是巨大的，因此能提供该服务的第三方数量并不是特别多。作为一种被动式防御手段，IDS 在防御分布式拒绝服务攻击（DDoS）时仍然有较好的效果。

#### IPv6

在 2019 年 11 月 25 日，IPv4 `/22`网络部分的 IP 地址已经全部分发完毕，剩下的子网 IP 分配干净只是时间问题，而现在的 IPv4 地址已经不能再为新出现的地区组织提供网络接入服务了。IPv6 采用 **128 比特**的网络地址能够很好地解决地址分发数量问题。此外，于 20 世纪 90 年代就开始研究的 IPv6 还能解决其他 IPv4 中出现的问题。

IPv6 使用**冒号分隔**每个 16 位二进制数表示的 10 进制数，因此总共有 8 个区间。

##### IPv6 数据报格式

IPv6 的数据报去除了一些 IPv4 中的冗余和不需要的部分，并扩展了一些内容，IPv6 数据报包含以下内容：

+ **版本**：4 比特，IPv6 的首部版本字段的有效值将是`0110`即 6 ，将该字段设置为 4 并不能创建一个合法的 IPv4 数据报，因为其他字段的内容 IPv4 处理设备无法处理；
+ **流量类型**（traffic class）：8 比特，类似 IPv4 中服务类型字段的作用，用于区分实时和非实时流量或标记控制数据报等；
+ **流标签**（flow label）：20 比特，**新增**的字段。该字段被一些特殊数据流打上标签，表示发送方要求该数据报被**特殊对待**。比如作为实时音视频或高级用户所有的流量在网络层中优先传递；
+ **有效载荷长度**：16 比特，IPv6 中不再包含总长度，而是直接记录载荷长度。IPv6 将有一个固定的 **40 字节首部长度**；
+ **下一个首部**（next header）：8 比特，该字段用于指示上层协议，因此被称为下一个首部。常见的值有：
  + ICMP ： 1
  + IPv4 ： 4（用于隧道情况）
  + TCP ： 6
  + UDP ： 17
+ **跳限制**（hop limit）：8 比特，IPv6 将每次路由称为**跳（hop）**，每次路由跳限制字段将减一，值为 0 时路由器将直接丢弃该数据报；
+ **源地址**：128 比特；
+ **目的地址**：128 比特；
+ **有效载荷**

而原先 IPv4 中的一些部分**不复存在**：

+ 标识符、标记位、片偏移：这些和分片相关的首部已经弃用，IPv6 **不允许**进行分片，这种操作不应该在路由器中进行，而是应该在源和目的地，即端系统上进行，这么做是为了加快路由转发过程。如果某个数据报过大而路由器无法处理，只需将其丢弃并返回一个 **ICMP “分组过大”差错报文**；
+ 首部校验和：首部校验和计算在每次路由中都需要重新计算，且和上层协议有冗余部分，因此被弃用；
+ 选项：选项在 IPv4 中很少用到，因此被弃用。但这些选项没有消失，它们被放在**上层报文段的首部**中。如果路由器需要，可以尝试解析报文段首部。

IPv6 同样采取多层拓扑，具有网络部分和主机部分以进行子网划分，区别是因为地址足够，不需要私有地址划分。支持 IPv6 的路由器内置转发表，根据网络部分转发分组到外部子网路由器，根据主机部分转发分组到子网。

##### 从 IPv4 迁移

IPv6 是向后兼容的，因此可以用于发送 IPv4 数据报，但是 IPv6 数据报**无法**由 IPv4 架构下的设备解析。一种被提出的迁移方案是在世界范围内宣布一个标志日，在当天完成所有互联网机器设备的升级。上次这么做还是在上世界 80 年代左右升级 NCP 到 TCP 的时候，但那时的因特网用户并不多，对于如今的因特网来说这种做法是不现实的。

因此，相比直接升级设备，更合理的一种做法是使用 IPv6 **隧道（tunnel）**，这种做法在应用层的 HTTPS 协议升级中也有使用。如果两个 IPv6 节点中存在一些 IPv4 设备，这些设备的集合就被称为隧道。**IPv6 输出节点**可以将 IPv6 数据报作为有效载荷封装在 IPv4 数据报中进行传输，由 IPv6 输出节点拆封并重新发送 IPv6 数据报。

### 4.4 通用转发和 SDN（OpenFlow）

前面所讲的路由器转发均是基于分组目的地址的转发。事实上，这种转发相关的一系列过程已经被证明拥有一种通用的**路由器行为模式**。这种模式被总结为两个步骤：

+ **查找**目的 IP 地址
+ **发送**到有特定输出端口的交换结构

因此，该模式被概括为一种**匹配加动作**的行为模式。基于目的地址的匹配加动作仅关注网络层本身的信息，这符合 OSI 网络模型的基本原则，但是可以看到，防火墙和 IDS 已经开始关注其他层的首部信息，因此需要有一种更加通用的模式来描述该行为。目前，最为成功和被高度认可的标准是 **OpenFlow** 。

#### 匹配动作表（流表）

在通用转发和 SDN 控制情境下，所有路由器的行为可以用一张**匹配加动作表**进行描述：根据一组匹配规则，执行相应动作。在 OpenFlow 中，该表被称为**流表（flow table）**，其中包含了一些表项（行）。通常为了可维护性，一张流表会由多个流表实现，如按照关系模型存储在多个关系表中。这些表项一般来自于三个部分：

+ 各层分组的首部字段：进入路由器的分组将与该部分的值进行匹配，并执行该项（行）中对应的动作。如果没有匹配成功，则丢弃分组，这类似于防火墙和 IDS 的功能；
+ 一组计数器的集合：表项中包含一些用于记录状态的计数器，如已经匹配成功的分组数量
+ 对应的动作集合：一组动作，将在匹配成功时依次执行

#### 匹配

OpenFlow 允许对来自三个协议层的首部字段值进行自定义正则模式的匹配（**打破**了 OSI 分层原则），包括 12 个典型的匹配字段：

+ 入端口：分组交换机（如路由器）上接收分组的输入端口
+ 链路层：
  + 源 MAC
  + 目的 MAC
  + 以太网类型
  + VLAN ID
  + VLAN 优先权
+ 网络层：
  + 源 IP
  + 目的 IP
  + IP 协议类型
  + IP 服务类型（TOS）
+ 运输层
  + TCP/UDP 套接字源端口
  + TCP/UDP 套接字目的地端口

在 OpenFlow 1.0 规范中只有这些字段值可以进行匹配，而在最新的规范中可进行匹配的字段已经超出了 40 个。可以看到，并非所有协议的所有首部字段都被运行进行匹配，这主要是为了避免整个 OpenFlow 规范与某层特定协议产生**紧耦合**，因此只选取通用的抽象字段进行匹配。此外，这些表项的匹配部分可以使用**通配符**或正则表达式来描述一种模式。

#### 动作

每个匹配动作表（流表）中都有 0 个或多个动作项，最主要的三个动作一般是：

+ **转发**：根据匹配结果，将分组转发到特定输出端，或**多播**到一组输出端，或**广播**到所有输出端；
+ **丢弃**：如果动作项**为 0** ，表示应该丢弃分组；
+ **修改字段**：可以修改三层分组中的首部字段值，但要注意不能引起过分的行为变化，比如修改 IP 首部中的协议字段可能引发接下来的路由问题。

#### 一些实际场景

OpenFlow 目前已经有了不少实现，在一些场景中得以运用：

+ 简单转发：一些转发表项中会包含 IP 地址、套接字端口信息以决定接下来的转发动作（即输出端口）；
+ 负载均衡：最常见的负载均衡情况是根据分组交换机的**入端口**决定出端口，以达到负载均衡；
+ 防火墙：对于没有能够匹配流表项的分组，分组交换机将直接**丢弃**。

## 第五章 网络层：控制平面

### 5.6 ICMP：因特网控制报文协议

**因特网控制报文协议（Internet Control Message Protocol，ICMP）**是 IP 协议的一个子协议，被封装在 IP 的有效载荷中，被主机和服务器用于彼此沟通网络层信息。ICMP 报文的结构为：

+ 类型：8 bits，和编码一起使用，解释报文信息
+ 编码：8 bits，和类型一起使用，解释报文信息
+ 校验和：16 bits
+ 其他首部部分
+ 载荷

类型和编码的含义：

| TYPE | CODE | Description                                                  | Is Query | Is Error |
| :--: | :--: | ------------------------------------------------------------ | :------: | :------: |
|  0   |  0   | Echo Reply——回显应答（Ping应答）                             |    x     |          |
|  3   |  0   | Network Unreachable——网络不可达                              |          |    x     |
|  3   |  1   | Host Unreachable——主机不可达                                 |          |    x     |
|  3   |  2   | Protocol Unreachable——协议不可达                             |          |    x     |
|  3   |  3   | Port Unreachable——端口不可达                                 |          |    x     |
|  3   |  4   | Fragmentation needed but no frag. bit set——需要进行分片但设置不分片比特 |          |    x     |
|  3   |  5   | Source routing failed——源站选路失败                          |          |    x     |
|  3   |  6   | Destination network unknown——目的网络未知                    |          |    x     |
|  3   |  7   | Destination host unknown——目的主机未知                       |          |    x     |
|  3   |  8   | Source host isolated (obsolete)——源主机被隔离（作废不用）    |          |    x     |
|  3   |  9   | Destination network administratively prohibited——目的网络被强制禁止 |          |    x     |
|  3   |  10  | Destination host administratively prohibited——目的主机被强制禁止 |          |    x     |
|  3   |  11  | Network unreachable for TOS——由于服务类型TOS，网络不可达     |          |    x     |
|  3   |  12  | Host unreachable for TOS——由于服务类型TOS，主机不可达        |          |    x     |
|  3   |  13  | Communication administratively prohibited by filtering——由于过滤，通信被强制禁止 |          |    x     |
|  3   |  14  | Host precedence violation——主机越权                          |          |    x     |
|  3   |  15  | Precedence cutoff in effect——优先中止生效                    |          |    x     |
|  4   |  0   | Source quench——源端被关闭（基本流控制）                      |          |          |
|  5   |  0   | Redirect for network——对网络重定向                           |          |          |
|  5   |  1   | Redirect for host——对主机重定向                              |          |          |
|  5   |  2   | Redirect for TOS and network——对服务类型和网络重定向         |          |          |
|  5   |  3   | Redirect for TOS and host——对服务类型和主机重定向            |          |          |
|  8   |  0   | Echo request——回显请求（Ping请求）                           |    x     |          |
|  9   |  0   | Router advertisement——路由器通告                             |          |          |
|  10  |  0   | Route solicitation——路由器请求                               |          |          |
|  11  |  0   | TTL equals 0 during transit——传输期间生存时间为0             |          |    x     |
|  11  |  1   | TTL equals 0 during reassembly——在数据报组装期间生存时间为0  |          |    x     |
|  12  |  0   | IP header bad (catchall error)——坏的IP首部（包括各种差错）   |          |    x     |
|  12  |  1   | Required options missing——缺少必需的选项                     |          |    x     |
|  13  |  0   | Timestamp request (obsolete)——时间戳请求（作废不用）         |    x     |          |
|  14  |      | Timestamp reply (obsolete)——时间戳应答（作废不用）           |    x     |          |
|  15  |  0   | Information request (obsolete)——信息请求（作废不用）         |    x     |          |
|  16  |  0   | Information reply (obsolete)——信息应答（作废不用）           |    x     |          |
|  17  |  0   | Address mask request——地址掩码请求                           |    x     |          |
|  18  |  0   | Address mask reply——地址掩码应答                             |          |          |

#### Traceroute

Traceroute 程序实际上利用 ICMP 报文来进行**路由跟踪**。源主机中的 Traceroute 向目的地主机发送一系列普通的 IP 数据报，每个数据报都包含一个**不可到达**端口的 UDP 数据报。此外，这些 IP 数据报的 TTL 依次从 1 开始增加，当第 N 个数据报到达第 N 个路由器时，数据报的寿命刚好结束。根据 IP 协议，路由器必须返回一个 **ICMP 警告**报文（类型 11 编码 0），该报文包含了路由器的名字和 IP 地址，因此 Traceroute 可以获取网络拓扑信息。而当 TTL 非 0 的数据报到达主机，主机将返回一个**ICMP 端口不可达**报文（类型 3 编码 3），此时 Traceroute 程序便停止发送数据报。

## 第六章 链路层和局域网

### 6.1 链路层概述

在链路层中，有几个关键术语：

+ **节点（node）**：运行链路层协议的任何**设备**，如主机、路由器、交换机、Wi-Fi 接入点
+ **链路（link）**：连接相邻节点的通讯**信道**
+ **帧（frame）**：链路层**分组**，封装有数据报

#### 链路层提供的服务

链路层提供的**基本服务**是通过单一信道链路将分组从一个节点运输到另一个节点。此外，大部分链路层协议的服务模型还包括：

+ **成帧（framing）**：封装上层数据报；
+ **链路接入**：**媒体访问控制（MAC）**协议规定了帧在链路上传输的规则。MAC 地址被用于以太网寻址；
+ **可靠交付**：保证无比特差错地交付分组。链路层服务的可靠交付和运输层一样，通过**确认和重传**实现。在易产生错误的信道如无线信道中，一般协议会包括可靠交付服务；在不易产生错误的信道如光纤、同轴电缆、双绞铜线链路中，协议可能不提供该服务；
+ **差错检测和校正**：链路层的传输差错一般来自于信号衰减和电磁噪声，并且该服务的实现相较运输层更为复杂，一般在**硬件**上实现。

#### 链路层的实现位置

在路由器中，链路层功能一般实现在**线路卡**中；而在主机上，链路层一般实现在**网络适配器（network adapter）**中，也称**网络接口卡（NIC）**，其核心是**链路层控制器**，所有链路层事务均在 NIC 中处理，然后才向节点网络层递交。该控制器是一个实现了多种上述服务的**芯片**，因此大多数链路层功能都实现在**硬件**中。现在，越来越多的网络适配器被直接综合进了主机的主板，而不再是外接设备。

此外，有部分链路层功能会在主机 CPU 上的软件中实现。

### 6.2 差错检测和纠正技术

链路层的**比特级差错检测和校正（bit-level error detection and correction）**通常会使用多个**差错检测和校正比特（EDC bit）**以及一些算法来实现，并且大部分情况下是一种**前向检测（Forward Error Detection，FED）**，即由接收方进行检测，对应的纠错称**前向纠错（Forward Error Correction，FEC）**。在这种情况下，接收方需要能够在仅接收差错比特和信息比特的情况下检出错误，并且可能还是会产生**未检出比特差错**。

#### 奇偶校验

**奇偶校验**是最简单的校验方法，且**二维**奇偶校验可以用于纠正。奇偶校验会在原有的数据信息 **D** 后加上 d + 1 个**EDC 比特**。在奇校验中，数据信息和校验比特中总共有**奇数个** 1 比特；在偶校验中，数据信息和校验比特中总共有**偶数个** 1 比特。如果接收方发现 1 比特的个数不对，就说明**出现**差错。

而二维奇偶校验将所有信息比特按 i 行 j 列分为一个矩阵，每行和每列都有一个校验比特。通过校验行与列，就可以定位出错误的比特坐标，并取反以修正。

奇偶校验的**主要问题**是当出现多个差错时，1 和 0 比特的奇偶数可能没有变化，导致错误无法检出。

#### 校验和

**校验和（checksum）**技术类似于运输层使用的因特网校验和。按一定方式将 k 位比特相加（溢出回卷）并取反计算出校验和并作为 EDC 比特存放在分组中。接收方将校验和和其他分组比特相加，如果结果不是 1 就说明出现差错。但是该方式**无法**直接进行修正。

#### 循环冗余检测

**循环冗余检测（Cyclic Redundancy Check，CRC）**是如今计算机网络中使用最多的差错检测和纠正技术。CRC 比奇偶校验与校验和更加复杂，因此被实现在硬件中以提高速度。CRC 有几个重要的概念：

+ 数据比特 **D** ：分组中原有的数据比特；
+ D 的位数 **d**
+ CRC 比特 **R** ：发送方和接收方约定的一个**EDC 比特**；
+ R 的位数 **r**
+ 生成多项式（generator） **G** ：发送方和接收方约定的一个 r + 1 位的**比特模式**，只存储在节点中，不会封装在帧中。

如果接收方收到的分组数据满足（n 是一个整数，右值没有常数项）：
$$
D\cdot 2^r \oplus R\ =nG
$$
那么说明接收到的分组不存在差错。即先将 D **左移** r 位，与 R 进行**异或**运算，然后与 G 进行**模运算**，如果没有余数，说明不存在差错，写成 C 语言代码为：

```c
if(((D << r) ^ R) % G == 0) { /* 无差错处理 */ } else { /* 差错处理 */ }
```

实践中，生成多项式 G 和 CRC 比特 R 的预计值是一个接收和发送方都知道的**常量**，除了 R 的实际值以外的信息均可以从帧中直接获取，因此接收方检测差错的手段是**计算 R 的实际值**。要计算 R，首先将 D 左移 r 位（避免 D 比 G 短），再与 G 进行按位模 2 （每步异或运算，即每次和 D 的前 r + 1 位异或，然后左移一位和后面的 r + 1 位异或，迭代 r 次）运算，得出的余数就是 R 。

以下是一个 D = 101110，d = 6，G = 1001，r = 3 的分组的 CRC 比特 R 的计算过程：
$$
注意：每行进行的是异或运算\\
\begin{array}{lr}  & 101011 \\
1001  \!\!\!\!\!\! & \overline{)101110000} \\
& \underline{1001\ \ \ \ \ \ \ \ \ \ } \\
& 101\ \ \ \ \ \ \ \  \\
& \underline{000\ \ \ \ \ \ \ \ } \\
& 1010\ \ \ \ \ \ \\
& \underline{1001\ \ \ \ \ \ }\\
& 110\ \ \ \ \\
& \underline{000\ \ \ \ } \\
& 1100\ \ \\
& \underline{1001\ \ }\\
& 1011\\
& \underline{1001}\\
& 010
& \end{array}
$$
首先将 D 左移 3 位，然后逐 r + 1 = 3 位与 G 模 2（就像十进制除法计算那样）运算，最后计算结果 R = 010 。如果双方约定的 R 为 010，说明分组无错误。

国际标准定义了 8 、12 、16 和 32 比特的生成多项式，以便于跨区域的链路节点进行分组校验：

+ 8：`0x131`
+ 12：`0x180D`
+ CCITT 标准的 16 位多项式：`0x11021`
+ ANSI 标准的 16 位多项式：`0x18005`
+ 32：`0x104C11DB7`

一个使用 CCITT 16 位多项式进行 R 计算的标准 C 程序：

```c
// 输入：数据比特 data
// 返回：EDC 比特
unsigned short crc16_ccitt(unsigned char data)
{
    // 初始化
    unsigned short ccitt16 = 0x1021; // 生成多项式 G
    unsigned short crc = 0; // EDC 比特
    int i; // 循环下标
    
    crc ^= (data << 8); // 左移 r 位
    
    // 每位异或
    for (i = 0; i < 8; i++)
    {
        if (crc & 0x8000)
        {
            crc <<= 1;
            crc ^= ccitt16;
        }
        else
        {
            crc <<= 1;
        }
    }
    
    return crc;
}
```

CRC 的检验误差概率和 G 的位数相关，CRC-8 的检验误差为 1/2^8^，以此类推。

### 6.3 多路访问链路和协议

网络链路基本上可以归于两种类型：**点对点链路（point-to-point link）**（由单一发送方和接收方组成）和**广播链路（broadcast link）**（多个发送方和接收方在同一个信道上通信）。对于点对点链路，使用**点对点协议（PPP）**和**高级数据链路控制协议（HDLC）**；对于广播链路，将面临**多路访问问题（multiple access problem）**，即单一信道上如果有多个帧同时传输，这些帧会互相污染，导致无法识别，这种现象叫做**碰撞（collide）**。为了解决碰撞问题，多种**多路访问协议（multiple access protocol）**或称**媒体访问控制协议（Multiple Access Control Protocol，MAC）**被提出。多路访问协议可以被分为三种类型：

+ **信道划分协议（channel partitioning protocol）**
+ **随机接入协议（random access protocol）**
+ **轮流协议（taking-turns protocol）**

这些协议应该具有以下理想化的特性：

1. 当仅有一个节点在链路中通信，其传输速率等于链路传输速率 R bps；
2. 当有多个节点在链路中通信，每个链路的平均速率应相等且均分链路传输速率 R/N bps；
3. 协议是分散的，不会因为某个主节点故障而崩溃
4. 协议时简单的，实现不应昂贵

#### 信道划分协议

**信道划分协议**有三种：

+ **时分多路复用（TDM）**：将固定时间单位划分成**时间帧**，并将每个时间帧划分为多个**时隙**，每个时隙用于单个发送和接收方二元组传输。TDM 是目前计算机网络中使用最多的信道划分协议，但有两个**主要缺陷**：
  1. 传输速率始终为 R/N bps，即使只有一个发送方-接收方二元组
  2. 节点必须等到自己的时隙轮次才能通信，即使只有一个发送方-接收方二元组
+ **频分多路复用（FDM）**：将信道的总频段带宽划分为多个不同频段的**带宽**，避免了碰撞，且足够公平。缺陷和 TDM 类似：
  + 一个节点永远只能使用 R/N 的带宽
+ **码分多址（CDMA）**：为每个接收-发送二元组采用不同的**编码**，因此可以同时传输，并不受其他节点干扰。CDMA 在军用系统中比较成熟，并已经广泛运用在民用场景中，如蜂窝电话。

#### 随机接入协议

**随机接入协议**中，每个节点总是以最大传输速率 **R** 发送帧。如果发生碰撞，涉及碰撞的节点会**反复**发送碰撞的帧，**直到**不再发生碰撞。在反复之前，节点等待一个**随机**的时间间隔再重新发送帧。随机接入协议非常多，常用的有具有**时隙的 ALOHA 协议**、**普通 ALOHA 协议**、**载波侦听多路访问协议（CSMA）**。

##### 时隙 ALOHA

时隙 ALOHA 将满足：

+ 所有帧有 L 比特
+ 每个时隙为 L/R 秒
+ 节点只在时隙开始时传输帧
+ 所有节点同步时隙，知道在何时传输帧
+ 发生的碰撞会被节点在下个时隙开始前检测到

时隙 ALOHA 在**发生碰撞**时，将以概率 **p** 在之后的每个**时隙**重新反复发送帧，直到不发生碰撞。概率 p 将决定 ALOHA 的**最大传输效率**：当存在大量活跃节点且每个节点都发送大量帧时，**成功时隙（successful slot）**（不发生碰撞的时隙）的比例。在有 N 个节点的情况下，效率可以表示为：
$$
Np(1-p)^{N-1}
$$
当 N 趋向于无穷时，可以推断出理论上时隙 ALOHA 的最大效率为：`1/e`，约等于 0.37 ，这个效率明显不尽人意。但 ALOHA 确实是非常简单的一种协议。

##### ALOHA

最早的 ALOHA 不带有碰撞检测，并且完全分散（不同步时隙，不知道应该在何时传输帧），在碰撞发生后**立刻**以概率 p 重传而不是等待时隙。其效率大致为`1/2e`，约等于 0.184 。

##### 载波侦听多路访问 CSMA

CSMA 有两个特点：

1. **传输前先侦听**：如果链路上有帧在传输，就不发送，该行为称为**载波侦听（carrier sensing）**；
2. **如果传输过程中受到干扰，就停止传输**：该行为称为**碰撞检测（collide detection）**，碰撞检测的方式是节点在传输过程中监听是否有其他数据到达自己所在的信道位置，如果有说明前方帧和自己的帧产生碰撞。如果发生碰撞，所有碰撞方都会停止传输，并等待随机时间后重传。

这两个特点被包含在**载波侦听多路访问（CSMA）**和**具有碰撞检测的 CSMA（CSMA/CD）**协议簇中。之所以在侦听的情况下**还会**发生碰撞，是因为当节点认为信道空闲并发送帧时，实际上信道可能并不空闲，只是该节点之前的帧**还没有**到达该节点。**信道传播时延**对 CSMA 的性能起着决定性作用，该时延越低，发送的帧碰撞可能性也越低。

##### 具有碰撞检测的 CSMA

在 **CSMA/CD（载波监听冲突检测）**协议中，发生碰撞的所有相关节点都会停止当前传输并重传，这么做可以避免传输一个损坏的帧，实际上有助于改善协议性能。如果用节点上连接链路的**适配器**来描述 CSMA/CD 工作过程，大概包括以下情况：

1. 适配器从上层获取数据报，封装成帧并放入缓存；
2. 适配器监听信道，在空闲时传输帧；
3. 适配器在**传输过程中**始终监听信道；
4. 如果发生碰撞（有其他帧到达节点所在信道位置），则停止，并再等待一个**随机**时间后**重新侦听**；如果没有发生碰撞，则完成传输。

发生碰撞时的随机等待监听时间使用**二进制指数回退（binary exponential backoff）**方法计算。当一个帧**已经**发生了 n 次碰撞，就在 [ 0 ，2^n-1^ ] **整数**范围内随机取值 K，等待该 512·K 比特时间（传输 512 比特所需时间，对于 100 Mbps 的信道来说是 5.12 ms）后重新侦听。时间范围呈指数增长，该方法因此得名。

CSMA/CD 的**效率**被定义为**没有碰撞的帧**在一个假定有大量节点以最大速率传输帧的信道中在长期运行时所占的比例。经研究推导，在两个适配器间最大传输时延为 d~prop~，传输一个最大长度以太网帧所需时间为 d~trans~（对于 10 Mbps 的以太网，近似为 1.2 ms），效率大致为：
$$
\frac{1}{1+5d_{prop}/d_{trans}}
$$

当 d~prop~ 趋向于 0，效率趋向于 1；当 d~trans~ 趋向于无穷，效率也趋向于 1 。

#### 轮流协议

**轮流协议**已有几十种，比较重要的轮流协议有两种：

+ **轮询协议（polling protocol）**：轮询协议要求信道上的某个节点成为**主节点**，主节点会监听信道空闲状态，以**轮询（polling）**的方式循环询问其他所有节点，告知它们当前能够传输的**最大帧数**；当上一个被轮询的节点传输一定帧后，主节点**才会**向下一个节点轮询告知能进行传输的最大帧数。轮询将引入一个新的时延：**轮询时延**，这会决定轮询协议的效率；该协议有两个问题：

  1. 如果信道中只有一个活跃节点，主节点还是要轮询其他非活跃节点；
  2. 如果主节点故障，整条信道都将不可操作。

  但是轮询协议可以有效避免碰撞问题，并减少空时隙的浪费，主要被用在 802.15 和蓝牙协议中；

+ **令牌传输协议（token-passing protocol）**：该协议没有主节点，但有一个**令牌（token）**，该令牌以一种固定顺序在每个节点间传播。当一个节点持有令牌，但无需传输帧时，**立即递交**令牌给下一个节点；只有节点持有令牌时，**才可**传输帧，并在**完成后**向后递交令牌。该协议的主要**问题**在于其中一个节点的故障会导致令牌无法继续传输。使用该协议的有光线分布式数据接口（FDDI）协议和 IEEE 802.5 令牌环协议。

#### 实例：DOCSIS

**数据经电缆服务接口（DOCSIS）**定义了**电缆调制解调器端接系统（CMTS）**的结构和协议，CMTS 是光纤出现前常用的住宅网络接入系统之一。DOCSIS 使用 FDM 将**下行**（CMTS 到调制解调器（MTS））和**上行**（MTS 到 CMTS）网络段分为多个频率信道，但每个频率并不能保证只有一个节点使用。

上行和下行均为广播信道。每个下行信道的速率大致为 40 Mbps，且是一对多传输，不存在碰撞。而上行信道是多对一传输，将会发生碰撞。因此，每条上行信道被划分为**时间间隔**（类似 TDM 的时间帧），并继续细分为多个**微时隙序列**。CMTS 在下行信道中发送 **MAP 控制报文**告诉每个 MTS 何时（哪个时间间隔内）进行传输，因此保证不发生碰撞。而 MTS 将在上行信道中发送**请求帧**向 CMTS 请求传输，请求帧可能发生碰撞，如果 MTS 没有收到 MAP 响应，就判定请求发生碰撞，并将在碰撞时使用**二进制指数回退**随机等待并重传。因为上行信道可能会空闲，MTS 也可能直接在请求帧中包含数据帧以提高效率。

### 6.4 交换局域网

在局域网中的节点通过链路层通过媒体访问控制协议 MAC 地址进行**寻址**，而不是使用 IP 地址。目前最常用的局域网技术是**以太网**。

#### 链路层寻址和 MAC

因特网协议栈中的主机和路由器的每个**接口**（网络适配器，即网络接口卡）除了拥有唯一的 IP 地址外，还拥有唯一的**媒体访问控制协议地址（MAC Address）**。MAC 地址实际用于在广播链路中进行接口寻址，而不是直接参与碰撞问题处理，因此在点对点链路中也被用于接口寻址。

##### MAC 地址

MAC 地址也称 LAN 地址或物理地址（physical address）。MAC 采用**十六进制表示法**，每个字节用一个十六进制数对表示，总长度为 **6 字节**即 48 比特，因此总共可能有 2^48^ 个 MAC 地址。MAC 地址被设计为**永久且唯一**，由设备厂商决定设备（网络适配器）的 MAC 地址，而 IEEE 则负责管理全球所有的 MAC 地址，并向每个厂商分发地址范围，每个范围能够容纳 2^24^ 个 MAC 地址。与 IP 不同，MAC 无论到哪里都不会发生变化，而主机的 IP 会根据其所在子网动态分配，因此 MAC 地址具有**扁平结构**，即没有像网络层中那样的子网生成树结构（每个网络层交换机管理和分配一块 IP 地址），同一个局域网中的设备没有进行流量隔离。

此外，**MAC 广播地址**`FF-FF-FF-FF-FF-FF`被用于局域网广播。

##### ARP 地址解析协议

**地址解析协议（Address Resolution Protocol，ARP）**被用于进行网络层地址（通常是 IP 地址）与 MAC 地址间的**转换**，当适配器获得上层 IP 数据报时，需要**根据** IP 地址获取 IP 所在适配器的 MAC 地址。在每台主机和路由器中都有一个 **ARP 表**记录了从 IP 地址到 MAC 地址的映射。每个映射对不是永久的，具有一个**寿命（TTL）**值，一般为 20 分钟，到期后映射对会被移除。ARP 表是**自动**建立的，无需网络管理员参与配置。如果节点在局域网中断开连接，其 ARP 表也会清空。每个局域网节点都将包含一个网络适配器和 **ARP 模块**，后者用于进行 ARP 服务提供。

ARP 分组一般不包含载荷，首部中最重要的四个部分是：

+ 发送方 IP
+ 发送方 MAC
+ 目标 IP 
+ 目标 MAC：在 ARP 查询中，该字段的 MAC 值一般为`00:00:00:00:00:00`

ARP 和 IP 间的一个重要区别是 ARP **只为**同一个子网中的设备服务，因此适配器发送的 **ARP 分组**中包含的 MAC 信息只能是子网中的适配器 MAC 地址。当 ARP 表中没有需要的映射时，发送方就根据 ARP 协议发送查询分组。每个 ARP 查询分组和 ARP 响应分组都包含发送方和接收方的 IP 与 MAC 地址。

当发送方发送的链路层帧的目的地位于**同一个子网**中时，节点的网络适配器首先会在其 ARP 表中根据 IP 数据报中的 IP 目的地址查找对应 MAC 。如果找到，适配器就直接发送帧；如果没有找到，适配器使用 MAC 广播地址进行一次**广播**，子网中的所有节点（主机和网络层路由器）的适配器都会收到该 **ARP 查询分组**。收到查询分组后，各节点的 ARP 模块将检查分组中接收方的 IP 字段，如果和节点的接口的 IP 地址匹配，就返回一个 **ARP 响应分组**，在发送方 MAC 字段中包含查询 IP 对应的 MAC 地址，因此查询方可以更新其 ARP 表。整个过程**没有**涉及网络层处理，即**以太网没有网络层**。

当发送方需要进行**跨子网**帧传输时，就**不能**直接将子网外节点的目的地 MAC 地址直接放入帧中，因为各节点的适配器在发现 ARP 请求的 MAC 不匹配后并**不会**将帧拆封上交给网络层，对于网关路由器而言也就不会将数据报转发到另一个子网中，因此不会得到任何响应。此时，查询分组中的接收方 MAC 地址字段值实际上是子网中**网关路由器**接口的 MAC 地址。一个包含 ARP 查询的跨子网传输将涉及**网络层**交换机（路由器）的处理，整个过程大致如下：

1. 发送方子网中的发送节点最初并不知道其网关路由器端口的 MAC，但在联网时通过 DHCP 获取了**第一跳** IP 即网关端口 IP ，ARP 表在 DCHP 查询前学习了 MAC-IP 映射；
1. 发送方节点的网络层将外网节点 IP 作为目的 IP 生成数据报，适配器将其封装进帧，以目的地 MAC 为**网关端口**的 MAC 发送该帧；
1. 网关路由器端口接收该帧，并拆封数据报上交给路由器的**网络层**，网络层发现数据报目的地 IP 指向外网，根据 IP 转发表确定**出端口**，出端口适配器再次封装成帧，向外网路由器转发帧，目的地址通过查询出端口适配器 ARP 表或向外网发送 ARP 查询获得；
1. 接收方子网路由器**入端口**解析帧，递交与网络层。接到响应后由出端口的适配器将数据报成帧，目的地 MAC 地址根据 ARP 表中映射和数据报中目的地 IP 进行设置，如果没有映射则使用 ARP 查询，随后发送帧到子网；
1. 接收方节点的适配器收到该帧，拆封并上交给节点网络层处理。

#### 以太网

##### 以太网技术发展

**以太网（Ethernet）**是目前使用最广泛的局域网技术，由 Bob Metcalfe 和 David Boggs 在 20 世纪 70 年代发明，现在其标准由 IEEE 803.2 工程组负责管理。最早的以太网使用同轴电缆总线连接，是一种总线拓扑；之后的以太网改为使用双绞铜线的基于集线器的星形拓扑连接。这两种连接方式都会产生**碰撞问题**，因此各自采用了一些 MAC 协议。

如今，以太网已经升级成**基于交换机的星形拓扑结构**，由一个中心节点即以太网**交换机（switch）**转发所有节点的帧，交换机和各节点是**点对点连接**，因此不会发生任何碰撞，且是全双工的，也就**不需要** MAC 协议了（MAC 地址仍用于以太网设备寻址）。

##### 以太网帧结构

以太网帧包含以下结构：

+ **前同步码（preamble）**：8 字节，也称**前导码**，具有固定值，前 7 比特都是`10101010`，即`0x55`，最后一个别特为`10101011`即`0xD5`。该字段用于不同网络适配器间的**时钟同步**（时钟指帧比特传输速率）。Wireshark 默认不显示该字段；
+ **目的地址**：6 字节，即目的地 MAC 地址；
+ **源地址**：6 字节；
+ **类型**：2 字节，使用一个十六进制字节对表示：
  + IPv4：`0x0800`
  + ARP：`0x0806`
  + PPPoE：`0x8864`
  + IPv6：`0x86DD`
+ **CRC 比特**：4 字节，用于循环冗余校验；
+ **数据字段**：46 ~ 1500 字节。如果超过以太网 MTU，上层数据报就必须**分片**；如果小于最小数据字段长度，上层数据报就必须**填充**，由目的地网络层软硬件根据首部长度字段去除填充部分内容。

一般认为以太网帧首部包括目的地址、源地址、类型三个字段，总长 14 字节。

##### 以太网服务模型

以太网提供的服务是一种**无连接**的服务，没有握手，不维护连接状态，因此是一种**不可靠传输服务**。虽然以太网协议会进行 CRC 校验，但是当发现错误时只是简单丢弃帧，而不会向发送方发送反馈帧，没有错误时也不发送应答帧，因此丢弃时产生了**间隙**。如果应用层使用 UDP 提供服务，就会发现报文中出现间隙；如果使用 TCP 提供服务，则 TCP 会负责可靠数据传输，使网络层和链路层执行重传，因此不会出现间隙。

#### 链路层交换机

基于交换机的星形拓扑中的**链路层交换机**对于子网中的主机和路由器节点是**透明**的，即节点并不知道中间有一层交换机（不会向交换机寻址）。交换机的**工作**是将其接收链路接收的帧转换到出链路。为了处理接口到达流量过大的情况，交换机的接口设有**缓存**。每个交换机有一个以上的接口，连接不同的节点，连接的链路都是全双工且无碰撞的。

现在，有一些链路层交换机可能会包含一些网络层功能，即实现了部分路由功能，这些交换机称为**三层交换机**，不包含网络层功能的传统交换机称为**二层交换机**。三层交换技术就是二层交换技术加上三层转发技术，因此会有自己的 IP 地址。

##### 交换机功能

交换机包括**转发（forwarding）**（转发到哪个出链路接口）和**过滤（filtering）**（转发还是丢弃帧）两种功能，两者借助一张**交换机表（switch table）**工作。交换机表项包括三部分：目的 MAC 地址、通向地址的交换机接口、表项被记录的时间。

交换机将检测到达帧的目的 MAC 地址字段，查找交换机表中是否有对应的表项，此时会有三种情况：

1. 没有对应表项：由于没有对应项，交换机将向其所有接口出链路（**除**接入接口，否则引发**环路**）**广播**当前帧，如果广播到达目的地，目的主机就会向源主机进行回应，交换机就可以学习到新的映射；如果链路上经过的其他交换机也没有对应表项，继续广播直到收到响应；
2. 有对应表项，但是指向入链路接口：说明该帧目的地在入链路所在网段，交换机无需转发，执行**过滤**，丢弃该帧；
3. 有对应表项，且指向其他接口：向其他接口转发帧。

##### 交换机的作用

1. **消除碰撞**：使用交换机的以太网拓扑是一种星形拓扑结构，因此不会发生任何碰撞；
2. **链路异质化**：交换的每个接口负责隔离不同的链路，因此各个链路可以使用不同的媒体来实现，并在交换机中中转以同步速率；
3. **管理**：可网管的交换机可以避免某个故障适配器产生的帧或其他恶意帧被转发向其他链路。

##### 自学习

交换机是**自学习**的，即交换机表是自动配置无需管理员手动参与的，是一种**即插即用设备**。交换机表一开始是**空**的，到达的新帧的**源 MAC 地址**和**接口**会被记录在新的表项中。根据时间字段，当表项超出一个指定的**老化时间**后，交换机会从交换机表中删除该项。需要注意的是交换机表空间不是无限的，当表满后，新到达的没有记录的帧**只能**通过广播进行转发。

##### 交换机毒化

**交换机毒化（switch poisoning）**是一种针对交换机的攻击，目的是截获不应转发到分组嗅探器所在主机上的那些分组。因为交换机不进行流量隔离，要获得这些分组，交换机毒化攻击者会发送大量带有伪造源 MAC 的帧来填满交换机的交换机表，使得局域网中的那些合法主机信息无法被记录，因此发向合法主机的帧永远会被以**广播**形式发送，并被嗅探者截获。

##### 广播风暴

由交换机毒化引起的广播问题被称为**广播风暴（broadcast storm）**，指广播数据充斥网络无法处理的情况。广播风暴的原因还可能是链路层交换机没有正确配置而产生了**环路**，导致交换机不断向各接口广播帧，最终导致局域网瘫痪。

一个简单的配置故障例子是交换机在需要进行帧广播时，向该帧**来源链路**发出了不必要的广播。如果该链路网段中没有交换机，一般的节点适配器会无视该广播；如果有交换机且交换机表中没有对应表项，就会发起另一个广播帧，这个广播帧会再次到达故障交换机接口，并引发广播环路。

##### 交换机和路由器对比

在点对点传输中，负责各个网段流量转发的设备是**交换机**或**路由器**。其中交换机负责两层协议栈内容，使用链路层协议进行转发，是链路层设备；路由器负责三层，使用网络层协议进行转发，是网络层设备；一般用交换机描述**链路层**交换机，路由器描述网络层交换机。对于网络层路由器来说，交换机是其子网中的透明设备。基于 SDN 的现代交换机也能转发网络层数据报。网络管理员在选择局域网互联设备时，应该考虑两者的优缺点。

交换机的**优点**有：

+ 即插即用：MAC 地址是扁平的，无需手动或自动配置；
+ 较高转发速率：只需考虑两层协议栈处理；

交换机的**缺点**有：

+ 没有隔离广播流量：虽然交换机会隔离一般的流量，但是如果交换机表中没有对应的出链路，会进行帧广播。帧广播内容可能是 ARP 也可能是数据帧；
+ 需要构建网络拓扑的生成树：因为 MAC 是扁平的，为了避免出现广播帧循环（广播风暴），需要使用网络拓扑生成树，如启用 **STP 生成树协议**，将局域网中节点划分为多个子树，在某个区域出现广播风暴时只需断开该子树中出现的环路。拥有该功能的交换机称为**可网管的交换机**，并将消耗额外资源；
+ 傻瓜交换机不提供对广播风暴的防护：傻瓜交换机是不具有生成树协议功能的交换机，无法防御广播风暴；

路由器的**优点**有：

+ 不会产生广播循环：路由器基于网络层协议进行分组转发，而网络层协议是非扁平的，广播消息（如 DHCP 发现数据报）只在子网中传输，没有广播循环问题；
+ 适用于复杂拓扑结构：因为不必担心广播风暴，无需使用生成树协议，路由器更适合构建大型网络如因特网；

路由器的**缺点**有：

+ 非即插即用：公网中的路由器和主机 IP 地址仍需手动配置；
+ 转发效率较慢：需要考虑三层处理。

一般来说，小型互联网使用交换机进行局域网网段隔离就足够了，而大型互联网则需要在使用交换机的同时加入路由器。

#### 虚拟局域网

一般的交换机有几个缺点：

+ 缺乏流量隔离：帧广播将导致分组发往所有节点接口，可能被攻击者利用；
+ 交换机的无效使用：因为交换机对于节点是透明的，如果直接通过一台交换机连接所有节点，实际上没有意义；
+ 节点转移：如果节点需要在两台交换机负责的网段中移动，就必须断开与原来交换机的链路连接，重新连接新的交换机。

而支持**虚拟局域网（VLAN）**的交换机可以很好地解决该问题。基于交换机**接口**的 VLAN 会将一台交换机上的一组接口划分为一个 VLAN，从而形成一个**广播域**，广播消息只会在该组接口中广播，而不会向外扩散。如果交换机上的两个 VLAN 中的节点需要通信，跨子网转发会经过一个交换机内部的**路由器**处理，该路由器将根据网络层协议进行目的地寻址，因此不会出现广播扩散；如果节点需要在 VLAN 中转移，只需在 **VLAN 配置软件**中更改节点 MAC 地址所属的 VLAN，而不需要断开重连。

如果两个位于不同交换机上的 VLAN 需要通信，则使用 **VLAN 干线连接（VLAN trunking）**的方式，使用一条干线连接两台交换机，该干线属于所有的 VLAN 。接收方 VLAN 所在的交换机为了知道到达的帧属于哪个 VLAN ，需要使用一种**扩展**的以太网帧格式：802.1Q，该标准用于跨越 VLAN 干线的帧传输。802.1Q 在以太网帧的首部末尾（数据载荷前）加入了两个新的字段，被称作 **VLAN 标签**：

+ **标签协议标识符（TPID）**：2 字节，具有固定值`0x8100`，表示是一个 VLAN 扩展；
+ **标签控制信息**：2 字节，包含一个 12 比特的 **VLAN 标识符**用于标记对应 VLAN，以及一个 3 比特的**优先权**字段用于流量控制。

发送方 VLAN 所在的交换机负责在以太网帧中**加入**扩展信息，而接收方 VLAN 根据扩展信息确定目的节点，将扩展信息**删除**后交给目的节点，因此节点并不知道与其他局域网的通信是跨干线的。

此外，基于链路层 MAC 地址和网络层 IP 地址进行 VLAN 划分也是可行的。现实中的 VLAN 往往是跨交换机子网甚至是地区 ISP 、将互联网中不同子网间主机相连的一种虚拟网络，如 zerotier 就提供全球区域的免费 VLAN 互联服务，但是由于其用户主机量逐渐增加，目前已经暂停了公开服务。全球范围内的 VLAN 的内部安全保障也是很重要的一方面。

### 6.5 链路虚拟化：网络层作为链路层

在传统的链路层实现中，通信链路大多是物理媒介，而现在的链路实现还包括无线电和其他媒体，因此链路的抽象实际上是一种**信道**。过去连接两台主机的链路层网络实际上是基于电路交换的**电话网**，如果链路实际上是一种信道，就可以有其他实现。

因特网将链路层提供的服务看成简单的线路连接，可以认为是**虚拟化**了电路网，将其视为物理层。

#### MPLS 多标签交换协议

**多标签交换协议（MPLS）**是建立在网络层设备上的一种基于分组交换的虚拟电路网络。之所以说是虚拟链路层技术，是因为其运作在网络层上，但**并不触及**网络层协议，即不解析 IP 首部字段，不基于 IP 地址进行分组转发，也就不需要执行最长前缀匹配，取而代之的是一组**标签**。**MPLS 首部**被插入在链路层帧首部和网络层数据报首部之间，内部包含一组标签，这些标签告知带有 MPLS 使能的路由器如何选择对应接口。MPLS 技术极大加速了网络层转发速度，已是新一代的 IP 高速骨干网络交换标准。即，在路由器上也就是网络层上建立一层**新的交换网络**。

此外 MPLS 还被用于 VPN（虚拟专用网）的实现。使用基于 MPLS VPN 技术的用户可以在没有 IP 地址的情况下经过 MPLS 使能路由器进行跨 ISP 局域网转发。

### 6.6 数据中心网络

当今的互联网公司如谷歌、微软、亚马逊、Meta、阿里巴巴等都拥有自己的一种局域网：**数据中心网络（data center network）**，这些数据中心网络具有自己的局域网拓扑结构，并与全球互联网互联。这些数据中心网络的设计模式或称设计艺术被称作**数据中心网络设计（data center network，design）**。数据中心网络的最基本单位是**刀片（blade）**，即具有 CPU、内存、外存等基本结构的主机，这些主机被存放在机架上，由机架顶部的一台以太网交换机互联，因此该交换机被称为**机架顶部（Top of Rack，TOR）交换机**，这些数据中心网络 TOR 交换机之间又彼此互联。

#### 拓扑模式

即使互联网公司各自的数据中心网络拓扑具体实现不同，但大都符合几种模式，并与因特网的实现模式相仿。数据中心网络通过一台或多台因特网边缘的**边界路由器（border router）**在网络层上与因特网相连。边界路由器又与数据中心内部负责子网划分的**接入路由器**连接。接入路由器负责的子网中的以太网交换机可能具有多层结构，最底层便是 TOR 交换机。

##### 负载均衡模式

在**负载均衡（load balance）**模式下，接入路由器下子网中的任意一层以太网交换机可能会连接一台**负载均衡器（load balance）**，负载均衡器是一台中转服务器，根据目的地主机的负载情况做决策。负载均衡器也可能会具有 NAT 的功能，将外部 IP 转为内部 IP。负载均衡在 NAT 使能下的作用是隐藏内部网络结构，防止用户直接与主机交互。

##### 等级体系结构模式

在小型数据中心中，简单的一层交换机网络就足够了，但在大型数据中心中往往具有多层**路由器和交换机等级结构（hierarchy of router and switch）**。这与整个因特网的拓扑类似，并且也会使用 VLAN 等技术使 ARP 广播流本地化。

#### 发展趋势

为了降低维护费用和增加传输性能，数据中心网络的部署方案正在不断设计和实现。

改善主极到主机传输速率性能的一个主要趋势是使用**全连接拓扑（fully connected topology）**，在这种情况下，具有多层结构的以太网交换机中的下层交换机可以与所有上层交换机互联，而不是只连接一台上层交换机。这么做不仅可以充分利用空闲链路，还可以避免原来结构中多台交换机共享同一台上层交换机可能导致的传输速率下降问题，并且没有突破原有的等级限制。

改善维护成本的一个趋势是使用**模块化数据中心（MDC）**。这种物理上的模块化实现可能是将一组机架放置在一个集装箱中，以集装箱为模块单位进行模块间的互联。当模块出现问题，直接用新的集装箱替换旧的集装箱。

另一种提高容错性的方法是建立**可用性区域**。这种技术的实现是在一个地理区域中复制多个数据中心，这些数据中心间不断同步数据并服务区域用户。即使有一个数据中心宕机，其他可用性区域中的数据中心也可继续工作。

### 6.7 回顾：Web 页面的请求过程

下面是一个实例，假设整个 Web 页面的请求过程是从主机联网开始的，并且该网络路径中的所有 ARP 表、交换机表和本地 DNS 服务器对所有信息一无所知。

#### 联网准备

1. 主机想要发送 Web 页面请求，就必须先连接网络。联网最初从一个 **DHCP 发现**报文开始，因为主机还没有 IP 地址。DHCP 发现报文将被一个 UDP 协议封装，使用端口 67 ，以 IP 广播地址（255.255.255.255）为目的地址，0.0.0.0 为源地址向所有主机广播以发现 DHCP 服务器；
2. DHCP 发现报文所在的 IP 数据报被封装在一个以太网帧中，因为不知道 DHCP 所在路由器端口的 MAC 地址，其以太网帧也需要**广播**；
3. 由于路由器是网络层设备，将拆封所有以太网帧（包括广播）并递交给网络层。DHCP 报文所在帧被路由器端口适配器拆封并向上递交，网络层根据数据报首部发现上层服务为 UDP ，UDP 再根据端口将 DHCP 报文递交给路由器的 DHCP 服务器，由路由器中的 DHCP 服务器接收并解析，进行后三次 DHCP 握手，主机获取自己的子网 IP 地址。该 DHCP 位于负责子网互联的路由器中，因此该路由器是主机的**网关**，主机将记录第一跳 IP 地址。至此，联网准备完成。

#### 请求准备

1. 主机上的浏览器已准备好一个 **HTTP GET 请求**，但并不知道目的地的 IP 地址，因此一个 **DNS 查询请求**将发送本地 DNS 服务器中。假设这个 DNS 服务器也位于网关路由器上；
2. 主机拥有第一跳 IP 地址的记录，但不知道网关的 MAC，因此将发送一个 ARP 广播，目的 IP 为第一跳 IP，MAC 为 FF-FF-FF-FF-FF-FF。接收 ARP 响应后，记录网关 MAC 进 ARP 表；
3. 主机发送包含 DNS 查询请求的帧至本地 DNS 服务器（网关），网关发现自己的 DNS 映射表中没有对应信息，因此向**根 DNS 服务器**发送查询，根 DNS 再向**顶级域 DNS**查询，顶级域 DNS 向**权威 DNS** 查询，获取 HTTP GET 请求域名的 IP 地址，并由网关中的本地 DNS 向主机返回。至此，HTTP 请求所需的准备已完成。

#### 与服务器交互

1. 主机上的浏览器已经准备发送 HTTP GET 请求，但需要先建立 **TCP 连接**；
2. 主机首先向服务器发送一个 **TCP SYN 报文段**进行第一次握手，服务器返回一个 **SYN ACK 报文段**表示准备建立连接，主机选择一个初始 TCP 序号，发送一个**普通 TCP 报文段**作为响应，TCP 握手完成，连接已建立；
3. 第三次握手的 TCP 报文段可能会直接封装 HTTP GET 请求，也可能单独使用一个 TCP 请求发送。服务器接收到 HTTP 请求后返回一个 **HTTP 响应**。至此，主机完成了 Web 页面请求的全过程。

